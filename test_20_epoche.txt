Epoch 1 Batch 0 Loss 7.4969 Accuracy 0.0000
Epoch 1 Batch 50 Loss 4.2089 Accuracy 0.7790
Epoch 1 Batch 100 Loss 3.3042 Accuracy 0.7936
Epoch 1 Batch 150 Loss 2.7812 Accuracy 0.7983
Epoch 1 Batch 200 Loss 2.4876 Accuracy 0.8008
Epoch 1 Batch 250 Loss 2.2949 Accuracy 0.8023
Epoch 1 Batch 300 Loss 2.1191 Accuracy 0.8041
Epoch 1 Batch 350 Loss 1.9838 Accuracy 0.8064
Epoch 1 Batch 400 Loss 1.8785 Accuracy 0.8084
Epoch 1 Batch 450 Loss 1.7932 Accuracy 0.8099
Epoch 1 Batch 500 Loss 1.7224 Accuracy 0.8114
Epoch 1 Batch 550 Loss 1.6613 Accuracy 0.8132
Epoch 1 Batch 600 Loss 1.6100 Accuracy 0.8149
Epoch 1 Batch 650 Loss 1.5654 Accuracy 0.8166
Epoch 1 Batch 700 Loss 1.5257 Accuracy 0.8181
Epoch 1 Batch 750 Loss 1.4917 Accuracy 0.8194
Epoch 1 Batch 800 Loss 1.4621 Accuracy 0.8206
Epoch 1 Batch 850 Loss 1.4348 Accuracy 0.8217
Epoch 1 Batch 900 Loss 1.4108 Accuracy 0.8226
Epoch 1 Batch 950 Loss 1.3893 Accuracy 0.8235
Epoch 1 Batch 1000 Loss 1.3694 Accuracy 0.8243
Epoch 1 Batch 1050 Loss 1.3514 Accuracy 0.8250
Epoch 1 Batch 1100 Loss 1.3348 Accuracy 0.8257
Epoch 1 Batch 1150 Loss 1.3197 Accuracy 0.8263
Epoch 1 Batch 1200 Loss 1.3055 Accuracy 0.8269
Epoch 1 Batch 1250 Loss 1.2928 Accuracy 0.8274
Epoch 1 Batch 1300 Loss 1.2806 Accuracy 0.8279
Epoch 1 Batch 1350 Loss 1.2696 Accuracy 0.8283
Epoch 1 Batch 1400 Loss 1.2591 Accuracy 0.8288
Epoch 1 Batch 1450 Loss 1.2490 Accuracy 0.8292
discarded batch 1476
Epoch 1 Batch 1500 Loss 1.2397 Accuracy 0.8296
Epoch 1 Loss 1.2312 Accuracy 0.8300
Time taken for 1 epoch: 46.09863543510437 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.9390 Accuracy 0.8417

epoch lasted: 47.558754444122314
Epoch 2 Batch 0 Loss 0.9145 Accuracy 0.8439
Epoch 2 Batch 50 Loss 0.9659 Accuracy 0.8418
discarded batch 60
Epoch 2 Batch 100 Loss 0.9618 Accuracy 0.8415
Epoch 2 Batch 150 Loss 0.9601 Accuracy 0.8414
Epoch 2 Batch 200 Loss 0.9600 Accuracy 0.8413
Epoch 2 Batch 250 Loss 0.9583 Accuracy 0.8414
Epoch 2 Batch 300 Loss 0.9584 Accuracy 0.8413
Epoch 2 Batch 350 Loss 0.9583 Accuracy 0.8413
Epoch 2 Batch 400 Loss 0.9573 Accuracy 0.8414
Epoch 2 Batch 450 Loss 0.9566 Accuracy 0.8414
Epoch 2 Batch 500 Loss 0.9552 Accuracy 0.8415
Epoch 2 Batch 550 Loss 0.9534 Accuracy 0.8416
Epoch 2 Batch 600 Loss 0.9527 Accuracy 0.8417
Epoch 2 Batch 650 Loss 0.9518 Accuracy 0.8418
Epoch 2 Batch 700 Loss 0.9514 Accuracy 0.8417
Epoch 2 Batch 750 Loss 0.9506 Accuracy 0.8418
Epoch 2 Batch 800 Loss 0.9493 Accuracy 0.8419
Epoch 2 Batch 850 Loss 0.9483 Accuracy 0.8419
Epoch 2 Batch 900 Loss 0.9473 Accuracy 0.8419
Epoch 2 Batch 950 Loss 0.9464 Accuracy 0.8419
Epoch 2 Batch 1000 Loss 0.9455 Accuracy 0.8419
Epoch 2 Batch 1050 Loss 0.9448 Accuracy 0.8420
Epoch 2 Batch 1100 Loss 0.9438 Accuracy 0.8421
Epoch 2 Batch 1150 Loss 0.9427 Accuracy 0.8421
Epoch 2 Batch 1200 Loss 0.9415 Accuracy 0.8422
Epoch 2 Batch 1250 Loss 0.9407 Accuracy 0.8423
Epoch 2 Batch 1300 Loss 0.9400 Accuracy 0.8423
Epoch 2 Batch 1350 Loss 0.9392 Accuracy 0.8424
Epoch 2 Batch 1400 Loss 0.9385 Accuracy 0.8424
Epoch 2 Batch 1450 Loss 0.9373 Accuracy 0.8425
Epoch 2 Batch 1500 Loss 0.9362 Accuracy 0.8425
Epoch 2 Loss 0.9351 Accuracy 0.8426
Time taken for 1 epoch: 35.513211727142334 secs

epoch lasted: 35.51670742034912
Epoch 3 Batch 0 Loss 0.9215 Accuracy 0.8422
Epoch 3 Batch 50 Loss 0.9111 Accuracy 0.8452
Epoch 3 Batch 100 Loss 0.9056 Accuracy 0.8451
Epoch 3 Batch 150 Loss 0.9023 Accuracy 0.8449
Epoch 3 Batch 200 Loss 0.9016 Accuracy 0.8447
Epoch 3 Batch 250 Loss 0.9002 Accuracy 0.8449
Epoch 3 Batch 300 Loss 0.8999 Accuracy 0.8448
Epoch 3 Batch 350 Loss 0.8995 Accuracy 0.8450
Epoch 3 Batch 400 Loss 0.8999 Accuracy 0.8450
Epoch 3 Batch 450 Loss 0.8977 Accuracy 0.8451
Epoch 3 Batch 500 Loss 0.8976 Accuracy 0.8452
Epoch 3 Batch 550 Loss 0.8974 Accuracy 0.8453
Epoch 3 Batch 600 Loss 0.8977 Accuracy 0.8453
Epoch 3 Batch 650 Loss 0.8971 Accuracy 0.8454
Epoch 3 Batch 700 Loss 0.8973 Accuracy 0.8454
Epoch 3 Batch 750 Loss 0.8965 Accuracy 0.8455
Epoch 3 Batch 800 Loss 0.8960 Accuracy 0.8456
Epoch 3 Batch 850 Loss 0.8954 Accuracy 0.8456
Epoch 3 Batch 900 Loss 0.8955 Accuracy 0.8457
Epoch 3 Batch 950 Loss 0.8952 Accuracy 0.8458
Epoch 3 Batch 1000 Loss 0.8949 Accuracy 0.8459
Epoch 3 Batch 1050 Loss 0.8946 Accuracy 0.8459
Epoch 3 Batch 1100 Loss 0.8937 Accuracy 0.8460
Epoch 3 Batch 1150 Loss 0.8928 Accuracy 0.8461
Epoch 3 Batch 1200 Loss 0.8922 Accuracy 0.8462
Epoch 3 Batch 1250 Loss 0.8916 Accuracy 0.8462
Epoch 3 Batch 1300 Loss 0.8908 Accuracy 0.8463
Epoch 3 Batch 1350 Loss 0.8902 Accuracy 0.8464
Epoch 3 Batch 1400 Loss 0.8899 Accuracy 0.8464
discarded batch 1445
Epoch 3 Batch 1450 Loss 0.8897 Accuracy 0.8464
Epoch 3 Batch 1500 Loss 0.8893 Accuracy 0.8465
Epoch 3 Loss 0.8886 Accuracy 0.8466
Time taken for 1 epoch: 36.02441716194153 secs

epoch lasted: 36.02930188179016
Epoch 4 Batch 0 Loss 0.8413 Accuracy 0.8588
Epoch 4 Batch 50 Loss 0.8581 Accuracy 0.8493
Epoch 4 Batch 100 Loss 0.8577 Accuracy 0.8493
Epoch 4 Batch 150 Loss 0.8591 Accuracy 0.8495
Epoch 4 Batch 200 Loss 0.8570 Accuracy 0.8500
Epoch 4 Batch 250 Loss 0.8567 Accuracy 0.8502
Epoch 4 Batch 300 Loss 0.8551 Accuracy 0.8505
Epoch 4 Batch 350 Loss 0.8548 Accuracy 0.8504
Epoch 4 Batch 400 Loss 0.8551 Accuracy 0.8504
Epoch 4 Batch 450 Loss 0.8560 Accuracy 0.8503
Epoch 4 Batch 500 Loss 0.8556 Accuracy 0.8503
Epoch 4 Batch 550 Loss 0.8555 Accuracy 0.8502
Epoch 4 Batch 600 Loss 0.8555 Accuracy 0.8503
Epoch 4 Batch 650 Loss 0.8552 Accuracy 0.8503
Epoch 4 Batch 700 Loss 0.8558 Accuracy 0.8504
Epoch 4 Batch 750 Loss 0.8559 Accuracy 0.8504
discarded batch 765
Epoch 4 Batch 800 Loss 0.8554 Accuracy 0.8505
Epoch 4 Batch 850 Loss 0.8549 Accuracy 0.8505
Epoch 4 Batch 900 Loss 0.8546 Accuracy 0.8505
Epoch 4 Batch 950 Loss 0.8542 Accuracy 0.8506
Epoch 4 Batch 1000 Loss 0.8532 Accuracy 0.8506
Epoch 4 Batch 1050 Loss 0.8530 Accuracy 0.8506
Epoch 4 Batch 1100 Loss 0.8528 Accuracy 0.8507
Epoch 4 Batch 1150 Loss 0.8526 Accuracy 0.8507
Epoch 4 Batch 1200 Loss 0.8520 Accuracy 0.8508
Epoch 4 Batch 1250 Loss 0.8518 Accuracy 0.8508
Epoch 4 Batch 1300 Loss 0.8515 Accuracy 0.8509
Epoch 4 Batch 1350 Loss 0.8510 Accuracy 0.8510
Epoch 4 Batch 1400 Loss 0.8505 Accuracy 0.8510
Epoch 4 Batch 1450 Loss 0.8500 Accuracy 0.8511
Epoch 4 Batch 1500 Loss 0.8495 Accuracy 0.8511
Epoch 4 Loss 0.8493 Accuracy 0.8512
Time taken for 1 epoch: 36.18309497833252 secs

epoch lasted: 36.187546730041504
Epoch 5 Batch 0 Loss 0.7783 Accuracy 0.8588
Epoch 5 Batch 50 Loss 0.8227 Accuracy 0.8526
Epoch 5 Batch 100 Loss 0.8201 Accuracy 0.8534
Epoch 5 Batch 150 Loss 0.8222 Accuracy 0.8539
Epoch 5 Batch 200 Loss 0.8216 Accuracy 0.8541
Epoch 5 Batch 250 Loss 0.8219 Accuracy 0.8540
Epoch 5 Batch 300 Loss 0.8244 Accuracy 0.8539
Epoch 5 Batch 350 Loss 0.8253 Accuracy 0.8539
Epoch 5 Batch 400 Loss 0.8247 Accuracy 0.8538
Epoch 5 Batch 450 Loss 0.8239 Accuracy 0.8539
Epoch 5 Batch 500 Loss 0.8236 Accuracy 0.8539
Epoch 5 Batch 550 Loss 0.8233 Accuracy 0.8539
Epoch 5 Batch 600 Loss 0.8231 Accuracy 0.8539
Epoch 5 Batch 650 Loss 0.8229 Accuracy 0.8539
Epoch 5 Batch 700 Loss 0.8223 Accuracy 0.8540
Epoch 5 Batch 750 Loss 0.8217 Accuracy 0.8539
Epoch 5 Batch 800 Loss 0.8213 Accuracy 0.8539
Epoch 5 Batch 850 Loss 0.8210 Accuracy 0.8540
Epoch 5 Batch 900 Loss 0.8211 Accuracy 0.8541
Epoch 5 Batch 950 Loss 0.8207 Accuracy 0.8541
Epoch 5 Batch 1000 Loss 0.8205 Accuracy 0.8541
Epoch 5 Batch 1050 Loss 0.8206 Accuracy 0.8541
Epoch 5 Batch 1100 Loss 0.8204 Accuracy 0.8542
Epoch 5 Batch 1150 Loss 0.8205 Accuracy 0.8541
Epoch 5 Batch 1200 Loss 0.8202 Accuracy 0.8541
Epoch 5 Batch 1250 Loss 0.8195 Accuracy 0.8542
Epoch 5 Batch 1300 Loss 0.8192 Accuracy 0.8542
Epoch 5 Batch 1350 Loss 0.8188 Accuracy 0.8542
Epoch 5 Batch 1400 Loss 0.8190 Accuracy 0.8542
Epoch 5 Batch 1450 Loss 0.8187 Accuracy 0.8542
discarded batch 1477
Epoch 5 Batch 1500 Loss 0.8187 Accuracy 0.8543
Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1
Epoch 5 Loss 0.8183 Accuracy 0.8543
Time taken for 1 epoch: 36.560630083084106 secs

epoch lasted: 36.56493353843689
Epoch 6 Batch 0 Loss 0.7573 Accuracy 0.8588
discarded batch 25
Epoch 6 Batch 50 Loss 0.7876 Accuracy 0.8568
Epoch 6 Batch 100 Loss 0.7871 Accuracy 0.8570
Epoch 6 Batch 150 Loss 0.7928 Accuracy 0.8564
Epoch 6 Batch 200 Loss 0.7955 Accuracy 0.8562
Epoch 6 Batch 250 Loss 0.7963 Accuracy 0.8564
Epoch 6 Batch 300 Loss 0.7972 Accuracy 0.8562
Epoch 6 Batch 350 Loss 0.7980 Accuracy 0.8562
Epoch 6 Batch 400 Loss 0.7982 Accuracy 0.8563
Epoch 6 Batch 450 Loss 0.7979 Accuracy 0.8563
Epoch 6 Batch 500 Loss 0.7982 Accuracy 0.8562
Epoch 6 Batch 550 Loss 0.7981 Accuracy 0.8564
Epoch 6 Batch 600 Loss 0.7978 Accuracy 0.8563
Epoch 6 Batch 650 Loss 0.7974 Accuracy 0.8563
Epoch 6 Batch 700 Loss 0.7975 Accuracy 0.8563
Epoch 6 Batch 750 Loss 0.7979 Accuracy 0.8564
Epoch 6 Batch 800 Loss 0.7979 Accuracy 0.8564
Epoch 6 Batch 850 Loss 0.7979 Accuracy 0.8563
Epoch 6 Batch 900 Loss 0.7979 Accuracy 0.8563
Epoch 6 Batch 950 Loss 0.7978 Accuracy 0.8563
Epoch 6 Batch 1000 Loss 0.7972 Accuracy 0.8564
Epoch 6 Batch 1050 Loss 0.7968 Accuracy 0.8564
Epoch 6 Batch 1100 Loss 0.7967 Accuracy 0.8564
Epoch 6 Batch 1150 Loss 0.7965 Accuracy 0.8564
Epoch 6 Batch 1200 Loss 0.7963 Accuracy 0.8564
Epoch 6 Batch 1250 Loss 0.7960 Accuracy 0.8565
Epoch 6 Batch 1300 Loss 0.7956 Accuracy 0.8566
Epoch 6 Batch 1350 Loss 0.7954 Accuracy 0.8565
Epoch 6 Batch 1400 Loss 0.7955 Accuracy 0.8565
Epoch 6 Batch 1450 Loss 0.7953 Accuracy 0.8565
Epoch 6 Batch 1500 Loss 0.7950 Accuracy 0.8565
Epoch 6 Loss 0.7947 Accuracy 0.8566
Time taken for 1 epoch: 36.64266347885132 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.7700 Accuracy 0.8565

epoch lasted: 36.790886640548706
Epoch 7 Batch 0 Loss 0.8706 Accuracy 0.8472
Epoch 7 Batch 50 Loss 0.7750 Accuracy 0.8583
Epoch 7 Batch 100 Loss 0.7776 Accuracy 0.8582
Epoch 7 Batch 150 Loss 0.7798 Accuracy 0.8579
discarded batch 154
Epoch 7 Batch 200 Loss 0.7784 Accuracy 0.8582
Epoch 7 Batch 250 Loss 0.7775 Accuracy 0.8582
Epoch 7 Batch 300 Loss 0.7777 Accuracy 0.8582
Epoch 7 Batch 350 Loss 0.7781 Accuracy 0.8578
Epoch 7 Batch 400 Loss 0.7775 Accuracy 0.8578
Epoch 7 Batch 450 Loss 0.7774 Accuracy 0.8579
Epoch 7 Batch 500 Loss 0.7768 Accuracy 0.8578
Epoch 7 Batch 550 Loss 0.7778 Accuracy 0.8578
Epoch 7 Batch 600 Loss 0.7779 Accuracy 0.8577
Epoch 7 Batch 650 Loss 0.7783 Accuracy 0.8577
Epoch 7 Batch 700 Loss 0.7782 Accuracy 0.8577
Epoch 7 Batch 750 Loss 0.7782 Accuracy 0.8577
Epoch 7 Batch 800 Loss 0.7777 Accuracy 0.8577
Epoch 7 Batch 850 Loss 0.7772 Accuracy 0.8578
Epoch 7 Batch 900 Loss 0.7771 Accuracy 0.8578
Epoch 7 Batch 950 Loss 0.7765 Accuracy 0.8578
Epoch 7 Batch 1000 Loss 0.7764 Accuracy 0.8578
Epoch 7 Batch 1050 Loss 0.7762 Accuracy 0.8578
Epoch 7 Batch 1100 Loss 0.7763 Accuracy 0.8578
Epoch 7 Batch 1150 Loss 0.7768 Accuracy 0.8578
Epoch 7 Batch 1200 Loss 0.7767 Accuracy 0.8578
Epoch 7 Batch 1250 Loss 0.7764 Accuracy 0.8579
Epoch 7 Batch 1300 Loss 0.7765 Accuracy 0.8578
Epoch 7 Batch 1350 Loss 0.7760 Accuracy 0.8579
Epoch 7 Batch 1400 Loss 0.7760 Accuracy 0.8579
Epoch 7 Batch 1450 Loss 0.7762 Accuracy 0.8579
Epoch 7 Batch 1500 Loss 0.7762 Accuracy 0.8579
Epoch 7 Loss 0.7761 Accuracy 0.8579
Time taken for 1 epoch: 36.81452989578247 secs

epoch lasted: 36.818193435668945
Epoch 8 Batch 0 Loss 0.7422 Accuracy 0.8588
Epoch 8 Batch 50 Loss 0.7586 Accuracy 0.8590
Epoch 8 Batch 100 Loss 0.7556 Accuracy 0.8594
Epoch 8 Batch 150 Loss 0.7557 Accuracy 0.8596
Epoch 8 Batch 200 Loss 0.7571 Accuracy 0.8596
Epoch 8 Batch 250 Loss 0.7581 Accuracy 0.8594
Epoch 8 Batch 300 Loss 0.7587 Accuracy 0.8592
Epoch 8 Batch 350 Loss 0.7590 Accuracy 0.8592
Epoch 8 Batch 400 Loss 0.7593 Accuracy 0.8591
Epoch 8 Batch 450 Loss 0.7595 Accuracy 0.8591
Epoch 8 Batch 500 Loss 0.7607 Accuracy 0.8591
Epoch 8 Batch 550 Loss 0.7616 Accuracy 0.8591
Epoch 8 Batch 600 Loss 0.7617 Accuracy 0.8590
Epoch 8 Batch 650 Loss 0.7611 Accuracy 0.8591
discarded batch 697
Epoch 8 Batch 700 Loss 0.7614 Accuracy 0.8591
Epoch 8 Batch 750 Loss 0.7613 Accuracy 0.8592
Epoch 8 Batch 800 Loss 0.7612 Accuracy 0.8592
Epoch 8 Batch 850 Loss 0.7612 Accuracy 0.8592
Epoch 8 Batch 900 Loss 0.7615 Accuracy 0.8592
Epoch 8 Batch 950 Loss 0.7618 Accuracy 0.8591
Epoch 8 Batch 1000 Loss 0.7616 Accuracy 0.8591
Epoch 8 Batch 1050 Loss 0.7611 Accuracy 0.8592
Epoch 8 Batch 1100 Loss 0.7612 Accuracy 0.8592
Epoch 8 Batch 1150 Loss 0.7615 Accuracy 0.8592
Epoch 8 Batch 1200 Loss 0.7614 Accuracy 0.8592
Epoch 8 Batch 1250 Loss 0.7616 Accuracy 0.8592
Epoch 8 Batch 1300 Loss 0.7616 Accuracy 0.8592
Epoch 8 Batch 1350 Loss 0.7613 Accuracy 0.8592
Epoch 8 Batch 1400 Loss 0.7612 Accuracy 0.8592
Epoch 8 Batch 1450 Loss 0.7612 Accuracy 0.8592
Epoch 8 Batch 1500 Loss 0.7611 Accuracy 0.8592
Epoch 8 Loss 0.7612 Accuracy 0.8592
Time taken for 1 epoch: 36.45181322097778 secs

epoch lasted: 36.456929445266724
Epoch 9 Batch 0 Loss 0.7330 Accuracy 0.8571
Epoch 9 Batch 50 Loss 0.7428 Accuracy 0.8609
Epoch 9 Batch 100 Loss 0.7466 Accuracy 0.8601
Epoch 9 Batch 150 Loss 0.7440 Accuracy 0.8605
Epoch 9 Batch 200 Loss 0.7461 Accuracy 0.8603
Epoch 9 Batch 250 Loss 0.7466 Accuracy 0.8601
Epoch 9 Batch 300 Loss 0.7455 Accuracy 0.8604
Epoch 9 Batch 350 Loss 0.7458 Accuracy 0.8605
Epoch 9 Batch 400 Loss 0.7464 Accuracy 0.8606
Epoch 9 Batch 450 Loss 0.7455 Accuracy 0.8608
Epoch 9 Batch 500 Loss 0.7460 Accuracy 0.8607
Epoch 9 Batch 550 Loss 0.7462 Accuracy 0.8607
Epoch 9 Batch 600 Loss 0.7463 Accuracy 0.8607
Epoch 9 Batch 650 Loss 0.7466 Accuracy 0.8606
Epoch 9 Batch 700 Loss 0.7467 Accuracy 0.8605
discarded batch 706
Epoch 9 Batch 750 Loss 0.7475 Accuracy 0.8606
Epoch 9 Batch 800 Loss 0.7476 Accuracy 0.8605
Epoch 9 Batch 850 Loss 0.7477 Accuracy 0.8605
Epoch 9 Batch 900 Loss 0.7479 Accuracy 0.8605
Epoch 9 Batch 950 Loss 0.7475 Accuracy 0.8606
Epoch 9 Batch 1000 Loss 0.7479 Accuracy 0.8605
Epoch 9 Batch 1050 Loss 0.7476 Accuracy 0.8605
Epoch 9 Batch 1100 Loss 0.7477 Accuracy 0.8605
Epoch 9 Batch 1150 Loss 0.7478 Accuracy 0.8605
Epoch 9 Batch 1200 Loss 0.7480 Accuracy 0.8605
Epoch 9 Batch 1250 Loss 0.7481 Accuracy 0.8604
Epoch 9 Batch 1300 Loss 0.7479 Accuracy 0.8605
Epoch 9 Batch 1350 Loss 0.7479 Accuracy 0.8604
Epoch 9 Batch 1400 Loss 0.7479 Accuracy 0.8604
Epoch 9 Batch 1450 Loss 0.7478 Accuracy 0.8604
Epoch 9 Batch 1500 Loss 0.7481 Accuracy 0.8604
Epoch 9 Loss 0.7481 Accuracy 0.8604
Time taken for 1 epoch: 36.71521520614624 secs

epoch lasted: 36.72024130821228
Epoch 10 Batch 0 Loss 0.7953 Accuracy 0.8505
Epoch 10 Batch 50 Loss 0.7345 Accuracy 0.8625
Epoch 10 Batch 100 Loss 0.7346 Accuracy 0.8623
Epoch 10 Batch 150 Loss 0.7342 Accuracy 0.8619
discarded batch 183
Epoch 10 Batch 200 Loss 0.7352 Accuracy 0.8616
Epoch 10 Batch 250 Loss 0.7342 Accuracy 0.8616
Epoch 10 Batch 300 Loss 0.7346 Accuracy 0.8617
Epoch 10 Batch 350 Loss 0.7344 Accuracy 0.8617
Epoch 10 Batch 400 Loss 0.7355 Accuracy 0.8615
Epoch 10 Batch 450 Loss 0.7348 Accuracy 0.8617
Epoch 10 Batch 500 Loss 0.7356 Accuracy 0.8615
Epoch 10 Batch 550 Loss 0.7353 Accuracy 0.8615
Epoch 10 Batch 600 Loss 0.7355 Accuracy 0.8615
Epoch 10 Batch 650 Loss 0.7360 Accuracy 0.8615
Epoch 10 Batch 700 Loss 0.7371 Accuracy 0.8613
Epoch 10 Batch 750 Loss 0.7370 Accuracy 0.8613
Epoch 10 Batch 800 Loss 0.7367 Accuracy 0.8613
Epoch 10 Batch 850 Loss 0.7369 Accuracy 0.8614
Epoch 10 Batch 900 Loss 0.7373 Accuracy 0.8613
Epoch 10 Batch 950 Loss 0.7372 Accuracy 0.8613
Epoch 10 Batch 1000 Loss 0.7371 Accuracy 0.8614
Epoch 10 Batch 1050 Loss 0.7370 Accuracy 0.8614
Epoch 10 Batch 1100 Loss 0.7373 Accuracy 0.8614
Epoch 10 Batch 1150 Loss 0.7372 Accuracy 0.8614
Epoch 10 Batch 1200 Loss 0.7372 Accuracy 0.8615
Epoch 10 Batch 1250 Loss 0.7373 Accuracy 0.8615
Epoch 10 Batch 1300 Loss 0.7374 Accuracy 0.8615
Epoch 10 Batch 1350 Loss 0.7377 Accuracy 0.8615
Epoch 10 Batch 1400 Loss 0.7377 Accuracy 0.8615
Epoch 10 Batch 1450 Loss 0.7376 Accuracy 0.8615
Epoch 10 Batch 1500 Loss 0.7374 Accuracy 0.8616
Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2
Epoch 10 Loss 0.7375 Accuracy 0.8616
Time taken for 1 epoch: 37.064375162124634 secs

epoch lasted: 37.06834936141968
Epoch 11 Batch 0 Loss 0.7251 Accuracy 0.8638
Epoch 11 Batch 50 Loss 0.7275 Accuracy 0.8625
Epoch 11 Batch 100 Loss 0.7299 Accuracy 0.8620
Epoch 11 Batch 150 Loss 0.7248 Accuracy 0.8624
Epoch 11 Batch 200 Loss 0.7241 Accuracy 0.8625
Epoch 11 Batch 250 Loss 0.7228 Accuracy 0.8625
Epoch 11 Batch 300 Loss 0.7231 Accuracy 0.8626
Epoch 11 Batch 350 Loss 0.7228 Accuracy 0.8626
discarded batch 373
Epoch 11 Batch 400 Loss 0.7233 Accuracy 0.8627
Epoch 11 Batch 450 Loss 0.7229 Accuracy 0.8627
Epoch 11 Batch 500 Loss 0.7241 Accuracy 0.8626
Epoch 11 Batch 550 Loss 0.7253 Accuracy 0.8625
Epoch 11 Batch 600 Loss 0.7258 Accuracy 0.8625
Epoch 11 Batch 650 Loss 0.7255 Accuracy 0.8624
Epoch 11 Batch 700 Loss 0.7255 Accuracy 0.8625
Epoch 11 Batch 750 Loss 0.7246 Accuracy 0.8625
Epoch 11 Batch 800 Loss 0.7250 Accuracy 0.8625
Epoch 11 Batch 850 Loss 0.7249 Accuracy 0.8625
Epoch 11 Batch 900 Loss 0.7254 Accuracy 0.8624
Epoch 11 Batch 950 Loss 0.7255 Accuracy 0.8624
Epoch 11 Batch 1000 Loss 0.7256 Accuracy 0.8624
Epoch 11 Batch 1050 Loss 0.7257 Accuracy 0.8625
Epoch 11 Batch 1100 Loss 0.7266 Accuracy 0.8624
Epoch 11 Batch 1150 Loss 0.7270 Accuracy 0.8624
Epoch 11 Batch 1200 Loss 0.7266 Accuracy 0.8624
Epoch 11 Batch 1250 Loss 0.7264 Accuracy 0.8624
Epoch 11 Batch 1300 Loss 0.7269 Accuracy 0.8624
Epoch 11 Batch 1350 Loss 0.7270 Accuracy 0.8624
Epoch 11 Batch 1400 Loss 0.7270 Accuracy 0.8624
Epoch 11 Batch 1450 Loss 0.7272 Accuracy 0.8624
Epoch 11 Batch 1500 Loss 0.7274 Accuracy 0.8624
Epoch 11 Loss 0.7277 Accuracy 0.8624
Time taken for 1 epoch: 36.738120317459106 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.7263 Accuracy 0.8617

epoch lasted: 36.88886213302612
Epoch 12 Batch 0 Loss 0.7264 Accuracy 0.8605
Epoch 12 Batch 50 Loss 0.7166 Accuracy 0.8641
Epoch 12 Batch 100 Loss 0.7187 Accuracy 0.8634
Epoch 12 Batch 150 Loss 0.7163 Accuracy 0.8638
Epoch 12 Batch 200 Loss 0.7171 Accuracy 0.8636
Epoch 12 Batch 250 Loss 0.7171 Accuracy 0.8635
Epoch 12 Batch 300 Loss 0.7162 Accuracy 0.8633
Epoch 12 Batch 350 Loss 0.7157 Accuracy 0.8634
Epoch 12 Batch 400 Loss 0.7177 Accuracy 0.8632
Epoch 12 Batch 450 Loss 0.7179 Accuracy 0.8633
Epoch 12 Batch 500 Loss 0.7174 Accuracy 0.8634
Epoch 12 Batch 550 Loss 0.7181 Accuracy 0.8635
Epoch 12 Batch 600 Loss 0.7180 Accuracy 0.8635
Epoch 12 Batch 650 Loss 0.7175 Accuracy 0.8636
Epoch 12 Batch 700 Loss 0.7174 Accuracy 0.8636
Epoch 12 Batch 750 Loss 0.7171 Accuracy 0.8635
Epoch 12 Batch 800 Loss 0.7172 Accuracy 0.8636
Epoch 12 Batch 850 Loss 0.7172 Accuracy 0.8636
Epoch 12 Batch 900 Loss 0.7173 Accuracy 0.8636
Epoch 12 Batch 950 Loss 0.7177 Accuracy 0.8635
Epoch 12 Batch 1000 Loss 0.7177 Accuracy 0.8635
Epoch 12 Batch 1050 Loss 0.7181 Accuracy 0.8634
Epoch 12 Batch 1100 Loss 0.7182 Accuracy 0.8634
Epoch 12 Batch 1150 Loss 0.7185 Accuracy 0.8634
Epoch 12 Batch 1200 Loss 0.7186 Accuracy 0.8634
Epoch 12 Batch 1250 Loss 0.7190 Accuracy 0.8634
discarded batch 1256
Epoch 12 Batch 1300 Loss 0.7191 Accuracy 0.8634
Epoch 12 Batch 1350 Loss 0.7192 Accuracy 0.8633
Epoch 12 Batch 1400 Loss 0.7193 Accuracy 0.8633
Epoch 12 Batch 1450 Loss 0.7189 Accuracy 0.8633
Epoch 12 Batch 1500 Loss 0.7187 Accuracy 0.8634
Epoch 12 Loss 0.7185 Accuracy 0.8634
Time taken for 1 epoch: 36.383848667144775 secs

epoch lasted: 36.38733506202698
Epoch 13 Batch 0 Loss 0.7419 Accuracy 0.8621
Epoch 13 Batch 50 Loss 0.7079 Accuracy 0.8648
Epoch 13 Batch 100 Loss 0.7082 Accuracy 0.8645
Epoch 13 Batch 150 Loss 0.7096 Accuracy 0.8640
Epoch 13 Batch 200 Loss 0.7092 Accuracy 0.8640
Epoch 13 Batch 250 Loss 0.7106 Accuracy 0.8638
Epoch 13 Batch 300 Loss 0.7090 Accuracy 0.8642
Epoch 13 Batch 350 Loss 0.7080 Accuracy 0.8644
Epoch 13 Batch 400 Loss 0.7078 Accuracy 0.8642
Epoch 13 Batch 450 Loss 0.7081 Accuracy 0.8642
Epoch 13 Batch 500 Loss 0.7074 Accuracy 0.8643
Epoch 13 Batch 550 Loss 0.7070 Accuracy 0.8644
Epoch 13 Batch 600 Loss 0.7068 Accuracy 0.8644
discarded batch 648
Epoch 13 Batch 650 Loss 0.7073 Accuracy 0.8645
Epoch 13 Batch 700 Loss 0.7076 Accuracy 0.8644
Epoch 13 Batch 750 Loss 0.7080 Accuracy 0.8644
Epoch 13 Batch 800 Loss 0.7076 Accuracy 0.8645
Epoch 13 Batch 850 Loss 0.7079 Accuracy 0.8646
Epoch 13 Batch 900 Loss 0.7084 Accuracy 0.8645
Epoch 13 Batch 950 Loss 0.7083 Accuracy 0.8646
Epoch 13 Batch 1000 Loss 0.7084 Accuracy 0.8646
Epoch 13 Batch 1050 Loss 0.7087 Accuracy 0.8645
Epoch 13 Batch 1100 Loss 0.7085 Accuracy 0.8645
Epoch 13 Batch 1150 Loss 0.7090 Accuracy 0.8644
Epoch 13 Batch 1200 Loss 0.7091 Accuracy 0.8645
Epoch 13 Batch 1250 Loss 0.7091 Accuracy 0.8644
Epoch 13 Batch 1300 Loss 0.7096 Accuracy 0.8644
Epoch 13 Batch 1350 Loss 0.7099 Accuracy 0.8644
Epoch 13 Batch 1400 Loss 0.7102 Accuracy 0.8644
Epoch 13 Batch 1450 Loss 0.7103 Accuracy 0.8644
Epoch 13 Batch 1500 Loss 0.7102 Accuracy 0.8644
Epoch 13 Loss 0.7101 Accuracy 0.8644
Time taken for 1 epoch: 37.21380662918091 secs

epoch lasted: 37.21828651428223
Epoch 14 Batch 0 Loss 0.6973 Accuracy 0.8671
Epoch 14 Batch 50 Loss 0.6974 Accuracy 0.8659
Epoch 14 Batch 100 Loss 0.6956 Accuracy 0.8666
Epoch 14 Batch 150 Loss 0.6945 Accuracy 0.8664
Epoch 14 Batch 200 Loss 0.6962 Accuracy 0.8657
Epoch 14 Batch 250 Loss 0.6957 Accuracy 0.8658
Epoch 14 Batch 300 Loss 0.6943 Accuracy 0.8661
Epoch 14 Batch 350 Loss 0.6962 Accuracy 0.8659
Epoch 14 Batch 400 Loss 0.6968 Accuracy 0.8658
Epoch 14 Batch 450 Loss 0.6972 Accuracy 0.8659
Epoch 14 Batch 500 Loss 0.6974 Accuracy 0.8659
Epoch 14 Batch 550 Loss 0.6980 Accuracy 0.8657
Epoch 14 Batch 600 Loss 0.6978 Accuracy 0.8657
Epoch 14 Batch 650 Loss 0.6982 Accuracy 0.8658
Epoch 14 Batch 700 Loss 0.6983 Accuracy 0.8656
Epoch 14 Batch 750 Loss 0.6985 Accuracy 0.8656
Epoch 14 Batch 800 Loss 0.6984 Accuracy 0.8655
Epoch 14 Batch 850 Loss 0.6990 Accuracy 0.8655
Epoch 14 Batch 900 Loss 0.6992 Accuracy 0.8655
Epoch 14 Batch 950 Loss 0.6995 Accuracy 0.8655
Epoch 14 Batch 1000 Loss 0.6999 Accuracy 0.8654
Epoch 14 Batch 1050 Loss 0.7000 Accuracy 0.8654
Epoch 14 Batch 1100 Loss 0.6999 Accuracy 0.8654
Epoch 14 Batch 1150 Loss 0.7002 Accuracy 0.8653
Epoch 14 Batch 1200 Loss 0.7002 Accuracy 0.8654
Epoch 14 Batch 1250 Loss 0.7005 Accuracy 0.8654
discarded batch 1253
Epoch 14 Batch 1300 Loss 0.7007 Accuracy 0.8654
Epoch 14 Batch 1350 Loss 0.7005 Accuracy 0.8654
Epoch 14 Batch 1400 Loss 0.7006 Accuracy 0.8654
Epoch 14 Batch 1450 Loss 0.7005 Accuracy 0.8655
Epoch 14 Batch 1500 Loss 0.7010 Accuracy 0.8655
Epoch 14 Loss 0.7014 Accuracy 0.8655
Time taken for 1 epoch: 36.13263392448425 secs

epoch lasted: 36.136521100997925
Epoch 15 Batch 0 Loss 0.6480 Accuracy 0.8638
Epoch 15 Batch 50 Loss 0.6783 Accuracy 0.8700
Epoch 15 Batch 100 Loss 0.6827 Accuracy 0.8683
Epoch 15 Batch 150 Loss 0.6825 Accuracy 0.8678
Epoch 15 Batch 200 Loss 0.6833 Accuracy 0.8675
Epoch 15 Batch 250 Loss 0.6861 Accuracy 0.8671
Epoch 15 Batch 300 Loss 0.6867 Accuracy 0.8671
Epoch 15 Batch 350 Loss 0.6869 Accuracy 0.8670
discarded batch 384
Epoch 15 Batch 400 Loss 0.6877 Accuracy 0.8669
Epoch 15 Batch 450 Loss 0.6887 Accuracy 0.8669
Epoch 15 Batch 500 Loss 0.6883 Accuracy 0.8669
Epoch 15 Batch 550 Loss 0.6881 Accuracy 0.8669
Epoch 15 Batch 600 Loss 0.6888 Accuracy 0.8668
Epoch 15 Batch 650 Loss 0.6893 Accuracy 0.8669
Epoch 15 Batch 700 Loss 0.6892 Accuracy 0.8669
Epoch 15 Batch 750 Loss 0.6900 Accuracy 0.8669
Epoch 15 Batch 800 Loss 0.6900 Accuracy 0.8668
Epoch 15 Batch 850 Loss 0.6903 Accuracy 0.8668
Epoch 15 Batch 900 Loss 0.6905 Accuracy 0.8667
Epoch 15 Batch 950 Loss 0.6908 Accuracy 0.8667
Epoch 15 Batch 1000 Loss 0.6910 Accuracy 0.8668
Epoch 15 Batch 1050 Loss 0.6913 Accuracy 0.8667
Epoch 15 Batch 1100 Loss 0.6914 Accuracy 0.8667
Epoch 15 Batch 1150 Loss 0.6919 Accuracy 0.8667
Epoch 15 Batch 1200 Loss 0.6922 Accuracy 0.8666
Epoch 15 Batch 1250 Loss 0.6926 Accuracy 0.8666
Epoch 15 Batch 1300 Loss 0.6925 Accuracy 0.8666
Epoch 15 Batch 1350 Loss 0.6928 Accuracy 0.8666
Epoch 15 Batch 1400 Loss 0.6931 Accuracy 0.8665
Epoch 15 Batch 1450 Loss 0.6931 Accuracy 0.8666
Epoch 15 Batch 1500 Loss 0.6931 Accuracy 0.8666
Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3
Epoch 15 Loss 0.6932 Accuracy 0.8666
Time taken for 1 epoch: 36.1157968044281 secs

epoch lasted: 36.120001554489136
Epoch 16 Batch 0 Loss 0.6601 Accuracy 0.8571
Epoch 16 Batch 50 Loss 0.6805 Accuracy 0.8658
Epoch 16 Batch 100 Loss 0.6808 Accuracy 0.8670
Epoch 16 Batch 150 Loss 0.6780 Accuracy 0.8678
Epoch 16 Batch 200 Loss 0.6788 Accuracy 0.8676
Epoch 16 Batch 250 Loss 0.6786 Accuracy 0.8679
Epoch 16 Batch 300 Loss 0.6791 Accuracy 0.8677
Epoch 16 Batch 350 Loss 0.6792 Accuracy 0.8679
Epoch 16 Batch 400 Loss 0.6799 Accuracy 0.8679
Epoch 16 Batch 450 Loss 0.6795 Accuracy 0.8679
Epoch 16 Batch 500 Loss 0.6799 Accuracy 0.8681
Epoch 16 Batch 550 Loss 0.6794 Accuracy 0.8681
Epoch 16 Batch 600 Loss 0.6805 Accuracy 0.8679
Epoch 16 Batch 650 Loss 0.6810 Accuracy 0.8679
Epoch 16 Batch 700 Loss 0.6814 Accuracy 0.8678
Epoch 16 Batch 750 Loss 0.6813 Accuracy 0.8679
Epoch 16 Batch 800 Loss 0.6819 Accuracy 0.8678
Epoch 16 Batch 850 Loss 0.6822 Accuracy 0.8678
Epoch 16 Batch 900 Loss 0.6829 Accuracy 0.8677
discarded batch 905
Epoch 16 Batch 950 Loss 0.6833 Accuracy 0.8677
Epoch 16 Batch 1000 Loss 0.6840 Accuracy 0.8676
Epoch 16 Batch 1050 Loss 0.6843 Accuracy 0.8676
Epoch 16 Batch 1100 Loss 0.6845 Accuracy 0.8676
Epoch 16 Batch 1150 Loss 0.6845 Accuracy 0.8676
Epoch 16 Batch 1200 Loss 0.6845 Accuracy 0.8676
Epoch 16 Batch 1250 Loss 0.6850 Accuracy 0.8675
Epoch 16 Batch 1300 Loss 0.6851 Accuracy 0.8676
Epoch 16 Batch 1350 Loss 0.6852 Accuracy 0.8676
Epoch 16 Batch 1400 Loss 0.6851 Accuracy 0.8675
Epoch 16 Batch 1450 Loss 0.6856 Accuracy 0.8675
Epoch 16 Batch 1500 Loss 0.6857 Accuracy 0.8675
Epoch 16 Loss 0.6859 Accuracy 0.8675
Time taken for 1 epoch: 35.977171182632446 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.7136 Accuracy 0.8642

epoch lasted: 36.13339447975159
Epoch 17 Batch 0 Loss 0.6641 Accuracy 0.8721
Epoch 17 Batch 50 Loss 0.6715 Accuracy 0.8690
Epoch 17 Batch 100 Loss 0.6665 Accuracy 0.8690
Epoch 17 Batch 150 Loss 0.6661 Accuracy 0.8691
Epoch 17 Batch 200 Loss 0.6668 Accuracy 0.8692
Epoch 17 Batch 250 Loss 0.6699 Accuracy 0.8689
Epoch 17 Batch 300 Loss 0.6721 Accuracy 0.8688
Epoch 17 Batch 350 Loss 0.6731 Accuracy 0.8688
Epoch 17 Batch 400 Loss 0.6743 Accuracy 0.8687
Epoch 17 Batch 450 Loss 0.6743 Accuracy 0.8688
Epoch 17 Batch 500 Loss 0.6751 Accuracy 0.8687
Epoch 17 Batch 550 Loss 0.6760 Accuracy 0.8686
Epoch 17 Batch 600 Loss 0.6769 Accuracy 0.8684
Epoch 17 Batch 650 Loss 0.6766 Accuracy 0.8685
Epoch 17 Batch 700 Loss 0.6765 Accuracy 0.8686
Epoch 17 Batch 750 Loss 0.6764 Accuracy 0.8687
Epoch 17 Batch 800 Loss 0.6766 Accuracy 0.8686
Epoch 17 Batch 850 Loss 0.6768 Accuracy 0.8686
Epoch 17 Batch 900 Loss 0.6766 Accuracy 0.8686
Epoch 17 Batch 950 Loss 0.6767 Accuracy 0.8685
Epoch 17 Batch 1000 Loss 0.6774 Accuracy 0.8685
Epoch 17 Batch 1050 Loss 0.6778 Accuracy 0.8684
Epoch 17 Batch 1100 Loss 0.6778 Accuracy 0.8684
Epoch 17 Batch 1150 Loss 0.6779 Accuracy 0.8684
Epoch 17 Batch 1200 Loss 0.6785 Accuracy 0.8683
Epoch 17 Batch 1250 Loss 0.6786 Accuracy 0.8683
discarded batch 1275
Epoch 17 Batch 1300 Loss 0.6788 Accuracy 0.8683
Epoch 17 Batch 1350 Loss 0.6785 Accuracy 0.8683
Epoch 17 Batch 1400 Loss 0.6788 Accuracy 0.8683
Epoch 17 Batch 1450 Loss 0.6791 Accuracy 0.8682
Epoch 17 Batch 1500 Loss 0.6791 Accuracy 0.8682
Epoch 17 Loss 0.6794 Accuracy 0.8682
Time taken for 1 epoch: 36.003069162368774 secs

epoch lasted: 36.006532192230225
Epoch 18 Batch 0 Loss 0.6407 Accuracy 0.8688
Epoch 18 Batch 50 Loss 0.6655 Accuracy 0.8686
Epoch 18 Batch 100 Loss 0.6629 Accuracy 0.8698
Epoch 18 Batch 150 Loss 0.6600 Accuracy 0.8704
Epoch 18 Batch 200 Loss 0.6644 Accuracy 0.8701
Epoch 18 Batch 250 Loss 0.6647 Accuracy 0.8701
Epoch 18 Batch 300 Loss 0.6655 Accuracy 0.8701
Epoch 18 Batch 350 Loss 0.6660 Accuracy 0.8699
Epoch 18 Batch 400 Loss 0.6658 Accuracy 0.8699
Epoch 18 Batch 450 Loss 0.6662 Accuracy 0.8699
Epoch 18 Batch 500 Loss 0.6668 Accuracy 0.8697
Epoch 18 Batch 550 Loss 0.6667 Accuracy 0.8697
Epoch 18 Batch 600 Loss 0.6671 Accuracy 0.8698
Epoch 18 Batch 650 Loss 0.6678 Accuracy 0.8695
Epoch 18 Batch 700 Loss 0.6678 Accuracy 0.8695
Epoch 18 Batch 750 Loss 0.6674 Accuracy 0.8696
Epoch 18 Batch 800 Loss 0.6678 Accuracy 0.8696
Epoch 18 Batch 850 Loss 0.6680 Accuracy 0.8695
Epoch 18 Batch 900 Loss 0.6682 Accuracy 0.8694
Epoch 18 Batch 950 Loss 0.6684 Accuracy 0.8694
Epoch 18 Batch 1000 Loss 0.6692 Accuracy 0.8694
Epoch 18 Batch 1050 Loss 0.6696 Accuracy 0.8694
Epoch 18 Batch 1100 Loss 0.6704 Accuracy 0.8692
Epoch 18 Batch 1150 Loss 0.6704 Accuracy 0.8692
Epoch 18 Batch 1200 Loss 0.6709 Accuracy 0.8692
Epoch 18 Batch 1250 Loss 0.6711 Accuracy 0.8691
Epoch 18 Batch 1300 Loss 0.6713 Accuracy 0.8691
Epoch 18 Batch 1350 Loss 0.6715 Accuracy 0.8691
Epoch 18 Batch 1400 Loss 0.6720 Accuracy 0.8691
Epoch 18 Batch 1450 Loss 0.6723 Accuracy 0.8690
Epoch 18 Batch 1500 Loss 0.6725 Accuracy 0.8690
discarded batch 1525
Epoch 18 Loss 0.6727 Accuracy 0.8689
Time taken for 1 epoch: 36.06467032432556 secs

epoch lasted: 36.069453716278076
Epoch 19 Batch 0 Loss 0.6354 Accuracy 0.8804
Epoch 19 Batch 50 Loss 0.6552 Accuracy 0.8714
Epoch 19 Batch 100 Loss 0.6554 Accuracy 0.8705
Epoch 19 Batch 150 Loss 0.6551 Accuracy 0.8702
Epoch 19 Batch 200 Loss 0.6561 Accuracy 0.8705
Epoch 19 Batch 250 Loss 0.6585 Accuracy 0.8701
Epoch 19 Batch 300 Loss 0.6594 Accuracy 0.8700
Epoch 19 Batch 350 Loss 0.6585 Accuracy 0.8702
Epoch 19 Batch 400 Loss 0.6589 Accuracy 0.8703
Epoch 19 Batch 450 Loss 0.6585 Accuracy 0.8704
discarded batch 482
Epoch 19 Batch 500 Loss 0.6588 Accuracy 0.8703
Epoch 19 Batch 550 Loss 0.6599 Accuracy 0.8703
Epoch 19 Batch 600 Loss 0.6606 Accuracy 0.8702
Epoch 19 Batch 650 Loss 0.6609 Accuracy 0.8702
Epoch 19 Batch 700 Loss 0.6609 Accuracy 0.8702
Epoch 19 Batch 750 Loss 0.6612 Accuracy 0.8701
Epoch 19 Batch 800 Loss 0.6617 Accuracy 0.8701
Epoch 19 Batch 850 Loss 0.6618 Accuracy 0.8700
Epoch 19 Batch 900 Loss 0.6620 Accuracy 0.8700
Epoch 19 Batch 950 Loss 0.6621 Accuracy 0.8700
Epoch 19 Batch 1000 Loss 0.6625 Accuracy 0.8700
Epoch 19 Batch 1050 Loss 0.6628 Accuracy 0.8700
Epoch 19 Batch 1100 Loss 0.6629 Accuracy 0.8700
Epoch 19 Batch 1150 Loss 0.6632 Accuracy 0.8699
Epoch 19 Batch 1200 Loss 0.6638 Accuracy 0.8699
Epoch 19 Batch 1250 Loss 0.6639 Accuracy 0.8699
Epoch 19 Batch 1300 Loss 0.6643 Accuracy 0.8698
Epoch 19 Batch 1350 Loss 0.6646 Accuracy 0.8698
Epoch 19 Batch 1400 Loss 0.6646 Accuracy 0.8698
Epoch 19 Batch 1450 Loss 0.6649 Accuracy 0.8698
Epoch 19 Batch 1500 Loss 0.6654 Accuracy 0.8698
Epoch 19 Loss 0.6659 Accuracy 0.8697
Time taken for 1 epoch: 35.992998123168945 secs

epoch lasted: 35.99701976776123
Epoch 20 Batch 0 Loss 0.6054 Accuracy 0.8704
Epoch 20 Batch 50 Loss 0.6531 Accuracy 0.8718
Epoch 20 Batch 100 Loss 0.6529 Accuracy 0.8713
Epoch 20 Batch 150 Loss 0.6531 Accuracy 0.8710
Epoch 20 Batch 200 Loss 0.6528 Accuracy 0.8709
Epoch 20 Batch 250 Loss 0.6534 Accuracy 0.8710
Epoch 20 Batch 300 Loss 0.6545 Accuracy 0.8708
Epoch 20 Batch 350 Loss 0.6546 Accuracy 0.8708
Epoch 20 Batch 400 Loss 0.6547 Accuracy 0.8708
discarded batch 441
Epoch 20 Batch 450 Loss 0.6555 Accuracy 0.8706
Epoch 20 Batch 500 Loss 0.6559 Accuracy 0.8705
Epoch 20 Batch 550 Loss 0.6566 Accuracy 0.8705
Epoch 20 Batch 600 Loss 0.6567 Accuracy 0.8704
Epoch 20 Batch 650 Loss 0.6572 Accuracy 0.8704
Epoch 20 Batch 700 Loss 0.6570 Accuracy 0.8704
Epoch 20 Batch 750 Loss 0.6567 Accuracy 0.8705
Epoch 20 Batch 800 Loss 0.6571 Accuracy 0.8704
Epoch 20 Batch 850 Loss 0.6572 Accuracy 0.8705
Epoch 20 Batch 900 Loss 0.6574 Accuracy 0.8705
Epoch 20 Batch 950 Loss 0.6575 Accuracy 0.8705
Epoch 20 Batch 1000 Loss 0.6573 Accuracy 0.8706
Epoch 20 Batch 1050 Loss 0.6574 Accuracy 0.8706
Epoch 20 Batch 1100 Loss 0.6577 Accuracy 0.8706
Epoch 20 Batch 1150 Loss 0.6578 Accuracy 0.8706
Epoch 20 Batch 1200 Loss 0.6581 Accuracy 0.8706
Epoch 20 Batch 1250 Loss 0.6582 Accuracy 0.8706
Epoch 20 Batch 1300 Loss 0.6584 Accuracy 0.8706
Epoch 20 Batch 1350 Loss 0.6586 Accuracy 0.8706
Epoch 20 Batch 1400 Loss 0.6588 Accuracy 0.8706
Epoch 20 Batch 1450 Loss 0.6591 Accuracy 0.8706
Epoch 20 Batch 1500 Loss 0.6594 Accuracy 0.8706
Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4
Epoch 20 Loss 0.6595 Accuracy 0.8706
Time taken for 1 epoch: 36.02783989906311 secs

epoch lasted: 36.03261590003967
Epoch 21 Batch 0 Loss 0.5800 Accuracy 0.8821
Epoch 21 Batch 50 Loss 0.6376 Accuracy 0.8733
Epoch 21 Batch 100 Loss 0.6408 Accuracy 0.8725
Epoch 21 Batch 150 Loss 0.6419 Accuracy 0.8727
Epoch 21 Batch 200 Loss 0.6418 Accuracy 0.8726
Epoch 21 Batch 250 Loss 0.6423 Accuracy 0.8725
Epoch 21 Batch 300 Loss 0.6441 Accuracy 0.8724
Epoch 21 Batch 350 Loss 0.6444 Accuracy 0.8721
Epoch 21 Batch 400 Loss 0.6451 Accuracy 0.8721
Epoch 21 Batch 450 Loss 0.6465 Accuracy 0.8720
Epoch 21 Batch 500 Loss 0.6467 Accuracy 0.8720
Epoch 21 Batch 550 Loss 0.6478 Accuracy 0.8718
Epoch 21 Batch 600 Loss 0.6484 Accuracy 0.8717
Epoch 21 Batch 650 Loss 0.6492 Accuracy 0.8716
Epoch 21 Batch 700 Loss 0.6495 Accuracy 0.8716
Epoch 21 Batch 750 Loss 0.6503 Accuracy 0.8714
Epoch 21 Batch 800 Loss 0.6509 Accuracy 0.8714
Epoch 21 Batch 850 Loss 0.6508 Accuracy 0.8714
Epoch 21 Batch 900 Loss 0.6516 Accuracy 0.8714
Epoch 21 Batch 950 Loss 0.6514 Accuracy 0.8714
Epoch 21 Batch 1000 Loss 0.6520 Accuracy 0.8713
discarded batch 1029
Epoch 21 Batch 1050 Loss 0.6521 Accuracy 0.8714
Epoch 21 Batch 1100 Loss 0.6526 Accuracy 0.8714
Epoch 21 Batch 1150 Loss 0.6527 Accuracy 0.8713
Epoch 21 Batch 1200 Loss 0.6533 Accuracy 0.8713
Epoch 21 Batch 1250 Loss 0.6534 Accuracy 0.8712
Epoch 21 Batch 1300 Loss 0.6536 Accuracy 0.8712
Epoch 21 Batch 1350 Loss 0.6538 Accuracy 0.8712
Epoch 21 Batch 1400 Loss 0.6537 Accuracy 0.8712
Epoch 21 Batch 1450 Loss 0.6540 Accuracy 0.8712
Epoch 21 Batch 1500 Loss 0.6541 Accuracy 0.8712
Epoch 21 Loss 0.6544 Accuracy 0.8712
Time taken for 1 epoch: 35.91269016265869 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.7098 Accuracy 0.8671

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 e |io |co|lui |a |lui |che |tu |ti |di|vi|di|
e |io |vi|di |là |do|lor |ti |di|pin|to|
e |io |a |quel |che |li |vi|d’ io |ma|ri|no|
                                                                                                                                                                   
 co|no|stra |ca|gion |di |dio |non |ti |prie|ga|
e |io |a |lui |e |io |vi|di |lor |mo|no|
e |io |vi|di |là |o|gne |par|ti|ca|ne|
 che |tu |ve|di |co|sì |che |non |son |con|fi|na|
e |io |co|no|stro |mal |non |son |li |pa|re|
o |al|cun |che |per |lui |che |tu |ve|du|na|
o|
                                                                                                                                                                 
 e |io |a |lui |che |già |per |li |do|lo|re|
e |io |non |ti |per|ché |per |al|cun |ca|to|
e |io |a |lui |non |mo|ver |per |li |mo|re|
 che |non |ti |mo|ve|ra|vi|di |quel |ch’ i’ |na|to|
e |per |non |ca|po |per |far |non |ti |ma|ni|
ma |per |al|lor |che |non |son |na|tu|re|mo|
                                                                                                                                                                   
 e |io |a |lui |che |tu |se’ |tu |ti |mo|ni|
e |io |a |lui |che |tu |se’ |che |non |di|mo|
e |io |a |lui |non |ti |ma |non |ti |na|ni|
o |na|mo|ver |na|tu|re|gi|na|mo|ra|di|to|
ma |per |li |do|na|mo|ver |mal |na|mo|to|
e |io |a |lui |che |non |son |na|tu|na|to|
                                                                                                                                                                   
 e |a |lui |an|cor |non |ti |mo|ra|gio|na|
e |io |di|nan|zi a |noi |o |a|ni|fe|sto|
di |quel |che |già |mai |non |fa|cea |o |i|na|
 o |bi|na|mo|ve|nir |per |li |mo|ver |s’ a|mo|
e |io |non |ca|to|sto |ma|to|sto |ma|sto|
e |io |non |ti |non |ti |ma |per|so|na|mo|
                                                                                                                                                                   
 ma |non |ti |mo|ver |di |quel |che |non |mo|sto|
che |tu |se’ |tu |se’ |che |tu |se’ |tu |ca|mo|
e |io |a |lui |che |non |ti |non |ti |mo|sto|
e |io |do|lo|co |do|ve |giu|bi|li |na|tu|ra|
ma |tu |se’ |che |tu |se’ |tu |chi |son |di|to|
e |io |vi|di |quel |di |quel |che ’l |do|lo|co|
                                                                                                                                                                   
 e |se |tu |se’ |o |i|ni|ma |na|tu|na|
per |li |vi|di |là |giù |di |lor |bi|lan|co|
e |se |tu |se’ |e |io |vi|ver |di|giu|na|
o |tu |non |bi|do|po |per |lo |mo|ver |li |vol|to|
che |tu |se’ |che |già |di |lor |li |mo|ni|re|
e |io |non |ti |do|lor |ca|gion |per |el|lo|
                                                                                                                                                                   
 a |quel |di |lui |a |lui |a |dir |ca|gio|re|
e |io |non |mo|stra|da |un |fi|ni|ma |ca|
che |tu |se’ |tu |se’ |tu |sai |non |mo|re|re|
o |a |sì |o |i|bi|do|man|do|po |non |na|to|
o |a|ver |do|man|do|ve |ca|po |ca|gio|
e |io |co|lui |che |tu |se’ |tu |se’ |do|to|
                                                                                                                                                                   
 per |lui |an|cor |non |ve|nir |per |li |do|no|
e |se |non |ti |ma |per|ché |non |ti |prie|go |to|
e |per |noi |ve|ni|ma |non |ti |man|ti|
e |io |co|lui |che |non |son |io |a |mo|ver |ca|to|
che |per |ve|nir |per|ché |per |al|lor |ca|re|
ma |non |mo|ve|du|bi|li |mo|ver |ca|to|
                                                                                                                                                                   
 e |se |non |ve|nir |per |al|lor |di|par|re|
ma |per|ché |per |noi |ve|nir |con |al|cun |ca|
ma |per |al|cun |mo|ra|vi|di |quel |mo|re|
 che |tu |non |do|po |che |tu |che |non |di|mo|do|
o |ca|na|vi|di |quel |ch’ i’ |non |ti |do|na|
a |lui |che |tu |se’ |tu |ve|nir |ca|ri|do|
                                                                                                                                                                   
 o |na|mo|ver |per |lui |non |ti |ca|po |di|
per |far |non |mo|ver |per |li |di|mo|do|do|
e |io |a |noi |ve|nir |con |li al|tri |di|to|
che |non |ca|gion |che |ca|ri|spuo|se |tu |se’ |ca|ri|
e |io |non |ti |mo|ver |non |ti |do|man|do|
o |per |lui |ve|dea |a |dir |per|do|na|to|
                                                                                                                                                                   
 e |io |a |lui |a |lui |per|ché |non |do|na|
e |co|no|stro |mo|ni|ti |fa|ti|ca|to|
di |quel |che |tu |se’ |tu |se’ |non |ti |mo|na|
 e |io |e |io |a |lui |che |già |non |di|mo|ve|
ma |non |ti |ca|gion |per |lo |mo|ver |na|to|
e |io |a |lui |che |non |son |più |di|man|ca|
                                                                                                                                                                   
 e |io |non |do|po |non |ti |mo|ver |mo|to|
ma |per |li |mo|ver |con |lui |che |non |mo|ve|
ma |per|ché |tu |se’ |tu |se’ |tu |se’ |i|mo|
 o |ca|gion |che |tu |ve|di |quel |che |tu |ve|ni|
a |di|man|dar |di |quel |do|ve |ca|po |ca|
per |al|lor |ca|gion |che |non |di|nan|zi |do|
                                                                                                                                                                   
 a |lui |a |di|vi|tà |che |tu |per|do|na|
e |io |a |lui |non |ca|gion |di |quel |mo|do|
e |io |a |lui |e |io |a |lui |di|man|ti|
 o |a|ni|ma |che |non |vi|di |là |giù |giu|to|
ma |per |mo|stra|di |lor |na|mo|ver |mal |mo|
e |io |ma|ra|do|man|do|ve |ca|gio|to|
                                                                                                                                                                   
 e |io |o |o |al|lo|co |più |che |mo|na|
e |per |non |son |io |ma|ni|ma |per|so|na|
e |per |li |mo|ni|ma |per |li |no|vel|la|
 o |che |tu |se’ |che |già |per |lo |co|sì |che |mo|
o |a|ni|ma |chi |per |li |mo|ver |giu|sto|
che |tu |se’ |non |son |di |quel |che |tu |mo|to|
                                                                                                                                                                   
 e |io |non |ti |ca|ri|sto|ru|bi|ti|ca|
a |lui |non |ti |non |ti |ma |per |li |mo|ni|
e |se |non |mo|ni|ma |con |es|so |ve|ni|
o |na|tu|na|tu|na|tu|na|mo|ver |che |mo|re|
e |io |do|lor |na|tu|ra|men|ti |ca|re|
che |tu |se’ |o |i|ma|ni|bi|li |gi|ra|
                                                                                                                                                                   
 e |io |o |i|bi|li |per |al|tra |sto|ri|
per |un |giu|sti|mo|ra|vi|di |lor |mo|ra|
o |a|ni|mo|stra|va |per |al|cun |lo|ri|

epoch lasted: 526.0917296409607
(1900, 128)
Epoch 1 Batch 0 Loss 0.6190 Accuracy 0.8771
Epoch 1 Batch 50 Loss 0.6357 Accuracy 0.8738
Epoch 1 Batch 100 Loss 0.6372 Accuracy 0.8733
Epoch 1 Batch 150 Loss 0.6391 Accuracy 0.8730
Epoch 1 Batch 200 Loss 0.6394 Accuracy 0.8725
Epoch 1 Batch 250 Loss 0.6396 Accuracy 0.8724
Epoch 1 Batch 300 Loss 0.6410 Accuracy 0.8723
Epoch 1 Batch 350 Loss 0.6412 Accuracy 0.8724
Epoch 1 Batch 400 Loss 0.6421 Accuracy 0.8725
Epoch 1 Batch 450 Loss 0.6419 Accuracy 0.8726
Epoch 1 Batch 500 Loss 0.6415 Accuracy 0.8726
Epoch 1 Batch 550 Loss 0.6438 Accuracy 0.8723
Epoch 1 Batch 600 Loss 0.6436 Accuracy 0.8723
Epoch 1 Batch 650 Loss 0.6444 Accuracy 0.8722
Epoch 1 Batch 700 Loss 0.6446 Accuracy 0.8723
Epoch 1 Batch 750 Loss 0.6444 Accuracy 0.8723
discarded batch 778
Epoch 1 Batch 800 Loss 0.6446 Accuracy 0.8723
Epoch 1 Batch 850 Loss 0.6448 Accuracy 0.8722
Epoch 1 Batch 900 Loss 0.6449 Accuracy 0.8722
Epoch 1 Batch 950 Loss 0.6453 Accuracy 0.8721
Epoch 1 Batch 1000 Loss 0.6454 Accuracy 0.8721
Epoch 1 Batch 1050 Loss 0.6459 Accuracy 0.8720
Epoch 1 Batch 1100 Loss 0.6460 Accuracy 0.8720
Epoch 1 Batch 1150 Loss 0.6462 Accuracy 0.8720
Epoch 1 Batch 1200 Loss 0.6465 Accuracy 0.8719
Epoch 1 Batch 1250 Loss 0.6471 Accuracy 0.8718
Epoch 1 Batch 1300 Loss 0.6476 Accuracy 0.8718
Epoch 1 Batch 1350 Loss 0.6480 Accuracy 0.8718
Epoch 1 Batch 1400 Loss 0.6486 Accuracy 0.8717
Epoch 1 Batch 1450 Loss 0.6488 Accuracy 0.8717
Epoch 1 Batch 1500 Loss 0.6490 Accuracy 0.8717

wandb: WARNING Step must only increase in log calls.  Step 1 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.64948803>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8716662>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 22; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.71207494>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8666667>}.

Epoch 1 Loss 0.6495 Accuracy 0.8717
Time taken for 1 epoch: 36.00280046463013 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.7121 Accuracy 0.8667

epoch lasted: 36.15464782714844
Epoch 2 Batch 0 Loss 0.6070 Accuracy 0.8804
Epoch 2 Batch 50 Loss 0.6257 Accuracy 0.8749
Epoch 2 Batch 100 Loss 0.6298 Accuracy 0.8737
Epoch 2 Batch 150 Loss 0.6288 Accuracy 0.8743
Epoch 2 Batch 200 Loss 0.6260 Accuracy 0.8745
Epoch 2 Batch 250 Loss 0.6286 Accuracy 0.8743
Epoch 2 Batch 300 Loss 0.6299 Accuracy 0.8741
Epoch 2 Batch 350 Loss 0.6303 Accuracy 0.8741
Epoch 2 Batch 400 Loss 0.6313 Accuracy 0.8740
Epoch 2 Batch 450 Loss 0.6325 Accuracy 0.8738
Epoch 2 Batch 500 Loss 0.6342 Accuracy 0.8736
Epoch 2 Batch 550 Loss 0.6345 Accuracy 0.8736
Epoch 2 Batch 600 Loss 0.6358 Accuracy 0.8734
discarded batch 644
Epoch 2 Batch 650 Loss 0.6364 Accuracy 0.8734
Epoch 2 Batch 700 Loss 0.6369 Accuracy 0.8734
Epoch 2 Batch 750 Loss 0.6374 Accuracy 0.8733
Epoch 2 Batch 800 Loss 0.6381 Accuracy 0.8732
Epoch 2 Batch 850 Loss 0.6382 Accuracy 0.8731
Epoch 2 Batch 900 Loss 0.6381 Accuracy 0.8731
Epoch 2 Batch 950 Loss 0.6388 Accuracy 0.8730
Epoch 2 Batch 1000 Loss 0.6390 Accuracy 0.8730
Epoch 2 Batch 1050 Loss 0.6391 Accuracy 0.8730
Epoch 2 Batch 1100 Loss 0.6393 Accuracy 0.8730
Epoch 2 Batch 1150 Loss 0.6394 Accuracy 0.8730
Epoch 2 Batch 1200 Loss 0.6398 Accuracy 0.8729
Epoch 2 Batch 1250 Loss 0.6404 Accuracy 0.8728
Epoch 2 Batch 1300 Loss 0.6409 Accuracy 0.8728
Epoch 2 Batch 1350 Loss 0.6411 Accuracy 0.8728
Epoch 2 Batch 1400 Loss 0.6414 Accuracy 0.8727
Epoch 2 Batch 1450 Loss 0.6425 Accuracy 0.8726
Epoch 2 Batch 1500 Loss 0.6430 Accuracy 0.8725

wandb: WARNING Step must only increase in log calls.  Step 2 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6434059>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8724791>}.

Epoch 2 Loss 0.6434 Accuracy 0.8725
Time taken for 1 epoch: 36.06069731712341 secs

epoch lasted: 36.06484818458557
Epoch 3 Batch 0 Loss 0.6705 Accuracy 0.8654
Epoch 3 Batch 50 Loss 0.6221 Accuracy 0.8751
Epoch 3 Batch 100 Loss 0.6207 Accuracy 0.8752
Epoch 3 Batch 150 Loss 0.6196 Accuracy 0.8754
Epoch 3 Batch 200 Loss 0.6190 Accuracy 0.8755
Epoch 3 Batch 250 Loss 0.6214 Accuracy 0.8753
Epoch 3 Batch 300 Loss 0.6227 Accuracy 0.8748
discarded batch 346
Epoch 3 Batch 350 Loss 0.6247 Accuracy 0.8745
Epoch 3 Batch 400 Loss 0.6262 Accuracy 0.8744
Epoch 3 Batch 450 Loss 0.6269 Accuracy 0.8745
Epoch 3 Batch 500 Loss 0.6281 Accuracy 0.8743
Epoch 3 Batch 550 Loss 0.6292 Accuracy 0.8742
Epoch 3 Batch 600 Loss 0.6295 Accuracy 0.8741
Epoch 3 Batch 650 Loss 0.6303 Accuracy 0.8742
Epoch 3 Batch 700 Loss 0.6312 Accuracy 0.8740
Epoch 3 Batch 750 Loss 0.6316 Accuracy 0.8740
Epoch 3 Batch 800 Loss 0.6318 Accuracy 0.8739
Epoch 3 Batch 850 Loss 0.6327 Accuracy 0.8737
Epoch 3 Batch 900 Loss 0.6329 Accuracy 0.8737
Epoch 3 Batch 950 Loss 0.6330 Accuracy 0.8737
Epoch 3 Batch 1000 Loss 0.6336 Accuracy 0.8736
Epoch 3 Batch 1050 Loss 0.6340 Accuracy 0.8735
Epoch 3 Batch 1100 Loss 0.6350 Accuracy 0.8734
Epoch 3 Batch 1150 Loss 0.6350 Accuracy 0.8734
Epoch 3 Batch 1200 Loss 0.6352 Accuracy 0.8734
Epoch 3 Batch 1250 Loss 0.6356 Accuracy 0.8733
Epoch 3 Batch 1300 Loss 0.6365 Accuracy 0.8732
Epoch 3 Batch 1350 Loss 0.6367 Accuracy 0.8732
Epoch 3 Batch 1400 Loss 0.6373 Accuracy 0.8731
Epoch 3 Batch 1450 Loss 0.6378 Accuracy 0.8730
Epoch 3 Batch 1500 Loss 0.6381 Accuracy 0.8730

wandb: WARNING Step must only increase in log calls.  Step 3 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6381181>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.87293804>}.

Epoch 3 Loss 0.6381 Accuracy 0.8729
Time taken for 1 epoch: 36.94047451019287 secs

epoch lasted: 36.94479465484619
Epoch 4 Batch 0 Loss 0.6422 Accuracy 0.8771
Epoch 4 Batch 50 Loss 0.6214 Accuracy 0.8748
Epoch 4 Batch 100 Loss 0.6246 Accuracy 0.8744
Epoch 4 Batch 150 Loss 0.6241 Accuracy 0.8747
Epoch 4 Batch 200 Loss 0.6242 Accuracy 0.8747
Epoch 4 Batch 250 Loss 0.6247 Accuracy 0.8747
Epoch 4 Batch 300 Loss 0.6255 Accuracy 0.8745
Epoch 4 Batch 350 Loss 0.6258 Accuracy 0.8746
Epoch 4 Batch 400 Loss 0.6254 Accuracy 0.8747
Epoch 4 Batch 450 Loss 0.6260 Accuracy 0.8745
Epoch 4 Batch 500 Loss 0.6256 Accuracy 0.8745
Epoch 4 Batch 550 Loss 0.6261 Accuracy 0.8744
Epoch 4 Batch 600 Loss 0.6264 Accuracy 0.8745
Epoch 4 Batch 650 Loss 0.6268 Accuracy 0.8744
Epoch 4 Batch 700 Loss 0.6271 Accuracy 0.8743
Epoch 4 Batch 750 Loss 0.6275 Accuracy 0.8743
Epoch 4 Batch 800 Loss 0.6279 Accuracy 0.8743
Epoch 4 Batch 850 Loss 0.6281 Accuracy 0.8742
Epoch 4 Batch 900 Loss 0.6287 Accuracy 0.8741
Epoch 4 Batch 950 Loss 0.6286 Accuracy 0.8742
Epoch 4 Batch 1000 Loss 0.6293 Accuracy 0.8741
Epoch 4 Batch 1050 Loss 0.6295 Accuracy 0.8740
Epoch 4 Batch 1100 Loss 0.6298 Accuracy 0.8739
discarded batch 1116
Epoch 4 Batch 1150 Loss 0.6301 Accuracy 0.8740
Epoch 4 Batch 1200 Loss 0.6305 Accuracy 0.8740
Epoch 4 Batch 1250 Loss 0.6307 Accuracy 0.8739
Epoch 4 Batch 1300 Loss 0.6313 Accuracy 0.8739
Epoch 4 Batch 1350 Loss 0.6316 Accuracy 0.8739
Epoch 4 Batch 1400 Loss 0.6318 Accuracy 0.8739
Epoch 4 Batch 1450 Loss 0.6323 Accuracy 0.8738
Epoch 4 Batch 1500 Loss 0.6327 Accuracy 0.8738

wandb: WARNING Step must only increase in log calls.  Step 4 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6327451>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.87374127>}.

Epoch 4 Loss 0.6327 Accuracy 0.8737
Time taken for 1 epoch: 36.338770151138306 secs

epoch lasted: 36.3428738117218
Epoch 5 Batch 0 Loss 0.6314 Accuracy 0.8671
Epoch 5 Batch 50 Loss 0.6115 Accuracy 0.8760
Epoch 5 Batch 100 Loss 0.6147 Accuracy 0.8754
Epoch 5 Batch 150 Loss 0.6164 Accuracy 0.8753
Epoch 5 Batch 200 Loss 0.6192 Accuracy 0.8750
Epoch 5 Batch 250 Loss 0.6197 Accuracy 0.8752
Epoch 5 Batch 300 Loss 0.6202 Accuracy 0.8750
Epoch 5 Batch 350 Loss 0.6212 Accuracy 0.8751
Epoch 5 Batch 400 Loss 0.6207 Accuracy 0.8752
Epoch 5 Batch 450 Loss 0.6210 Accuracy 0.8752
Epoch 5 Batch 500 Loss 0.6219 Accuracy 0.8750
Epoch 5 Batch 550 Loss 0.6219 Accuracy 0.8749
Epoch 5 Batch 600 Loss 0.6215 Accuracy 0.8751
Epoch 5 Batch 650 Loss 0.6218 Accuracy 0.8751
Epoch 5 Batch 700 Loss 0.6218 Accuracy 0.8751
Epoch 5 Batch 750 Loss 0.6223 Accuracy 0.8750
Epoch 5 Batch 800 Loss 0.6229 Accuracy 0.8749
discarded batch 836
Epoch 5 Batch 850 Loss 0.6232 Accuracy 0.8749
Epoch 5 Batch 900 Loss 0.6235 Accuracy 0.8749
Epoch 5 Batch 950 Loss 0.6238 Accuracy 0.8749
Epoch 5 Batch 1000 Loss 0.6247 Accuracy 0.8748
Epoch 5 Batch 1050 Loss 0.6249 Accuracy 0.8748
Epoch 5 Batch 1100 Loss 0.6250 Accuracy 0.8748
Epoch 5 Batch 1150 Loss 0.6252 Accuracy 0.8747
Epoch 5 Batch 1200 Loss 0.6255 Accuracy 0.8747
Epoch 5 Batch 1250 Loss 0.6257 Accuracy 0.8746
Epoch 5 Batch 1300 Loss 0.6261 Accuracy 0.8745
Epoch 5 Batch 1350 Loss 0.6270 Accuracy 0.8744
Epoch 5 Batch 1400 Loss 0.6273 Accuracy 0.8744
Epoch 5 Batch 1450 Loss 0.6277 Accuracy 0.8743
Epoch 5 Batch 1500 Loss 0.6278 Accuracy 0.8744

wandb: WARNING Step must only increase in log calls.  Step 5 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6278807>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.87430966>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-5
Epoch 5 Loss 0.6279 Accuracy 0.8743
Time taken for 1 epoch: 36.09310746192932 secs

epoch lasted: 36.097331285476685
Epoch 6 Batch 0 Loss 0.6428 Accuracy 0.8804
Epoch 6 Batch 50 Loss 0.6116 Accuracy 0.8770
Epoch 6 Batch 100 Loss 0.6136 Accuracy 0.8770
Epoch 6 Batch 150 Loss 0.6143 Accuracy 0.8765
Epoch 6 Batch 200 Loss 0.6142 Accuracy 0.8764
Epoch 6 Batch 250 Loss 0.6130 Accuracy 0.8765
Epoch 6 Batch 300 Loss 0.6135 Accuracy 0.8763
Epoch 6 Batch 350 Loss 0.6130 Accuracy 0.8762
Epoch 6 Batch 400 Loss 0.6141 Accuracy 0.8761
discarded batch 404
Epoch 6 Batch 450 Loss 0.6149 Accuracy 0.8762
Epoch 6 Batch 500 Loss 0.6158 Accuracy 0.8761
Epoch 6 Batch 550 Loss 0.6164 Accuracy 0.8759
Epoch 6 Batch 600 Loss 0.6166 Accuracy 0.8758
Epoch 6 Batch 650 Loss 0.6172 Accuracy 0.8757
Epoch 6 Batch 700 Loss 0.6175 Accuracy 0.8757
Epoch 6 Batch 750 Loss 0.6177 Accuracy 0.8756
Epoch 6 Batch 800 Loss 0.6184 Accuracy 0.8756
Epoch 6 Batch 850 Loss 0.6187 Accuracy 0.8755
Epoch 6 Batch 900 Loss 0.6188 Accuracy 0.8755
Epoch 6 Batch 950 Loss 0.6190 Accuracy 0.8755
Epoch 6 Batch 1000 Loss 0.6195 Accuracy 0.8754
Epoch 6 Batch 1050 Loss 0.6201 Accuracy 0.8753
Epoch 6 Batch 1100 Loss 0.6205 Accuracy 0.8752
Epoch 6 Batch 1150 Loss 0.6205 Accuracy 0.8753
Epoch 6 Batch 1200 Loss 0.6207 Accuracy 0.8752
Epoch 6 Batch 1250 Loss 0.6213 Accuracy 0.8752
Epoch 6 Batch 1300 Loss 0.6218 Accuracy 0.8751
Epoch 6 Batch 1350 Loss 0.6221 Accuracy 0.8751
Epoch 6 Batch 1400 Loss 0.6222 Accuracy 0.8750
Epoch 6 Batch 1450 Loss 0.6225 Accuracy 0.8750
Epoch 6 Batch 1500 Loss 0.6228 Accuracy 0.8750

wandb: WARNING Step must only increase in log calls.  Step 6 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6229424>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8749359>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 22; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.7154719>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8671097>}.

Epoch 6 Loss 0.6229 Accuracy 0.8749
Time taken for 1 epoch: 35.86969876289368 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.7155 Accuracy 0.8671

epoch lasted: 36.023354291915894
Epoch 7 Batch 0 Loss 0.5863 Accuracy 0.8654
Epoch 7 Batch 50 Loss 0.6106 Accuracy 0.8762
Epoch 7 Batch 100 Loss 0.6051 Accuracy 0.8773
Epoch 7 Batch 150 Loss 0.6053 Accuracy 0.8772
Epoch 7 Batch 200 Loss 0.6036 Accuracy 0.8775
Epoch 7 Batch 250 Loss 0.6022 Accuracy 0.8777
Epoch 7 Batch 300 Loss 0.6027 Accuracy 0.8777
Epoch 7 Batch 350 Loss 0.6038 Accuracy 0.8774
Epoch 7 Batch 400 Loss 0.6056 Accuracy 0.8772
Epoch 7 Batch 450 Loss 0.6068 Accuracy 0.8771
discarded batch 492
Epoch 7 Batch 500 Loss 0.6078 Accuracy 0.8769
Epoch 7 Batch 550 Loss 0.6091 Accuracy 0.8768
Epoch 7 Batch 600 Loss 0.6096 Accuracy 0.8768
Epoch 7 Batch 650 Loss 0.6105 Accuracy 0.8766
Epoch 7 Batch 700 Loss 0.6110 Accuracy 0.8765
Epoch 7 Batch 750 Loss 0.6118 Accuracy 0.8764
Epoch 7 Batch 800 Loss 0.6124 Accuracy 0.8765
Epoch 7 Batch 850 Loss 0.6130 Accuracy 0.8764
Epoch 7 Batch 900 Loss 0.6134 Accuracy 0.8764
Epoch 7 Batch 950 Loss 0.6139 Accuracy 0.8763
Epoch 7 Batch 1000 Loss 0.6144 Accuracy 0.8762
Epoch 7 Batch 1050 Loss 0.6149 Accuracy 0.8762
Epoch 7 Batch 1100 Loss 0.6153 Accuracy 0.8762
Epoch 7 Batch 1150 Loss 0.6156 Accuracy 0.8761
Epoch 7 Batch 1200 Loss 0.6159 Accuracy 0.8761
Epoch 7 Batch 1250 Loss 0.6165 Accuracy 0.8760
Epoch 7 Batch 1300 Loss 0.6169 Accuracy 0.8760
Epoch 7 Batch 1350 Loss 0.6171 Accuracy 0.8759
Epoch 7 Batch 1400 Loss 0.6172 Accuracy 0.8759
Epoch 7 Batch 1450 Loss 0.6177 Accuracy 0.8759
Epoch 7 Batch 1500 Loss 0.6180 Accuracy 0.8758

wandb: WARNING Step must only increase in log calls.  Step 7 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.61811376>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8757874>}.

Epoch 7 Loss 0.6181 Accuracy 0.8758
Time taken for 1 epoch: 35.9515585899353 secs

epoch lasted: 35.95582318305969
Epoch 8 Batch 0 Loss 0.5856 Accuracy 0.8837
Epoch 8 Batch 50 Loss 0.5992 Accuracy 0.8768
Epoch 8 Batch 100 Loss 0.6021 Accuracy 0.8765
Epoch 8 Batch 150 Loss 0.6031 Accuracy 0.8768
Epoch 8 Batch 200 Loss 0.6024 Accuracy 0.8772
Epoch 8 Batch 250 Loss 0.6044 Accuracy 0.8772
Epoch 8 Batch 300 Loss 0.6044 Accuracy 0.8774
Epoch 8 Batch 350 Loss 0.6050 Accuracy 0.8771
Epoch 8 Batch 400 Loss 0.6054 Accuracy 0.8771
Epoch 8 Batch 450 Loss 0.6062 Accuracy 0.8770
Epoch 8 Batch 500 Loss 0.6056 Accuracy 0.8770
Epoch 8 Batch 550 Loss 0.6057 Accuracy 0.8771
Epoch 8 Batch 600 Loss 0.6069 Accuracy 0.8770
Epoch 8 Batch 650 Loss 0.6077 Accuracy 0.8770
Epoch 8 Batch 700 Loss 0.6078 Accuracy 0.8769
Epoch 8 Batch 750 Loss 0.6079 Accuracy 0.8769
Epoch 8 Batch 800 Loss 0.6086 Accuracy 0.8767
Epoch 8 Batch 850 Loss 0.6092 Accuracy 0.8767
Epoch 8 Batch 900 Loss 0.6101 Accuracy 0.8765
Epoch 8 Batch 950 Loss 0.6101 Accuracy 0.8765
Epoch 8 Batch 1000 Loss 0.6102 Accuracy 0.8766
Epoch 8 Batch 1050 Loss 0.6109 Accuracy 0.8765
Epoch 8 Batch 1100 Loss 0.6114 Accuracy 0.8765
discarded batch 1109
Epoch 8 Batch 1150 Loss 0.6117 Accuracy 0.8765
Epoch 8 Batch 1200 Loss 0.6119 Accuracy 0.8765
Epoch 8 Batch 1250 Loss 0.6125 Accuracy 0.8764
Epoch 8 Batch 1300 Loss 0.6129 Accuracy 0.8764
Epoch 8 Batch 1350 Loss 0.6128 Accuracy 0.8764
Epoch 8 Batch 1400 Loss 0.6135 Accuracy 0.8762
Epoch 8 Batch 1450 Loss 0.6136 Accuracy 0.8763
Epoch 8 Batch 1500 Loss 0.6138 Accuracy 0.8763

wandb: WARNING Step must only increase in log calls.  Step 8 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.61391777>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8762582>}.

Epoch 8 Loss 0.6139 Accuracy 0.8763
Time taken for 1 epoch: 35.884702920913696 secs

epoch lasted: 35.88913559913635
Epoch 9 Batch 0 Loss 0.5578 Accuracy 0.8787
Epoch 9 Batch 50 Loss 0.5854 Accuracy 0.8799
Epoch 9 Batch 100 Loss 0.5886 Accuracy 0.8797
discarded batch 130
Epoch 9 Batch 150 Loss 0.5910 Accuracy 0.8796
Epoch 9 Batch 200 Loss 0.5940 Accuracy 0.8789
Epoch 9 Batch 250 Loss 0.5952 Accuracy 0.8785
Epoch 9 Batch 300 Loss 0.5959 Accuracy 0.8783
Epoch 9 Batch 350 Loss 0.5978 Accuracy 0.8781
Epoch 9 Batch 400 Loss 0.5979 Accuracy 0.8781
Epoch 9 Batch 450 Loss 0.5987 Accuracy 0.8780
Epoch 9 Batch 500 Loss 0.5994 Accuracy 0.8779
Epoch 9 Batch 550 Loss 0.6001 Accuracy 0.8779
Epoch 9 Batch 600 Loss 0.6006 Accuracy 0.8777
Epoch 9 Batch 650 Loss 0.6014 Accuracy 0.8774
Epoch 9 Batch 700 Loss 0.6019 Accuracy 0.8774
Epoch 9 Batch 750 Loss 0.6025 Accuracy 0.8774
Epoch 9 Batch 800 Loss 0.6028 Accuracy 0.8774
Epoch 9 Batch 850 Loss 0.6032 Accuracy 0.8773
Epoch 9 Batch 900 Loss 0.6040 Accuracy 0.8772
Epoch 9 Batch 950 Loss 0.6045 Accuracy 0.8771
Epoch 9 Batch 1000 Loss 0.6048 Accuracy 0.8771
Epoch 9 Batch 1050 Loss 0.6050 Accuracy 0.8771
Epoch 9 Batch 1100 Loss 0.6056 Accuracy 0.8771
Epoch 9 Batch 1150 Loss 0.6061 Accuracy 0.8771
Epoch 9 Batch 1200 Loss 0.6066 Accuracy 0.8770
Epoch 9 Batch 1250 Loss 0.6071 Accuracy 0.8770
Epoch 9 Batch 1300 Loss 0.6071 Accuracy 0.8770
Epoch 9 Batch 1350 Loss 0.6077 Accuracy 0.8769
Epoch 9 Batch 1400 Loss 0.6077 Accuracy 0.8769
Epoch 9 Batch 1450 Loss 0.6079 Accuracy 0.8769
Epoch 9 Batch 1500 Loss 0.6084 Accuracy 0.8769

wandb: WARNING Step must only increase in log calls.  Step 9 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6088026>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.876848>}.

Epoch 9 Loss 0.6088 Accuracy 0.8768
Time taken for 1 epoch: 35.903698444366455 secs

epoch lasted: 35.90786266326904
Epoch 10 Batch 0 Loss 0.5635 Accuracy 0.8837
discarded batch 24
Epoch 10 Batch 50 Loss 0.5889 Accuracy 0.8788
Epoch 10 Batch 100 Loss 0.5914 Accuracy 0.8787
Epoch 10 Batch 150 Loss 0.5917 Accuracy 0.8790
Epoch 10 Batch 200 Loss 0.5936 Accuracy 0.8788
Epoch 10 Batch 250 Loss 0.5925 Accuracy 0.8789
Epoch 10 Batch 300 Loss 0.5933 Accuracy 0.8788
Epoch 10 Batch 350 Loss 0.5961 Accuracy 0.8784
Epoch 10 Batch 400 Loss 0.5975 Accuracy 0.8782
Epoch 10 Batch 450 Loss 0.5981 Accuracy 0.8781
Epoch 10 Batch 500 Loss 0.5980 Accuracy 0.8782
Epoch 10 Batch 550 Loss 0.5987 Accuracy 0.8782
Epoch 10 Batch 600 Loss 0.5988 Accuracy 0.8782
Epoch 10 Batch 650 Loss 0.5996 Accuracy 0.8782
Epoch 10 Batch 700 Loss 0.6002 Accuracy 0.8782
Epoch 10 Batch 750 Loss 0.6006 Accuracy 0.8781
Epoch 10 Batch 800 Loss 0.6003 Accuracy 0.8781
Epoch 10 Batch 850 Loss 0.6008 Accuracy 0.8779
Epoch 10 Batch 900 Loss 0.6009 Accuracy 0.8779
Epoch 10 Batch 950 Loss 0.6008 Accuracy 0.8779
Epoch 10 Batch 1000 Loss 0.6012 Accuracy 0.8779
Epoch 10 Batch 1050 Loss 0.6015 Accuracy 0.8779
Epoch 10 Batch 1100 Loss 0.6019 Accuracy 0.8779
Epoch 10 Batch 1150 Loss 0.6021 Accuracy 0.8778
Epoch 10 Batch 1200 Loss 0.6022 Accuracy 0.8777
Epoch 10 Batch 1250 Loss 0.6027 Accuracy 0.8777
Epoch 10 Batch 1300 Loss 0.6031 Accuracy 0.8776
Epoch 10 Batch 1350 Loss 0.6034 Accuracy 0.8776
Epoch 10 Batch 1400 Loss 0.6038 Accuracy 0.8776
Epoch 10 Batch 1450 Loss 0.6044 Accuracy 0.8775
Epoch 10 Batch 1500 Loss 0.6048 Accuracy 0.8774

wandb: WARNING Step must only increase in log calls.  Step 10 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.60493946>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8774196>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-6
Epoch 10 Loss 0.6049 Accuracy 0.8774
Time taken for 1 epoch: 36.50587511062622 secs

epoch lasted: 36.50994277000427
Epoch 11 Batch 0 Loss 0.6345 Accuracy 0.8854
Epoch 11 Batch 50 Loss 0.5822 Accuracy 0.8800
Epoch 11 Batch 100 Loss 0.5808 Accuracy 0.8798
Epoch 11 Batch 150 Loss 0.5859 Accuracy 0.8792
Epoch 11 Batch 200 Loss 0.5884 Accuracy 0.8789
Epoch 11 Batch 250 Loss 0.5885 Accuracy 0.8788
Epoch 11 Batch 300 Loss 0.5890 Accuracy 0.8789
Epoch 11 Batch 350 Loss 0.5891 Accuracy 0.8791
Epoch 11 Batch 400 Loss 0.5906 Accuracy 0.8788
Epoch 11 Batch 450 Loss 0.5912 Accuracy 0.8787
Epoch 11 Batch 500 Loss 0.5914 Accuracy 0.8787
Epoch 11 Batch 550 Loss 0.5915 Accuracy 0.8789
Epoch 11 Batch 600 Loss 0.5922 Accuracy 0.8788
Epoch 11 Batch 650 Loss 0.5929 Accuracy 0.8787
discarded batch 681
Epoch 11 Batch 700 Loss 0.5934 Accuracy 0.8785
Epoch 11 Batch 750 Loss 0.5942 Accuracy 0.8784
Epoch 11 Batch 800 Loss 0.5949 Accuracy 0.8785
Epoch 11 Batch 850 Loss 0.5950 Accuracy 0.8784
Epoch 11 Batch 900 Loss 0.5954 Accuracy 0.8783
Epoch 11 Batch 950 Loss 0.5956 Accuracy 0.8783
Epoch 11 Batch 1000 Loss 0.5960 Accuracy 0.8783
Epoch 11 Batch 1050 Loss 0.5964 Accuracy 0.8782
Epoch 11 Batch 1100 Loss 0.5967 Accuracy 0.8782
Epoch 11 Batch 1150 Loss 0.5972 Accuracy 0.8781
Epoch 11 Batch 1200 Loss 0.5980 Accuracy 0.8780
Epoch 11 Batch 1250 Loss 0.5980 Accuracy 0.8779
Epoch 11 Batch 1300 Loss 0.5984 Accuracy 0.8780
Epoch 11 Batch 1350 Loss 0.5987 Accuracy 0.8779
Epoch 11 Batch 1400 Loss 0.5994 Accuracy 0.8779
Epoch 11 Batch 1450 Loss 0.5994 Accuracy 0.8779
Epoch 11 Batch 1500 Loss 0.5997 Accuracy 0.8779

wandb: WARNING Step must only increase in log calls.  Step 11 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.6004312>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8778153>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 22; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.7205775>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.866999>}.

Epoch 11 Loss 0.6004 Accuracy 0.8778
Time taken for 1 epoch: 36.31729483604431 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.7206 Accuracy 0.8670

epoch lasted: 36.477004289627075
Epoch 12 Batch 0 Loss 0.5725 Accuracy 0.8937
Epoch 12 Batch 50 Loss 0.5779 Accuracy 0.8824
Epoch 12 Batch 100 Loss 0.5794 Accuracy 0.8812
Epoch 12 Batch 150 Loss 0.5813 Accuracy 0.8809
Epoch 12 Batch 200 Loss 0.5827 Accuracy 0.8807
Epoch 12 Batch 250 Loss 0.5840 Accuracy 0.8804
Epoch 12 Batch 300 Loss 0.5840 Accuracy 0.8804
Epoch 12 Batch 350 Loss 0.5842 Accuracy 0.8803
Epoch 12 Batch 400 Loss 0.5851 Accuracy 0.8800
Epoch 12 Batch 450 Loss 0.5854 Accuracy 0.8799
Epoch 12 Batch 500 Loss 0.5862 Accuracy 0.8798
Epoch 12 Batch 550 Loss 0.5869 Accuracy 0.8797
Epoch 12 Batch 600 Loss 0.5868 Accuracy 0.8798
Epoch 12 Batch 650 Loss 0.5870 Accuracy 0.8798
Epoch 12 Batch 700 Loss 0.5878 Accuracy 0.8797
Epoch 12 Batch 750 Loss 0.5881 Accuracy 0.8796
Epoch 12 Batch 800 Loss 0.5890 Accuracy 0.8795
Epoch 12 Batch 850 Loss 0.5896 Accuracy 0.8794
Epoch 12 Batch 900 Loss 0.5901 Accuracy 0.8794
Epoch 12 Batch 950 Loss 0.5902 Accuracy 0.8794
Epoch 12 Batch 1000 Loss 0.5905 Accuracy 0.8794
Epoch 12 Batch 1050 Loss 0.5912 Accuracy 0.8793
Epoch 12 Batch 1100 Loss 0.5918 Accuracy 0.8792
Epoch 12 Batch 1150 Loss 0.5922 Accuracy 0.8791
Epoch 12 Batch 1200 Loss 0.5923 Accuracy 0.8791
Epoch 12 Batch 1250 Loss 0.5929 Accuracy 0.8790
Epoch 12 Batch 1300 Loss 0.5934 Accuracy 0.8789
Epoch 12 Batch 1350 Loss 0.5941 Accuracy 0.8788
discarded batch 1386
Epoch 12 Batch 1400 Loss 0.5942 Accuracy 0.8788
Epoch 12 Batch 1450 Loss 0.5944 Accuracy 0.8788
Epoch 12 Batch 1500 Loss 0.5948 Accuracy 0.8787

wandb: WARNING Step must only increase in log calls.  Step 12 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5953422>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8786442>}.

Epoch 12 Loss 0.5953 Accuracy 0.8786
Time taken for 1 epoch: 35.887856006622314 secs

epoch lasted: 35.89243292808533
Epoch 13 Batch 0 Loss 0.5619 Accuracy 0.8821
Epoch 13 Batch 50 Loss 0.5708 Accuracy 0.8810
Epoch 13 Batch 100 Loss 0.5729 Accuracy 0.8812
Epoch 13 Batch 150 Loss 0.5733 Accuracy 0.8811
discarded batch 183
Epoch 13 Batch 200 Loss 0.5756 Accuracy 0.8812
Epoch 13 Batch 250 Loss 0.5769 Accuracy 0.8812
Epoch 13 Batch 300 Loss 0.5768 Accuracy 0.8809
Epoch 13 Batch 350 Loss 0.5783 Accuracy 0.8806
Epoch 13 Batch 400 Loss 0.5783 Accuracy 0.8807
Epoch 13 Batch 450 Loss 0.5794 Accuracy 0.8806
Epoch 13 Batch 500 Loss 0.5808 Accuracy 0.8804
Epoch 13 Batch 550 Loss 0.5819 Accuracy 0.8802
Epoch 13 Batch 600 Loss 0.5827 Accuracy 0.8800
Epoch 13 Batch 650 Loss 0.5831 Accuracy 0.8799
Epoch 13 Batch 700 Loss 0.5835 Accuracy 0.8799
Epoch 13 Batch 750 Loss 0.5840 Accuracy 0.8798
Epoch 13 Batch 800 Loss 0.5844 Accuracy 0.8798
Epoch 13 Batch 850 Loss 0.5848 Accuracy 0.8798
Epoch 13 Batch 900 Loss 0.5850 Accuracy 0.8797
Epoch 13 Batch 950 Loss 0.5856 Accuracy 0.8796
Epoch 13 Batch 1000 Loss 0.5859 Accuracy 0.8796
Epoch 13 Batch 1050 Loss 0.5866 Accuracy 0.8795
Epoch 13 Batch 1100 Loss 0.5870 Accuracy 0.8795
Epoch 13 Batch 1150 Loss 0.5877 Accuracy 0.8794
Epoch 13 Batch 1200 Loss 0.5885 Accuracy 0.8793
Epoch 13 Batch 1250 Loss 0.5890 Accuracy 0.8792
Epoch 13 Batch 1300 Loss 0.5895 Accuracy 0.8792
Epoch 13 Batch 1350 Loss 0.5897 Accuracy 0.8792
Epoch 13 Batch 1400 Loss 0.5901 Accuracy 0.8791
Epoch 13 Batch 1450 Loss 0.5907 Accuracy 0.8790
Epoch 13 Batch 1500 Loss 0.5912 Accuracy 0.8790

wandb: WARNING Step must only increase in log calls.  Step 13 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5916443>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.87897134>}.

Epoch 13 Loss 0.5916 Accuracy 0.8790
Time taken for 1 epoch: 36.13112497329712 secs

epoch lasted: 36.13578534126282
Epoch 14 Batch 0 Loss 0.5543 Accuracy 0.8837
Epoch 14 Batch 50 Loss 0.5706 Accuracy 0.8817
Epoch 14 Batch 100 Loss 0.5714 Accuracy 0.8814
Epoch 14 Batch 150 Loss 0.5707 Accuracy 0.8816
Epoch 14 Batch 200 Loss 0.5727 Accuracy 0.8814
Epoch 14 Batch 250 Loss 0.5724 Accuracy 0.8815
Epoch 14 Batch 300 Loss 0.5727 Accuracy 0.8816
Epoch 14 Batch 350 Loss 0.5734 Accuracy 0.8815
Epoch 14 Batch 400 Loss 0.5732 Accuracy 0.8816
Epoch 14 Batch 450 Loss 0.5735 Accuracy 0.8816
Epoch 14 Batch 500 Loss 0.5740 Accuracy 0.8815
Epoch 14 Batch 550 Loss 0.5744 Accuracy 0.8814
Epoch 14 Batch 600 Loss 0.5762 Accuracy 0.8812
discarded batch 617
Epoch 14 Batch 650 Loss 0.5772 Accuracy 0.8811
Epoch 14 Batch 700 Loss 0.5783 Accuracy 0.8810
Epoch 14 Batch 750 Loss 0.5791 Accuracy 0.8808
Epoch 14 Batch 800 Loss 0.5799 Accuracy 0.8807
Epoch 14 Batch 850 Loss 0.5809 Accuracy 0.8805
Epoch 14 Batch 900 Loss 0.5812 Accuracy 0.8805
Epoch 14 Batch 950 Loss 0.5819 Accuracy 0.8804
Epoch 14 Batch 1000 Loss 0.5822 Accuracy 0.8804
Epoch 14 Batch 1050 Loss 0.5825 Accuracy 0.8803
Epoch 14 Batch 1100 Loss 0.5834 Accuracy 0.8802
Epoch 14 Batch 1150 Loss 0.5839 Accuracy 0.8800
Epoch 14 Batch 1200 Loss 0.5844 Accuracy 0.8800
Epoch 14 Batch 1250 Loss 0.5849 Accuracy 0.8800
Epoch 14 Batch 1300 Loss 0.5852 Accuracy 0.8799
Epoch 14 Batch 1350 Loss 0.5855 Accuracy 0.8799
Epoch 14 Batch 1400 Loss 0.5860 Accuracy 0.8798
Epoch 14 Batch 1450 Loss 0.5865 Accuracy 0.8797
Epoch 14 Batch 1500 Loss 0.5872 Accuracy 0.8796

wandb: WARNING Step must only increase in log calls.  Step 14 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5877035>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.87959546>}.

Epoch 14 Loss 0.5877 Accuracy 0.8796
Time taken for 1 epoch: 36.05220580101013 secs

epoch lasted: 36.05935859680176
Epoch 15 Batch 0 Loss 0.6110 Accuracy 0.8821
Epoch 15 Batch 50 Loss 0.5658 Accuracy 0.8831
Epoch 15 Batch 100 Loss 0.5680 Accuracy 0.8820
Epoch 15 Batch 150 Loss 0.5668 Accuracy 0.8822
Epoch 15 Batch 200 Loss 0.5686 Accuracy 0.8823
Epoch 15 Batch 250 Loss 0.5683 Accuracy 0.8825
Epoch 15 Batch 300 Loss 0.5686 Accuracy 0.8824
Epoch 15 Batch 350 Loss 0.5696 Accuracy 0.8821
Epoch 15 Batch 400 Loss 0.5720 Accuracy 0.8817
Epoch 15 Batch 450 Loss 0.5734 Accuracy 0.8815
Epoch 15 Batch 500 Loss 0.5734 Accuracy 0.8816
Epoch 15 Batch 550 Loss 0.5739 Accuracy 0.8815
Epoch 15 Batch 600 Loss 0.5747 Accuracy 0.8814
Epoch 15 Batch 650 Loss 0.5757 Accuracy 0.8813
Epoch 15 Batch 700 Loss 0.5765 Accuracy 0.8812
Epoch 15 Batch 750 Loss 0.5769 Accuracy 0.8812
Epoch 15 Batch 800 Loss 0.5774 Accuracy 0.8812
discarded batch 836
Epoch 15 Batch 850 Loss 0.5780 Accuracy 0.8811
Epoch 15 Batch 900 Loss 0.5786 Accuracy 0.8811
Epoch 15 Batch 950 Loss 0.5789 Accuracy 0.8811
Epoch 15 Batch 1000 Loss 0.5788 Accuracy 0.8810
Epoch 15 Batch 1050 Loss 0.5797 Accuracy 0.8809
Epoch 15 Batch 1100 Loss 0.5801 Accuracy 0.8808
Epoch 15 Batch 1150 Loss 0.5804 Accuracy 0.8808
Epoch 15 Batch 1200 Loss 0.5811 Accuracy 0.8808
Epoch 15 Batch 1250 Loss 0.5813 Accuracy 0.8807
Epoch 15 Batch 1300 Loss 0.5818 Accuracy 0.8807
Epoch 15 Batch 1350 Loss 0.5821 Accuracy 0.8807
Epoch 15 Batch 1400 Loss 0.5822 Accuracy 0.8807
Epoch 15 Batch 1450 Loss 0.5829 Accuracy 0.8805
Epoch 15 Batch 1500 Loss 0.5832 Accuracy 0.8804

wandb: WARNING Step must only increase in log calls.  Step 15 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.58368707>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88032144>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-7
Epoch 15 Loss 0.5837 Accuracy 0.8803
Time taken for 1 epoch: 36.20006346702576 secs

epoch lasted: 36.20886254310608
Epoch 16 Batch 0 Loss 0.6066 Accuracy 0.8787
Epoch 16 Batch 50 Loss 0.5616 Accuracy 0.8816
Epoch 16 Batch 100 Loss 0.5637 Accuracy 0.8818
Epoch 16 Batch 150 Loss 0.5654 Accuracy 0.8813
discarded batch 178
Epoch 16 Batch 200 Loss 0.5659 Accuracy 0.8816
Epoch 16 Batch 250 Loss 0.5660 Accuracy 0.8818
Epoch 16 Batch 300 Loss 0.5648 Accuracy 0.8820
Epoch 16 Batch 350 Loss 0.5650 Accuracy 0.8820
Epoch 16 Batch 400 Loss 0.5657 Accuracy 0.8818
Epoch 16 Batch 450 Loss 0.5659 Accuracy 0.8821
Epoch 16 Batch 500 Loss 0.5671 Accuracy 0.8819
Epoch 16 Batch 550 Loss 0.5685 Accuracy 0.8818
Epoch 16 Batch 600 Loss 0.5699 Accuracy 0.8815
Epoch 16 Batch 650 Loss 0.5708 Accuracy 0.8815
Epoch 16 Batch 700 Loss 0.5712 Accuracy 0.8815
Epoch 16 Batch 750 Loss 0.5718 Accuracy 0.8814
Epoch 16 Batch 800 Loss 0.5723 Accuracy 0.8813
Epoch 16 Batch 850 Loss 0.5731 Accuracy 0.8812
Epoch 16 Batch 900 Loss 0.5744 Accuracy 0.8812
Epoch 16 Batch 950 Loss 0.5745 Accuracy 0.8811
Epoch 16 Batch 1000 Loss 0.5748 Accuracy 0.8811
Epoch 16 Batch 1050 Loss 0.5752 Accuracy 0.8810
Epoch 16 Batch 1100 Loss 0.5759 Accuracy 0.8810
Epoch 16 Batch 1150 Loss 0.5764 Accuracy 0.8810
Epoch 16 Batch 1200 Loss 0.5768 Accuracy 0.8810
Epoch 16 Batch 1250 Loss 0.5773 Accuracy 0.8809
Epoch 16 Batch 1300 Loss 0.5776 Accuracy 0.8809
Epoch 16 Batch 1350 Loss 0.5779 Accuracy 0.8808
Epoch 16 Batch 1400 Loss 0.5785 Accuracy 0.8807
Epoch 16 Batch 1450 Loss 0.5790 Accuracy 0.8807
Epoch 16 Batch 1500 Loss 0.5795 Accuracy 0.8806

wandb: WARNING Step must only increase in log calls.  Step 16 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5798973>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8806099>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 22; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.7332024>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86766326>}.

Epoch 16 Loss 0.5799 Accuracy 0.8806
Time taken for 1 epoch: 35.88561820983887 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.7332 Accuracy 0.8677

epoch lasted: 36.040229082107544
Epoch 17 Batch 0 Loss 0.5867 Accuracy 0.8771
Epoch 17 Batch 50 Loss 0.5611 Accuracy 0.8837
Epoch 17 Batch 100 Loss 0.5589 Accuracy 0.8838
Epoch 17 Batch 150 Loss 0.5593 Accuracy 0.8837
Epoch 17 Batch 200 Loss 0.5607 Accuracy 0.8833
Epoch 17 Batch 250 Loss 0.5614 Accuracy 0.8830
Epoch 17 Batch 300 Loss 0.5610 Accuracy 0.8829
Epoch 17 Batch 350 Loss 0.5624 Accuracy 0.8827
Epoch 17 Batch 400 Loss 0.5627 Accuracy 0.8828
Epoch 17 Batch 450 Loss 0.5640 Accuracy 0.8826
discarded batch 486
Epoch 17 Batch 500 Loss 0.5647 Accuracy 0.8826
Epoch 17 Batch 550 Loss 0.5653 Accuracy 0.8824
Epoch 17 Batch 600 Loss 0.5662 Accuracy 0.8822
Epoch 17 Batch 650 Loss 0.5667 Accuracy 0.8822
Epoch 17 Batch 700 Loss 0.5667 Accuracy 0.8821
Epoch 17 Batch 750 Loss 0.5675 Accuracy 0.8820
Epoch 17 Batch 800 Loss 0.5684 Accuracy 0.8819
Epoch 17 Batch 850 Loss 0.5694 Accuracy 0.8817
Epoch 17 Batch 900 Loss 0.5704 Accuracy 0.8816
Epoch 17 Batch 950 Loss 0.5709 Accuracy 0.8815
Epoch 17 Batch 1000 Loss 0.5712 Accuracy 0.8814
Epoch 17 Batch 1050 Loss 0.5719 Accuracy 0.8813
Epoch 17 Batch 1100 Loss 0.5722 Accuracy 0.8814
Epoch 17 Batch 1150 Loss 0.5727 Accuracy 0.8813
Epoch 17 Batch 1200 Loss 0.5734 Accuracy 0.8812
Epoch 17 Batch 1250 Loss 0.5740 Accuracy 0.8812
Epoch 17 Batch 1300 Loss 0.5747 Accuracy 0.8811
Epoch 17 Batch 1350 Loss 0.5755 Accuracy 0.8810
Epoch 17 Batch 1400 Loss 0.5756 Accuracy 0.8811
Epoch 17 Batch 1450 Loss 0.5758 Accuracy 0.8811
Epoch 17 Batch 1500 Loss 0.5760 Accuracy 0.8811

wandb: WARNING Step must only increase in log calls.  Step 17 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5764666>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8809874>}.

Epoch 17 Loss 0.5765 Accuracy 0.8810
Time taken for 1 epoch: 35.977211713790894 secs

epoch lasted: 35.98166537284851
Epoch 18 Batch 0 Loss 0.5430 Accuracy 0.8787
Epoch 18 Batch 50 Loss 0.5541 Accuracy 0.8839
Epoch 18 Batch 100 Loss 0.5528 Accuracy 0.8840
Epoch 18 Batch 150 Loss 0.5563 Accuracy 0.8837
Epoch 18 Batch 200 Loss 0.5567 Accuracy 0.8836
Epoch 18 Batch 250 Loss 0.5565 Accuracy 0.8837
Epoch 18 Batch 300 Loss 0.5579 Accuracy 0.8834
Epoch 18 Batch 350 Loss 0.5592 Accuracy 0.8830
Epoch 18 Batch 400 Loss 0.5597 Accuracy 0.8831
discarded batch 438
Epoch 18 Batch 450 Loss 0.5599 Accuracy 0.8830
Epoch 18 Batch 500 Loss 0.5610 Accuracy 0.8829
Epoch 18 Batch 550 Loss 0.5615 Accuracy 0.8828
Epoch 18 Batch 600 Loss 0.5622 Accuracy 0.8827
Epoch 18 Batch 650 Loss 0.5634 Accuracy 0.8825
Epoch 18 Batch 700 Loss 0.5645 Accuracy 0.8824
Epoch 18 Batch 750 Loss 0.5653 Accuracy 0.8824
Epoch 18 Batch 800 Loss 0.5661 Accuracy 0.8823
Epoch 18 Batch 850 Loss 0.5666 Accuracy 0.8822
Epoch 18 Batch 900 Loss 0.5672 Accuracy 0.8822
Epoch 18 Batch 950 Loss 0.5680 Accuracy 0.8821
Epoch 18 Batch 1000 Loss 0.5683 Accuracy 0.8821
Epoch 18 Batch 1050 Loss 0.5689 Accuracy 0.8820
Epoch 18 Batch 1100 Loss 0.5693 Accuracy 0.8819
Epoch 18 Batch 1150 Loss 0.5698 Accuracy 0.8819
Epoch 18 Batch 1200 Loss 0.5700 Accuracy 0.8819
Epoch 18 Batch 1250 Loss 0.5706 Accuracy 0.8818
Epoch 18 Batch 1300 Loss 0.5711 Accuracy 0.8818
Epoch 18 Batch 1350 Loss 0.5714 Accuracy 0.8817
Epoch 18 Batch 1400 Loss 0.5718 Accuracy 0.8818
Epoch 18 Batch 1450 Loss 0.5720 Accuracy 0.8817
Epoch 18 Batch 1500 Loss 0.5725 Accuracy 0.8817

wandb: WARNING Step must only increase in log calls.  Step 18 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.57273567>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8816523>}.

Epoch 18 Loss 0.5727 Accuracy 0.8817
Time taken for 1 epoch: 35.94387340545654 secs

epoch lasted: 35.94800281524658
Epoch 19 Batch 0 Loss 0.5587 Accuracy 0.8854
Epoch 19 Batch 50 Loss 0.5587 Accuracy 0.8833
Epoch 19 Batch 100 Loss 0.5566 Accuracy 0.8835
Epoch 19 Batch 150 Loss 0.5515 Accuracy 0.8844
Epoch 19 Batch 200 Loss 0.5527 Accuracy 0.8841
Epoch 19 Batch 250 Loss 0.5548 Accuracy 0.8836
Epoch 19 Batch 300 Loss 0.5557 Accuracy 0.8836
Epoch 19 Batch 350 Loss 0.5558 Accuracy 0.8836
Epoch 19 Batch 400 Loss 0.5565 Accuracy 0.8836
Epoch 19 Batch 450 Loss 0.5578 Accuracy 0.8834
Epoch 19 Batch 500 Loss 0.5579 Accuracy 0.8833
Epoch 19 Batch 550 Loss 0.5591 Accuracy 0.8832
Epoch 19 Batch 600 Loss 0.5592 Accuracy 0.8834
Epoch 19 Batch 650 Loss 0.5595 Accuracy 0.8833
Epoch 19 Batch 700 Loss 0.5601 Accuracy 0.8831
Epoch 19 Batch 750 Loss 0.5604 Accuracy 0.8831
discarded batch 778
Epoch 19 Batch 800 Loss 0.5608 Accuracy 0.8831
Epoch 19 Batch 850 Loss 0.5617 Accuracy 0.8830
Epoch 19 Batch 900 Loss 0.5621 Accuracy 0.8830
Epoch 19 Batch 950 Loss 0.5627 Accuracy 0.8829
Epoch 19 Batch 1000 Loss 0.5637 Accuracy 0.8828
Epoch 19 Batch 1050 Loss 0.5647 Accuracy 0.8826
Epoch 19 Batch 1100 Loss 0.5651 Accuracy 0.8826
Epoch 19 Batch 1150 Loss 0.5658 Accuracy 0.8826
Epoch 19 Batch 1200 Loss 0.5658 Accuracy 0.8827
Epoch 19 Batch 1250 Loss 0.5663 Accuracy 0.8825
Epoch 19 Batch 1300 Loss 0.5666 Accuracy 0.8825
Epoch 19 Batch 1350 Loss 0.5673 Accuracy 0.8824
Epoch 19 Batch 1400 Loss 0.5681 Accuracy 0.8823
Epoch 19 Batch 1450 Loss 0.5686 Accuracy 0.8822
Epoch 19 Batch 1500 Loss 0.5690 Accuracy 0.8822

wandb: WARNING Step must only increase in log calls.  Step 19 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5694202>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8821134>}.

Epoch 19 Loss 0.5694 Accuracy 0.8821
Time taken for 1 epoch: 36.07954788208008 secs

epoch lasted: 36.084662675857544
Epoch 20 Batch 0 Loss 0.5185 Accuracy 0.8904
Epoch 20 Batch 50 Loss 0.5416 Accuracy 0.8858
Epoch 20 Batch 100 Loss 0.5429 Accuracy 0.8863
Epoch 20 Batch 150 Loss 0.5439 Accuracy 0.8858
Epoch 20 Batch 200 Loss 0.5439 Accuracy 0.8856
Epoch 20 Batch 250 Loss 0.5467 Accuracy 0.8852
Epoch 20 Batch 300 Loss 0.5488 Accuracy 0.8852
Epoch 20 Batch 350 Loss 0.5502 Accuracy 0.8852
Epoch 20 Batch 400 Loss 0.5515 Accuracy 0.8850
Epoch 20 Batch 450 Loss 0.5531 Accuracy 0.8849
Epoch 20 Batch 500 Loss 0.5537 Accuracy 0.8847
Epoch 20 Batch 550 Loss 0.5547 Accuracy 0.8845
Epoch 20 Batch 600 Loss 0.5549 Accuracy 0.8844
Epoch 20 Batch 650 Loss 0.5555 Accuracy 0.8842
Epoch 20 Batch 700 Loss 0.5561 Accuracy 0.8841
Epoch 20 Batch 750 Loss 0.5564 Accuracy 0.8840
Epoch 20 Batch 800 Loss 0.5571 Accuracy 0.8838
Epoch 20 Batch 850 Loss 0.5579 Accuracy 0.8837
discarded batch 856
Epoch 20 Batch 900 Loss 0.5586 Accuracy 0.8836
Epoch 20 Batch 950 Loss 0.5592 Accuracy 0.8835
Epoch 20 Batch 1000 Loss 0.5599 Accuracy 0.8834
Epoch 20 Batch 1050 Loss 0.5603 Accuracy 0.8834
Epoch 20 Batch 1100 Loss 0.5610 Accuracy 0.8833
Epoch 20 Batch 1150 Loss 0.5615 Accuracy 0.8832
Epoch 20 Batch 1200 Loss 0.5617 Accuracy 0.8831
Epoch 20 Batch 1250 Loss 0.5621 Accuracy 0.8831
Epoch 20 Batch 1300 Loss 0.5628 Accuracy 0.8830
Epoch 20 Batch 1350 Loss 0.5632 Accuracy 0.8829
Epoch 20 Batch 1400 Loss 0.5639 Accuracy 0.8828
Epoch 20 Batch 1450 Loss 0.5644 Accuracy 0.8828
Epoch 20 Batch 1500 Loss 0.5647 Accuracy 0.8827

wandb: WARNING Step must only increase in log calls.  Step 20 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5652372>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8826485>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-8
Epoch 20 Loss 0.5652 Accuracy 0.8826
Time taken for 1 epoch: 36.14118218421936 secs

epoch lasted: 36.146092891693115
Epoch 21 Batch 0 Loss 0.6149 Accuracy 0.8887
Epoch 21 Batch 50 Loss 0.5451 Accuracy 0.8857
Epoch 21 Batch 100 Loss 0.5456 Accuracy 0.8857
Epoch 21 Batch 150 Loss 0.5497 Accuracy 0.8851
Epoch 21 Batch 200 Loss 0.5471 Accuracy 0.8853
Epoch 21 Batch 250 Loss 0.5468 Accuracy 0.8854
Epoch 21 Batch 300 Loss 0.5467 Accuracy 0.8855
Epoch 21 Batch 350 Loss 0.5472 Accuracy 0.8856
Epoch 21 Batch 400 Loss 0.5481 Accuracy 0.8854
Epoch 21 Batch 450 Loss 0.5491 Accuracy 0.8852
Epoch 21 Batch 500 Loss 0.5504 Accuracy 0.8849
discarded batch 537
Epoch 21 Batch 550 Loss 0.5511 Accuracy 0.8848
Epoch 21 Batch 600 Loss 0.5517 Accuracy 0.8848
Epoch 21 Batch 650 Loss 0.5520 Accuracy 0.8846
Epoch 21 Batch 700 Loss 0.5521 Accuracy 0.8846
Epoch 21 Batch 750 Loss 0.5525 Accuracy 0.8846
Epoch 21 Batch 800 Loss 0.5535 Accuracy 0.8845
Epoch 21 Batch 850 Loss 0.5543 Accuracy 0.8844
Epoch 21 Batch 900 Loss 0.5552 Accuracy 0.8842
Epoch 21 Batch 950 Loss 0.5556 Accuracy 0.8841
Epoch 21 Batch 1000 Loss 0.5560 Accuracy 0.8839
Epoch 21 Batch 1050 Loss 0.5564 Accuracy 0.8839
Epoch 21 Batch 1100 Loss 0.5571 Accuracy 0.8839
Epoch 21 Batch 1150 Loss 0.5577 Accuracy 0.8838
Epoch 21 Batch 1200 Loss 0.5582 Accuracy 0.8838
Epoch 21 Batch 1250 Loss 0.5585 Accuracy 0.8837
Epoch 21 Batch 1300 Loss 0.5589 Accuracy 0.8836
Epoch 21 Batch 1350 Loss 0.5595 Accuracy 0.8835
Epoch 21 Batch 1400 Loss 0.5597 Accuracy 0.8835
Epoch 21 Batch 1450 Loss 0.5604 Accuracy 0.8834
Epoch 21 Batch 1500 Loss 0.5613 Accuracy 0.8833

wandb: WARNING Step must only increase in log calls.  Step 21 < 22; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.561778>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8832105>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 22; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.74249834>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86788476>}.

Epoch 21 Loss 0.5618 Accuracy 0.8832
Time taken for 1 epoch: 36.09142804145813 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.7425 Accuracy 0.8679

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 co|sì |che ’l |tuo |pa|ce e |io |con |que|sti |be|ne|
e |co|me a |chi |se’ |tu |se’ |ben |di|let|to|
ma |per|ché |nel |ve|di |tut|ti |mo|stra|ne|
                                                                                                                                                                   
 e |a |lui |chi |se’ |o|gne |pa|ro|spet|to|
per |que|sti |cia|scun |di |quel |che |tu |ca|ne|
co|me ’l |dì |a |lui |che |di |quel |gi|gan|na|
e |per|ché |la |ca|gion |di |cia|scu|na |ve|nu|be|
e |io |a |di|re e |di |sé |re|tro |gi|ra|
e |io |a |lui |ca|re e |del |lo|re e |tar|
                                                                                                                                                                    
 di |cri|sto |ch’ io |fer|mar |non |ti |ca|gio|ra|
a |re|ve|nir |più |non |cre|a|tu|ro|ro|
e |se |ne |la |men|te a |ter|ra |gi|ra|
 ma |per|ch’ io |veg|gen|te e |co|min|ciò |che |di|
e |io |veg|gi |del |suo |già |di |qua |sù |re|gi|
ma |per|ché |non |e|ran |tut|to |gi|na|to|
                                                                                                                                                                   
 se |tu |se’ |tu |se’ |tu |se’ |i|scia|gi|ra|
e |io |non |è |ma |se |mai |non |ti |ca|to|
ma |per|ché |più |e |io |non |ti |con|ti|ra|
 di |que|sto|sto|re e |del |cie|lo e |ve|de|sto|
di |qua |gi|ra|gio|sto|re e |di |sé |e |ca|ra|
e |di |qua |sù |con |que|sto |ca|ren|ti|ra|
                                                                                                                                                                   
 e |io |a |lui |a |sé |e |di |pa|sto|ra|
di |quel|le |no|stri |pa|ro|le |del |mon|do|
di |que|sto |fon|do a |cia|scu|no e |com|pa|sto|
e |di |qua |che |del |ca|gio|no |di |qua |con|si|ra|
e |se |be|a|let|tor |ch’ i’ |non |ti |gi|ra|
e |io |veg|gi |de|re e |per|ché |non |gi|ra|
                                                                                                                                                                   
 a |dir |co|min|ciò |el|li |mar|che|li|ra|
o |tu |per|ché |tut|to |del |suo |fi|gu|ra|
e |se |non |ti |par|lar |non |si |con|di|to|
ma |per|fet|to |di |qua |sù |e |di |sé |stes|so |se|
e |io |veg|gio |co|sì |co|tal |mo|stra|da|
e |co|min|ciò |a |lui |ve|nu|to |gi|
                                                                                                                                                                    
 e |io |veg|gio |ben |qua |sù |di|sce|mo|
a |lui |ch’ a |be|a|ti |par|lar |con|tem|pra|
di |re|tro |mo|stra|re e |per|ché |non |ti |mo|ni|
 ma |se |tan|to |fer|man|ni e |con |que|sto |mon|ti|
e |que|sti |ciò |che |più |e |co|sto|let|to|
di |qua |giù |nel |mon|do a |tut|ti |ca|gio|ne|
                                                                                                                                                                   
 di |quel |che |più |e |io |veg|gio|no |pen|to|
di |qua |sù |ca|gion |di |lor |ca|ri|sto|ne|
ma |io |non |cre|a|to |co|me |di|mo|to|
e |io |be|ni|mal |con|ten|de|re e |del |cie|lo|co|
ma |per|ché |tut|ti |li al|tri |le |sue |brac|cia|
e |co|min|ciò |el|li |tuoi |pen|sier |du|co|
                                                                                                                                                                   
 e |io |a |lui |che ’n |que|sti |con|ten|to|sto|
e |io |veg|gen|za |già |mai |non |si |mo|ro|
che |si |con|ten|der |ciò |ch’ io |non |si |cer|sto|
 e |io |con |le |ca|de|re e |del |mon|do|man|to|
e |se |ca|po |di |qua |giu|sti|be|ni|do|
e |se |ben |m’ ac|ce|si |con|ten|de|gna|
                                                                                                                                                                    
 se |tu |ve|nir |del |buon |buon |mar|che|spet|to|
di |que|sta |gen|te |già |mai |non |di|gna|gna|
e |io |veg|gio|nan|zi a |noi |o|mai |o|do|
 e |co|sto|sto|e|sti|zia |di |que|sti |la|
e |io |a |lui |per|ché |di |que|sto |cie|lo|
e |io |a |lui |per|ch’ io |non |cre|de|re e |gi|
                                                                                                                                                                    
 ma |io |a |dir |per|ché |più |e |co|per|so|
e |un |di |que|sto |mon|do |più |gio|na|
e |io |veg|gio|na|tu|ra |già |mai |cre|di|
e |io |in |que|sto |cie|lo e |van|no |più |a|spet|to|
ma |tu |la|to|sto|re|gno |di |gran |do|ri|
di |tut|to |le |gen|ti e |ce|re e |più |pet|to|
                                                                                                                                                                   
 e |io |a |dir |co|sì |fat|to |di|mo|ri|
di |que|sta |pa|ren|za |che |tu |ve|der|to|
di |re|tro a |lui |ch’ a |lui |non |si |di|mo|ri|
 ma |io |veg|gen|te |del |tuo |ca|po |con|ven|ti|
e |io |veg|gi |con|ten|der |non |ti |gi|chi|
e |co|min|ciò |el|li a |cui |re|tro a |que|sto|
                                                                                                                                                                   
 e |io |a|scol|tan|to |più |e |co|sto|
a |dir |lo |dol|ce |lo|ro |tut|to |ca|sto|sto|
di |que|sti |co|lui |ch’ a |lui |con|ten|de|
 e |di |que|sto |cie|lo e |di |que|sto |cie|lo e |cer|be|
quan|d’ io |ca|po |di |ciò |ch’ io |di|stin|sto|
di |lui |ve|drai |ben |ch’ a |lui |ca|ver |gio|sto|
                                                                                                                                                                   
 quan|d’ io |ch’ a|vea |ca|po |di |quel |ch’ a|spet|sto|
quan|to |che |tu |ve|nir |del |mon|do |ca|sto|
non |è |ciò |ch’ io |non |cre|di |quel |ch’ a|spet|ti|
ma |guar|di |sé |stes|so |del |tuo |gi|ra|zion |bu|sto|
ma |per|ché |di |qua |e |io |ti |con|ce|sto|
di |que|sti |ciò |che ’n |ca|gion |qui |è |ca|sto|
                                                                                                                                                                   
 e |quei |co|lui |che |non |te|ni|fe|li|sto|
di |que|sti |co|lui |che ’n |que|sto |gi|ra|sto|
di |que|sto |fon|do a |ciò |ch’ io |non |ti |li|sto|
 e |di |quel |ca|po |di |be|ni|me |ve|nu|be|
ma |io |veg|gi |del |ve|nu|to a |gi|ra|
ma |per|ché |tu |chi |se’ |ve|nir |del |tuo |mo|be|
                                                                                                                                                                   
 e |io |a |lui |par|ver |co|lor |con|ti|ra|
di |que|sti |cia|scu|na |gen|te |si |gi|ro|
e |se |tu |ve|der |di |quel |ch’ i’ |veg|gio|ra|
e |co|sì |co|sto|ro e |per|ché |ve|di |quel |ch’ i’ |o|ne|
e |io |veg|gen|te |che |non |a|spet|to|
co|me |ve|nu|be |tut|to |di |quel |ca|ro|
                                                                                                                                                                   
 ma |per|ché |co|sì |co|sì |co|tal |bu|sto|
e |co|min|ciò |con |le |man |de|stra |cia|
e |io |a |lui |che |tu |ve|nu|me|ro |gi|sto|

epoch lasted: 526.0022468566895
(1900, 128)
Epoch 1 Batch 0 Loss 0.5651 Accuracy 0.8738
Epoch 1 Batch 50 Loss 0.5346 Accuracy 0.8870
Epoch 1 Batch 100 Loss 0.5373 Accuracy 0.8864
Epoch 1 Batch 150 Loss 0.5409 Accuracy 0.8862
Epoch 1 Batch 200 Loss 0.5416 Accuracy 0.8860
Epoch 1 Batch 250 Loss 0.5423 Accuracy 0.8862
Epoch 1 Batch 300 Loss 0.5432 Accuracy 0.8861
Epoch 1 Batch 350 Loss 0.5460 Accuracy 0.8857
Epoch 1 Batch 400 Loss 0.5465 Accuracy 0.8854
Epoch 1 Batch 450 Loss 0.5461 Accuracy 0.8855
Epoch 1 Batch 500 Loss 0.5466 Accuracy 0.8854
Epoch 1 Batch 550 Loss 0.5475 Accuracy 0.8854
Epoch 1 Batch 600 Loss 0.5486 Accuracy 0.8852
Epoch 1 Batch 650 Loss 0.5487 Accuracy 0.8851
discarded batch 682
Epoch 1 Batch 700 Loss 0.5495 Accuracy 0.8851
Epoch 1 Batch 750 Loss 0.5500 Accuracy 0.8849
Epoch 1 Batch 800 Loss 0.5503 Accuracy 0.8849
Epoch 1 Batch 850 Loss 0.5511 Accuracy 0.8847
Epoch 1 Batch 900 Loss 0.5518 Accuracy 0.8846
Epoch 1 Batch 950 Loss 0.5525 Accuracy 0.8845
Epoch 1 Batch 1000 Loss 0.5534 Accuracy 0.8844
Epoch 1 Batch 1050 Loss 0.5539 Accuracy 0.8843
Epoch 1 Batch 1100 Loss 0.5543 Accuracy 0.8843
Epoch 1 Batch 1150 Loss 0.5548 Accuracy 0.8842
Epoch 1 Batch 1200 Loss 0.5550 Accuracy 0.8842
Epoch 1 Batch 1250 Loss 0.5557 Accuracy 0.8841
Epoch 1 Batch 1300 Loss 0.5564 Accuracy 0.8840
Epoch 1 Batch 1350 Loss 0.5568 Accuracy 0.8840
Epoch 1 Batch 1400 Loss 0.5569 Accuracy 0.8839
Epoch 1 Batch 1450 Loss 0.5576 Accuracy 0.8838
Epoch 1 Batch 1500 Loss 0.5582 Accuracy 0.8837

wandb: WARNING Step must only increase in log calls.  Step 1 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5586189>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88370806>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 23; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.74524754>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86699885>}.

Epoch 1 Loss 0.5586 Accuracy 0.8837
Time taken for 1 epoch: 36.166812896728516 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.7452 Accuracy 0.8670

epoch lasted: 36.32105493545532
Epoch 2 Batch 0 Loss 0.5205 Accuracy 0.8987
Epoch 2 Batch 50 Loss 0.5443 Accuracy 0.8863
Epoch 2 Batch 100 Loss 0.5424 Accuracy 0.8855
Epoch 2 Batch 150 Loss 0.5426 Accuracy 0.8859
Epoch 2 Batch 200 Loss 0.5436 Accuracy 0.8856
discarded batch 214
Epoch 2 Batch 250 Loss 0.5419 Accuracy 0.8860
Epoch 2 Batch 300 Loss 0.5414 Accuracy 0.8860
Epoch 2 Batch 350 Loss 0.5406 Accuracy 0.8860
Epoch 2 Batch 400 Loss 0.5407 Accuracy 0.8861
Epoch 2 Batch 450 Loss 0.5408 Accuracy 0.8860
Epoch 2 Batch 500 Loss 0.5409 Accuracy 0.8860
Epoch 2 Batch 550 Loss 0.5427 Accuracy 0.8858
Epoch 2 Batch 600 Loss 0.5434 Accuracy 0.8856
Epoch 2 Batch 650 Loss 0.5440 Accuracy 0.8854
Epoch 2 Batch 700 Loss 0.5446 Accuracy 0.8854
Epoch 2 Batch 750 Loss 0.5456 Accuracy 0.8852
Epoch 2 Batch 800 Loss 0.5460 Accuracy 0.8852
Epoch 2 Batch 850 Loss 0.5468 Accuracy 0.8850
Epoch 2 Batch 900 Loss 0.5475 Accuracy 0.8850
Epoch 2 Batch 950 Loss 0.5481 Accuracy 0.8850
Epoch 2 Batch 1000 Loss 0.5485 Accuracy 0.8849
Epoch 2 Batch 1050 Loss 0.5492 Accuracy 0.8848
Epoch 2 Batch 1100 Loss 0.5501 Accuracy 0.8847
Epoch 2 Batch 1150 Loss 0.5505 Accuracy 0.8846
Epoch 2 Batch 1200 Loss 0.5513 Accuracy 0.8846
Epoch 2 Batch 1250 Loss 0.5520 Accuracy 0.8845
Epoch 2 Batch 1300 Loss 0.5523 Accuracy 0.8844
Epoch 2 Batch 1350 Loss 0.5527 Accuracy 0.8844
Epoch 2 Batch 1400 Loss 0.5532 Accuracy 0.8844
Epoch 2 Batch 1450 Loss 0.5538 Accuracy 0.8843
Epoch 2 Batch 1500 Loss 0.5543 Accuracy 0.8842

wandb: WARNING Step must only increase in log calls.  Step 2 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.55467993>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88418204>}.

Epoch 2 Loss 0.5547 Accuracy 0.8842
Time taken for 1 epoch: 36.16370439529419 secs

epoch lasted: 36.1680212020874
Epoch 3 Batch 0 Loss 0.5120 Accuracy 0.8787
Epoch 3 Batch 50 Loss 0.5289 Accuracy 0.8869
Epoch 3 Batch 100 Loss 0.5311 Accuracy 0.8878
Epoch 3 Batch 150 Loss 0.5354 Accuracy 0.8865
Epoch 3 Batch 200 Loss 0.5361 Accuracy 0.8863
Epoch 3 Batch 250 Loss 0.5378 Accuracy 0.8863
Epoch 3 Batch 300 Loss 0.5377 Accuracy 0.8863
Epoch 3 Batch 350 Loss 0.5393 Accuracy 0.8862
Epoch 3 Batch 400 Loss 0.5405 Accuracy 0.8859
Epoch 3 Batch 450 Loss 0.5405 Accuracy 0.8859
Epoch 3 Batch 500 Loss 0.5416 Accuracy 0.8857
Epoch 3 Batch 550 Loss 0.5413 Accuracy 0.8859
Epoch 3 Batch 600 Loss 0.5418 Accuracy 0.8858
Epoch 3 Batch 650 Loss 0.5427 Accuracy 0.8855
Epoch 3 Batch 700 Loss 0.5437 Accuracy 0.8855
Epoch 3 Batch 750 Loss 0.5447 Accuracy 0.8855
Epoch 3 Batch 800 Loss 0.5447 Accuracy 0.8854
Epoch 3 Batch 850 Loss 0.5451 Accuracy 0.8854
Epoch 3 Batch 900 Loss 0.5458 Accuracy 0.8853
Epoch 3 Batch 950 Loss 0.5461 Accuracy 0.8853
Epoch 3 Batch 1000 Loss 0.5466 Accuracy 0.8853
Epoch 3 Batch 1050 Loss 0.5471 Accuracy 0.8852
discarded batch 1073
Epoch 3 Batch 1100 Loss 0.5476 Accuracy 0.8853
Epoch 3 Batch 1150 Loss 0.5481 Accuracy 0.8852
Epoch 3 Batch 1200 Loss 0.5490 Accuracy 0.8851
Epoch 3 Batch 1250 Loss 0.5492 Accuracy 0.8850
Epoch 3 Batch 1300 Loss 0.5493 Accuracy 0.8850
Epoch 3 Batch 1350 Loss 0.5495 Accuracy 0.8850
Epoch 3 Batch 1400 Loss 0.5499 Accuracy 0.8849
Epoch 3 Batch 1450 Loss 0.5507 Accuracy 0.8847
Epoch 3 Batch 1500 Loss 0.5508 Accuracy 0.8847

wandb: WARNING Step must only increase in log calls.  Step 3 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.55135125>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8845713>}.

Epoch 3 Loss 0.5514 Accuracy 0.8846
Time taken for 1 epoch: 35.975051164627075 secs

epoch lasted: 35.9792423248291
Epoch 4 Batch 0 Loss 0.5521 Accuracy 0.8837
Epoch 4 Batch 50 Loss 0.5290 Accuracy 0.8875
Epoch 4 Batch 100 Loss 0.5306 Accuracy 0.8885
discarded batch 131
Epoch 4 Batch 150 Loss 0.5324 Accuracy 0.8879
Epoch 4 Batch 200 Loss 0.5327 Accuracy 0.8877
Epoch 4 Batch 250 Loss 0.5328 Accuracy 0.8877
Epoch 4 Batch 300 Loss 0.5331 Accuracy 0.8875
Epoch 4 Batch 350 Loss 0.5326 Accuracy 0.8876
Epoch 4 Batch 400 Loss 0.5328 Accuracy 0.8875
Epoch 4 Batch 450 Loss 0.5345 Accuracy 0.8873
Epoch 4 Batch 500 Loss 0.5357 Accuracy 0.8870
Epoch 4 Batch 550 Loss 0.5367 Accuracy 0.8869
Epoch 4 Batch 600 Loss 0.5380 Accuracy 0.8868
Epoch 4 Batch 650 Loss 0.5390 Accuracy 0.8866
Epoch 4 Batch 700 Loss 0.5399 Accuracy 0.8865
Epoch 4 Batch 750 Loss 0.5405 Accuracy 0.8864
Epoch 4 Batch 800 Loss 0.5410 Accuracy 0.8863
Epoch 4 Batch 850 Loss 0.5420 Accuracy 0.8861
Epoch 4 Batch 900 Loss 0.5429 Accuracy 0.8859
Epoch 4 Batch 950 Loss 0.5428 Accuracy 0.8859
Epoch 4 Batch 1000 Loss 0.5433 Accuracy 0.8859
Epoch 4 Batch 1050 Loss 0.5437 Accuracy 0.8858
Epoch 4 Batch 1100 Loss 0.5440 Accuracy 0.8857
Epoch 4 Batch 1150 Loss 0.5445 Accuracy 0.8857
Epoch 4 Batch 1200 Loss 0.5448 Accuracy 0.8856
Epoch 4 Batch 1250 Loss 0.5451 Accuracy 0.8856
Epoch 4 Batch 1300 Loss 0.5459 Accuracy 0.8855
Epoch 4 Batch 1350 Loss 0.5467 Accuracy 0.8854
Epoch 4 Batch 1400 Loss 0.5469 Accuracy 0.8853
Epoch 4 Batch 1450 Loss 0.5474 Accuracy 0.8853
Epoch 4 Batch 1500 Loss 0.5478 Accuracy 0.8853

wandb: WARNING Step must only increase in log calls.  Step 4 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.54823285>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8852008>}.

Epoch 4 Loss 0.5482 Accuracy 0.8852
Time taken for 1 epoch: 36.011208057403564 secs

epoch lasted: 36.01579213142395
Epoch 5 Batch 0 Loss 0.5299 Accuracy 0.8787
Epoch 5 Batch 50 Loss 0.5240 Accuracy 0.8870
Epoch 5 Batch 100 Loss 0.5258 Accuracy 0.8876
Epoch 5 Batch 150 Loss 0.5279 Accuracy 0.8876
Epoch 5 Batch 200 Loss 0.5271 Accuracy 0.8882
Epoch 5 Batch 250 Loss 0.5272 Accuracy 0.8885
Epoch 5 Batch 300 Loss 0.5269 Accuracy 0.8883
Epoch 5 Batch 350 Loss 0.5282 Accuracy 0.8881
Epoch 5 Batch 400 Loss 0.5287 Accuracy 0.8880
discarded batch 417
Epoch 5 Batch 450 Loss 0.5297 Accuracy 0.8878
Epoch 5 Batch 500 Loss 0.5306 Accuracy 0.8877
Epoch 5 Batch 550 Loss 0.5310 Accuracy 0.8876
Epoch 5 Batch 600 Loss 0.5316 Accuracy 0.8875
Epoch 5 Batch 650 Loss 0.5327 Accuracy 0.8873
Epoch 5 Batch 700 Loss 0.5339 Accuracy 0.8871
Epoch 5 Batch 750 Loss 0.5351 Accuracy 0.8870
Epoch 5 Batch 800 Loss 0.5361 Accuracy 0.8868
Epoch 5 Batch 850 Loss 0.5369 Accuracy 0.8867
Epoch 5 Batch 900 Loss 0.5376 Accuracy 0.8865
Epoch 5 Batch 950 Loss 0.5381 Accuracy 0.8865
Epoch 5 Batch 1000 Loss 0.5386 Accuracy 0.8864
Epoch 5 Batch 1050 Loss 0.5394 Accuracy 0.8863
Epoch 5 Batch 1100 Loss 0.5402 Accuracy 0.8862
Epoch 5 Batch 1150 Loss 0.5406 Accuracy 0.8862
Epoch 5 Batch 1200 Loss 0.5409 Accuracy 0.8861
Epoch 5 Batch 1250 Loss 0.5418 Accuracy 0.8860
Epoch 5 Batch 1300 Loss 0.5424 Accuracy 0.8860
Epoch 5 Batch 1350 Loss 0.5430 Accuracy 0.8859
Epoch 5 Batch 1400 Loss 0.5434 Accuracy 0.8858
Epoch 5 Batch 1450 Loss 0.5438 Accuracy 0.8857
Epoch 5 Batch 1500 Loss 0.5443 Accuracy 0.8856

wandb: WARNING Step must only increase in log calls.  Step 5 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.54487824>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8856019>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-9
Epoch 5 Loss 0.5449 Accuracy 0.8856
Time taken for 1 epoch: 36.16653370857239 secs

epoch lasted: 36.17167043685913
Epoch 6 Batch 0 Loss 0.5448 Accuracy 0.8771
Epoch 6 Batch 50 Loss 0.5210 Accuracy 0.8885
Epoch 6 Batch 100 Loss 0.5168 Accuracy 0.8893
Epoch 6 Batch 150 Loss 0.5204 Accuracy 0.8895
Epoch 6 Batch 200 Loss 0.5222 Accuracy 0.8893
discarded batch 228
Epoch 6 Batch 250 Loss 0.5244 Accuracy 0.8889
Epoch 6 Batch 300 Loss 0.5248 Accuracy 0.8886
Epoch 6 Batch 350 Loss 0.5260 Accuracy 0.8882
Epoch 6 Batch 400 Loss 0.5279 Accuracy 0.8880
Epoch 6 Batch 450 Loss 0.5288 Accuracy 0.8879
Epoch 6 Batch 500 Loss 0.5293 Accuracy 0.8878
Epoch 6 Batch 550 Loss 0.5298 Accuracy 0.8877
Epoch 6 Batch 600 Loss 0.5297 Accuracy 0.8877
Epoch 6 Batch 650 Loss 0.5313 Accuracy 0.8876
Epoch 6 Batch 700 Loss 0.5320 Accuracy 0.8876
Epoch 6 Batch 750 Loss 0.5327 Accuracy 0.8876
Epoch 6 Batch 800 Loss 0.5335 Accuracy 0.8875
Epoch 6 Batch 850 Loss 0.5346 Accuracy 0.8873
Epoch 6 Batch 900 Loss 0.5349 Accuracy 0.8872
Epoch 6 Batch 950 Loss 0.5361 Accuracy 0.8870
Epoch 6 Batch 1000 Loss 0.5367 Accuracy 0.8869
Epoch 6 Batch 1050 Loss 0.5372 Accuracy 0.8868
Epoch 6 Batch 1100 Loss 0.5377 Accuracy 0.8867
Epoch 6 Batch 1150 Loss 0.5383 Accuracy 0.8867
Epoch 6 Batch 1200 Loss 0.5390 Accuracy 0.8866
Epoch 6 Batch 1250 Loss 0.5394 Accuracy 0.8865
Epoch 6 Batch 1300 Loss 0.5396 Accuracy 0.8864
Epoch 6 Batch 1350 Loss 0.5400 Accuracy 0.8863
Epoch 6 Batch 1400 Loss 0.5406 Accuracy 0.8862
Epoch 6 Batch 1450 Loss 0.5410 Accuracy 0.8861
Epoch 6 Batch 1500 Loss 0.5413 Accuracy 0.8861

wandb: WARNING Step must only increase in log calls.  Step 6 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5417951>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.886092>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 23; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.75657046>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8658915>}.

Epoch 6 Loss 0.5418 Accuracy 0.8861
Time taken for 1 epoch: 36.06109881401062 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.7566 Accuracy 0.8659

epoch lasted: 36.214378118515015
Epoch 7 Batch 0 Loss 0.4400 Accuracy 0.9053
Epoch 7 Batch 50 Loss 0.5149 Accuracy 0.8904
Epoch 7 Batch 100 Loss 0.5160 Accuracy 0.8901
Epoch 7 Batch 150 Loss 0.5163 Accuracy 0.8895
Epoch 7 Batch 200 Loss 0.5185 Accuracy 0.8896
Epoch 7 Batch 250 Loss 0.5195 Accuracy 0.8894
Epoch 7 Batch 300 Loss 0.5202 Accuracy 0.8892
Epoch 7 Batch 350 Loss 0.5217 Accuracy 0.8888
Epoch 7 Batch 400 Loss 0.5219 Accuracy 0.8888
Epoch 7 Batch 450 Loss 0.5225 Accuracy 0.8887
Epoch 7 Batch 500 Loss 0.5234 Accuracy 0.8886
Epoch 7 Batch 550 Loss 0.5243 Accuracy 0.8884
Epoch 7 Batch 600 Loss 0.5252 Accuracy 0.8883
Epoch 7 Batch 650 Loss 0.5259 Accuracy 0.8881
Epoch 7 Batch 700 Loss 0.5270 Accuracy 0.8879
Epoch 7 Batch 750 Loss 0.5276 Accuracy 0.8878
Epoch 7 Batch 800 Loss 0.5282 Accuracy 0.8877
Epoch 7 Batch 850 Loss 0.5289 Accuracy 0.8876
Epoch 7 Batch 900 Loss 0.5294 Accuracy 0.8875
Epoch 7 Batch 950 Loss 0.5308 Accuracy 0.8874
Epoch 7 Batch 1000 Loss 0.5314 Accuracy 0.8873
Epoch 7 Batch 1050 Loss 0.5320 Accuracy 0.8873
Epoch 7 Batch 1100 Loss 0.5329 Accuracy 0.8872
Epoch 7 Batch 1150 Loss 0.5337 Accuracy 0.8870
Epoch 7 Batch 1200 Loss 0.5339 Accuracy 0.8870
Epoch 7 Batch 1250 Loss 0.5345 Accuracy 0.8869
discarded batch 1298
Epoch 7 Batch 1300 Loss 0.5351 Accuracy 0.8868
Epoch 7 Batch 1350 Loss 0.5358 Accuracy 0.8867
Epoch 7 Batch 1400 Loss 0.5360 Accuracy 0.8868
Epoch 7 Batch 1450 Loss 0.5363 Accuracy 0.8867
Epoch 7 Batch 1500 Loss 0.5368 Accuracy 0.8867

wandb: WARNING Step must only increase in log calls.  Step 7 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.537511>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.886626>}.

Epoch 7 Loss 0.5375 Accuracy 0.8866
Time taken for 1 epoch: 36.44038963317871 secs

epoch lasted: 36.44957375526428
Epoch 8 Batch 0 Loss 0.5030 Accuracy 0.8887
Epoch 8 Batch 50 Loss 0.5199 Accuracy 0.8885
Epoch 8 Batch 100 Loss 0.5158 Accuracy 0.8895
Epoch 8 Batch 150 Loss 0.5163 Accuracy 0.8898
Epoch 8 Batch 200 Loss 0.5160 Accuracy 0.8898
Epoch 8 Batch 250 Loss 0.5162 Accuracy 0.8895
Epoch 8 Batch 300 Loss 0.5174 Accuracy 0.8894
Epoch 8 Batch 350 Loss 0.5182 Accuracy 0.8892
Epoch 8 Batch 400 Loss 0.5197 Accuracy 0.8890
Epoch 8 Batch 450 Loss 0.5201 Accuracy 0.8889
Epoch 8 Batch 500 Loss 0.5211 Accuracy 0.8888
Epoch 8 Batch 550 Loss 0.5225 Accuracy 0.8886
Epoch 8 Batch 600 Loss 0.5237 Accuracy 0.8885
Epoch 8 Batch 650 Loss 0.5248 Accuracy 0.8883
Epoch 8 Batch 700 Loss 0.5251 Accuracy 0.8883
Epoch 8 Batch 750 Loss 0.5256 Accuracy 0.8883
Epoch 8 Batch 800 Loss 0.5261 Accuracy 0.8882
Epoch 8 Batch 850 Loss 0.5263 Accuracy 0.8881
Epoch 8 Batch 900 Loss 0.5274 Accuracy 0.8879
Epoch 8 Batch 950 Loss 0.5278 Accuracy 0.8878
Epoch 8 Batch 1000 Loss 0.5284 Accuracy 0.8877
Epoch 8 Batch 1050 Loss 0.5291 Accuracy 0.8876
Epoch 8 Batch 1100 Loss 0.5293 Accuracy 0.8876
Epoch 8 Batch 1150 Loss 0.5301 Accuracy 0.8875
Epoch 8 Batch 1200 Loss 0.5305 Accuracy 0.8874
Epoch 8 Batch 1250 Loss 0.5308 Accuracy 0.8874
Epoch 8 Batch 1300 Loss 0.5313 Accuracy 0.8873
discarded batch 1345
Epoch 8 Batch 1350 Loss 0.5319 Accuracy 0.8873
Epoch 8 Batch 1400 Loss 0.5322 Accuracy 0.8873
Epoch 8 Batch 1450 Loss 0.5329 Accuracy 0.8872
Epoch 8 Batch 1500 Loss 0.5332 Accuracy 0.8872

wandb: WARNING Step must only increase in log calls.  Step 8 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.53372526>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8871536>}.

Epoch 8 Loss 0.5337 Accuracy 0.8872
Time taken for 1 epoch: 36.20550227165222 secs

epoch lasted: 36.21022582054138
Epoch 9 Batch 0 Loss 0.5106 Accuracy 0.8804
Epoch 9 Batch 50 Loss 0.5134 Accuracy 0.8896
Epoch 9 Batch 100 Loss 0.5118 Accuracy 0.8902
Epoch 9 Batch 150 Loss 0.5125 Accuracy 0.8901
Epoch 9 Batch 200 Loss 0.5125 Accuracy 0.8900
Epoch 9 Batch 250 Loss 0.5136 Accuracy 0.8896
Epoch 9 Batch 300 Loss 0.5155 Accuracy 0.8893
Epoch 9 Batch 350 Loss 0.5172 Accuracy 0.8892
Epoch 9 Batch 400 Loss 0.5167 Accuracy 0.8894
Epoch 9 Batch 450 Loss 0.5170 Accuracy 0.8893
Epoch 9 Batch 500 Loss 0.5176 Accuracy 0.8894
Epoch 9 Batch 550 Loss 0.5187 Accuracy 0.8892
Epoch 9 Batch 600 Loss 0.5194 Accuracy 0.8890
Epoch 9 Batch 650 Loss 0.5204 Accuracy 0.8888
Epoch 9 Batch 700 Loss 0.5208 Accuracy 0.8887
Epoch 9 Batch 750 Loss 0.5218 Accuracy 0.8886
Epoch 9 Batch 800 Loss 0.5224 Accuracy 0.8885
Epoch 9 Batch 850 Loss 0.5232 Accuracy 0.8884
Epoch 9 Batch 900 Loss 0.5240 Accuracy 0.8883
Epoch 9 Batch 950 Loss 0.5246 Accuracy 0.8882
Epoch 9 Batch 1000 Loss 0.5253 Accuracy 0.8882
Epoch 9 Batch 1050 Loss 0.5258 Accuracy 0.8881
Epoch 9 Batch 1100 Loss 0.5260 Accuracy 0.8880
Epoch 9 Batch 1150 Loss 0.5266 Accuracy 0.8880
Epoch 9 Batch 1200 Loss 0.5273 Accuracy 0.8879
Epoch 9 Batch 1250 Loss 0.5278 Accuracy 0.8878
Epoch 9 Batch 1300 Loss 0.5282 Accuracy 0.8878
discarded batch 1341
Epoch 9 Batch 1350 Loss 0.5285 Accuracy 0.8877
Epoch 9 Batch 1400 Loss 0.5291 Accuracy 0.8876
Epoch 9 Batch 1450 Loss 0.5296 Accuracy 0.8876
Epoch 9 Batch 1500 Loss 0.5298 Accuracy 0.8875

wandb: WARNING Step must only increase in log calls.  Step 9 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.530473>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88745606>}.

Epoch 9 Loss 0.5305 Accuracy 0.8875
Time taken for 1 epoch: 35.94664144515991 secs

epoch lasted: 35.95371723175049
Epoch 10 Batch 0 Loss 0.5210 Accuracy 0.8754
discarded batch 48
Epoch 10 Batch 50 Loss 0.5098 Accuracy 0.8895
Epoch 10 Batch 100 Loss 0.5061 Accuracy 0.8905
Epoch 10 Batch 150 Loss 0.5083 Accuracy 0.8900
Epoch 10 Batch 200 Loss 0.5105 Accuracy 0.8898
Epoch 10 Batch 250 Loss 0.5106 Accuracy 0.8900
Epoch 10 Batch 300 Loss 0.5103 Accuracy 0.8902
Epoch 10 Batch 350 Loss 0.5113 Accuracy 0.8902
Epoch 10 Batch 400 Loss 0.5124 Accuracy 0.8900
Epoch 10 Batch 450 Loss 0.5140 Accuracy 0.8897
Epoch 10 Batch 500 Loss 0.5146 Accuracy 0.8896
Epoch 10 Batch 550 Loss 0.5152 Accuracy 0.8895
Epoch 10 Batch 600 Loss 0.5160 Accuracy 0.8893
Epoch 10 Batch 650 Loss 0.5168 Accuracy 0.8892
Epoch 10 Batch 700 Loss 0.5177 Accuracy 0.8891
Epoch 10 Batch 750 Loss 0.5178 Accuracy 0.8891
Epoch 10 Batch 800 Loss 0.5190 Accuracy 0.8890
Epoch 10 Batch 850 Loss 0.5198 Accuracy 0.8888
Epoch 10 Batch 900 Loss 0.5205 Accuracy 0.8887
Epoch 10 Batch 950 Loss 0.5210 Accuracy 0.8886
Epoch 10 Batch 1000 Loss 0.5214 Accuracy 0.8886
Epoch 10 Batch 1050 Loss 0.5218 Accuracy 0.8885
Epoch 10 Batch 1100 Loss 0.5224 Accuracy 0.8885
Epoch 10 Batch 1150 Loss 0.5231 Accuracy 0.8884
Epoch 10 Batch 1200 Loss 0.5233 Accuracy 0.8884
Epoch 10 Batch 1250 Loss 0.5239 Accuracy 0.8883
Epoch 10 Batch 1300 Loss 0.5245 Accuracy 0.8882
Epoch 10 Batch 1350 Loss 0.5250 Accuracy 0.8881
Epoch 10 Batch 1400 Loss 0.5254 Accuracy 0.8881
Epoch 10 Batch 1450 Loss 0.5261 Accuracy 0.8880
Epoch 10 Batch 1500 Loss 0.5268 Accuracy 0.8879

wandb: WARNING Step must only increase in log calls.  Step 10 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.52747667>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88784856>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-10
Epoch 10 Loss 0.5275 Accuracy 0.8878
Time taken for 1 epoch: 36.15867280960083 secs

epoch lasted: 36.16361117362976
Epoch 11 Batch 0 Loss 0.5125 Accuracy 0.8953
Epoch 11 Batch 50 Loss 0.5053 Accuracy 0.8903
Epoch 11 Batch 100 Loss 0.5082 Accuracy 0.8904
Epoch 11 Batch 150 Loss 0.5096 Accuracy 0.8903
Epoch 11 Batch 200 Loss 0.5109 Accuracy 0.8899
Epoch 11 Batch 250 Loss 0.5124 Accuracy 0.8899
Epoch 11 Batch 300 Loss 0.5123 Accuracy 0.8898
Epoch 11 Batch 350 Loss 0.5126 Accuracy 0.8899
Epoch 11 Batch 400 Loss 0.5128 Accuracy 0.8899
Epoch 11 Batch 450 Loss 0.5128 Accuracy 0.8898
Epoch 11 Batch 500 Loss 0.5135 Accuracy 0.8897
Epoch 11 Batch 550 Loss 0.5135 Accuracy 0.8898
Epoch 11 Batch 600 Loss 0.5146 Accuracy 0.8896
Epoch 11 Batch 650 Loss 0.5146 Accuracy 0.8897
Epoch 11 Batch 700 Loss 0.5154 Accuracy 0.8896
Epoch 11 Batch 750 Loss 0.5164 Accuracy 0.8894
Epoch 11 Batch 800 Loss 0.5168 Accuracy 0.8894
Epoch 11 Batch 850 Loss 0.5169 Accuracy 0.8894
Epoch 11 Batch 900 Loss 0.5173 Accuracy 0.8893
Epoch 11 Batch 950 Loss 0.5181 Accuracy 0.8892
Epoch 11 Batch 1000 Loss 0.5181 Accuracy 0.8892
Epoch 11 Batch 1050 Loss 0.5189 Accuracy 0.8890
Epoch 11 Batch 1100 Loss 0.5192 Accuracy 0.8890
Epoch 11 Batch 1150 Loss 0.5198 Accuracy 0.8889
Epoch 11 Batch 1200 Loss 0.5206 Accuracy 0.8888
Epoch 11 Batch 1250 Loss 0.5211 Accuracy 0.8887
Epoch 11 Batch 1300 Loss 0.5216 Accuracy 0.8887
Epoch 11 Batch 1350 Loss 0.5223 Accuracy 0.8886
Epoch 11 Batch 1400 Loss 0.5228 Accuracy 0.8885
discarded batch 1437
Epoch 11 Batch 1450 Loss 0.5232 Accuracy 0.8885
Epoch 11 Batch 1500 Loss 0.5239 Accuracy 0.8884

wandb: WARNING Step must only increase in log calls.  Step 11 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5241282>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88837403>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 23; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.76928395>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8653378>}.

Epoch 11 Loss 0.5241 Accuracy 0.8884
Time taken for 1 epoch: 35.88739013671875 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.7693 Accuracy 0.8653

epoch lasted: 36.04151749610901
Epoch 12 Batch 0 Loss 0.4778 Accuracy 0.8987
Epoch 12 Batch 50 Loss 0.4984 Accuracy 0.8934
Epoch 12 Batch 100 Loss 0.5004 Accuracy 0.8933
Epoch 12 Batch 150 Loss 0.5034 Accuracy 0.8922
Epoch 12 Batch 200 Loss 0.5020 Accuracy 0.8922
Epoch 12 Batch 250 Loss 0.5041 Accuracy 0.8918
Epoch 12 Batch 300 Loss 0.5060 Accuracy 0.8916
Epoch 12 Batch 350 Loss 0.5057 Accuracy 0.8918
Epoch 12 Batch 400 Loss 0.5057 Accuracy 0.8916
Epoch 12 Batch 450 Loss 0.5071 Accuracy 0.8913
Epoch 12 Batch 500 Loss 0.5088 Accuracy 0.8910
Epoch 12 Batch 550 Loss 0.5097 Accuracy 0.8909
Epoch 12 Batch 600 Loss 0.5105 Accuracy 0.8907
Epoch 12 Batch 650 Loss 0.5111 Accuracy 0.8906
Epoch 12 Batch 700 Loss 0.5120 Accuracy 0.8905
Epoch 12 Batch 750 Loss 0.5126 Accuracy 0.8903
Epoch 12 Batch 800 Loss 0.5131 Accuracy 0.8903
Epoch 12 Batch 850 Loss 0.5136 Accuracy 0.8902
Epoch 12 Batch 900 Loss 0.5142 Accuracy 0.8902
Epoch 12 Batch 950 Loss 0.5148 Accuracy 0.8901
Epoch 12 Batch 1000 Loss 0.5151 Accuracy 0.8900
Epoch 12 Batch 1050 Loss 0.5157 Accuracy 0.8899
Epoch 12 Batch 1100 Loss 0.5166 Accuracy 0.8898
Epoch 12 Batch 1150 Loss 0.5169 Accuracy 0.8897
Epoch 12 Batch 1200 Loss 0.5172 Accuracy 0.8897
Epoch 12 Batch 1250 Loss 0.5178 Accuracy 0.8896
Epoch 12 Batch 1300 Loss 0.5183 Accuracy 0.8895
Epoch 12 Batch 1350 Loss 0.5191 Accuracy 0.8894
discarded batch 1376
Epoch 12 Batch 1400 Loss 0.5197 Accuracy 0.8893
Epoch 12 Batch 1450 Loss 0.5203 Accuracy 0.8892
Epoch 12 Batch 1500 Loss 0.5208 Accuracy 0.8891

wandb: WARNING Step must only increase in log calls.  Step 12 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.521029>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88907427>}.

Epoch 12 Loss 0.5210 Accuracy 0.8891
Time taken for 1 epoch: 35.94113850593567 secs

epoch lasted: 35.9458544254303
Epoch 13 Batch 0 Loss 0.5276 Accuracy 0.8904
Epoch 13 Batch 50 Loss 0.4985 Accuracy 0.8923
Epoch 13 Batch 100 Loss 0.4980 Accuracy 0.8919
Epoch 13 Batch 150 Loss 0.4989 Accuracy 0.8922
Epoch 13 Batch 200 Loss 0.5006 Accuracy 0.8920
Epoch 13 Batch 250 Loss 0.5005 Accuracy 0.8923
Epoch 13 Batch 300 Loss 0.5019 Accuracy 0.8918
Epoch 13 Batch 350 Loss 0.5015 Accuracy 0.8919
Epoch 13 Batch 400 Loss 0.5027 Accuracy 0.8917
Epoch 13 Batch 450 Loss 0.5028 Accuracy 0.8917
Epoch 13 Batch 500 Loss 0.5032 Accuracy 0.8917
Epoch 13 Batch 550 Loss 0.5040 Accuracy 0.8916
Epoch 13 Batch 600 Loss 0.5055 Accuracy 0.8913
Epoch 13 Batch 650 Loss 0.5059 Accuracy 0.8910
Epoch 13 Batch 700 Loss 0.5066 Accuracy 0.8909
Epoch 13 Batch 750 Loss 0.5075 Accuracy 0.8908
Epoch 13 Batch 800 Loss 0.5084 Accuracy 0.8907
Epoch 13 Batch 850 Loss 0.5092 Accuracy 0.8906
Epoch 13 Batch 900 Loss 0.5099 Accuracy 0.8904
Epoch 13 Batch 950 Loss 0.5105 Accuracy 0.8903
Epoch 13 Batch 1000 Loss 0.5113 Accuracy 0.8903
Epoch 13 Batch 1050 Loss 0.5119 Accuracy 0.8902
Epoch 13 Batch 1100 Loss 0.5123 Accuracy 0.8901
Epoch 13 Batch 1150 Loss 0.5128 Accuracy 0.8901
Epoch 13 Batch 1200 Loss 0.5134 Accuracy 0.8900
Epoch 13 Batch 1250 Loss 0.5142 Accuracy 0.8898
discarded batch 1296
Epoch 13 Batch 1300 Loss 0.5146 Accuracy 0.8898
Epoch 13 Batch 1350 Loss 0.5154 Accuracy 0.8897
Epoch 13 Batch 1400 Loss 0.5157 Accuracy 0.8896
Epoch 13 Batch 1450 Loss 0.5160 Accuracy 0.8896
Epoch 13 Batch 1500 Loss 0.5169 Accuracy 0.8895

wandb: WARNING Step must only increase in log calls.  Step 13 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.51732236>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.889455>}.

Epoch 13 Loss 0.5173 Accuracy 0.8895
Time taken for 1 epoch: 35.90067386627197 secs

epoch lasted: 35.91162705421448
Epoch 14 Batch 0 Loss 0.4254 Accuracy 0.8970
Epoch 14 Batch 50 Loss 0.4878 Accuracy 0.8939
Epoch 14 Batch 100 Loss 0.4903 Accuracy 0.8935
Epoch 14 Batch 150 Loss 0.4940 Accuracy 0.8932
Epoch 14 Batch 200 Loss 0.4962 Accuracy 0.8930
Epoch 14 Batch 250 Loss 0.4980 Accuracy 0.8929
Epoch 14 Batch 300 Loss 0.4986 Accuracy 0.8922
Epoch 14 Batch 350 Loss 0.5001 Accuracy 0.8919
Epoch 14 Batch 400 Loss 0.5010 Accuracy 0.8919
Epoch 14 Batch 450 Loss 0.5016 Accuracy 0.8917
Epoch 14 Batch 500 Loss 0.5033 Accuracy 0.8914
Epoch 14 Batch 550 Loss 0.5037 Accuracy 0.8914
Epoch 14 Batch 600 Loss 0.5044 Accuracy 0.8912
Epoch 14 Batch 650 Loss 0.5049 Accuracy 0.8912
Epoch 14 Batch 700 Loss 0.5055 Accuracy 0.8911
Epoch 14 Batch 750 Loss 0.5061 Accuracy 0.8910
Epoch 14 Batch 800 Loss 0.5069 Accuracy 0.8908
Epoch 14 Batch 850 Loss 0.5071 Accuracy 0.8908
Epoch 14 Batch 900 Loss 0.5079 Accuracy 0.8908
Epoch 14 Batch 950 Loss 0.5090 Accuracy 0.8907
Epoch 14 Batch 1000 Loss 0.5095 Accuracy 0.8906
Epoch 14 Batch 1050 Loss 0.5100 Accuracy 0.8906
Epoch 14 Batch 1100 Loss 0.5101 Accuracy 0.8906
Epoch 14 Batch 1150 Loss 0.5107 Accuracy 0.8905
Epoch 14 Batch 1200 Loss 0.5111 Accuracy 0.8904
Epoch 14 Batch 1250 Loss 0.5115 Accuracy 0.8903
Epoch 14 Batch 1300 Loss 0.5121 Accuracy 0.8902
Epoch 14 Batch 1350 Loss 0.5127 Accuracy 0.8901
Epoch 14 Batch 1400 Loss 0.5132 Accuracy 0.8900
Epoch 14 Batch 1450 Loss 0.5138 Accuracy 0.8899
discarded batch 1469
Epoch 14 Batch 1500 Loss 0.5142 Accuracy 0.8899

wandb: WARNING Step must only increase in log calls.  Step 14 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5145166>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.88977563>}.

Epoch 14 Loss 0.5145 Accuracy 0.8898
Time taken for 1 epoch: 35.95820140838623 secs

epoch lasted: 35.96310520172119
Epoch 15 Batch 0 Loss 0.4957 Accuracy 0.8821
Epoch 15 Batch 50 Loss 0.4963 Accuracy 0.8928
Epoch 15 Batch 100 Loss 0.4934 Accuracy 0.8935
Epoch 15 Batch 150 Loss 0.4904 Accuracy 0.8935
Epoch 15 Batch 200 Loss 0.4939 Accuracy 0.8930
discarded batch 231
Epoch 15 Batch 250 Loss 0.4934 Accuracy 0.8931
Epoch 15 Batch 300 Loss 0.4949 Accuracy 0.8930
Epoch 15 Batch 350 Loss 0.4962 Accuracy 0.8925
Epoch 15 Batch 400 Loss 0.4971 Accuracy 0.8924
Epoch 15 Batch 450 Loss 0.4991 Accuracy 0.8921
Epoch 15 Batch 500 Loss 0.4997 Accuracy 0.8920
Epoch 15 Batch 550 Loss 0.5001 Accuracy 0.8919
Epoch 15 Batch 600 Loss 0.5009 Accuracy 0.8919
Epoch 15 Batch 650 Loss 0.5014 Accuracy 0.8917
Epoch 15 Batch 700 Loss 0.5022 Accuracy 0.8915
Epoch 15 Batch 750 Loss 0.5027 Accuracy 0.8914
Epoch 15 Batch 800 Loss 0.5036 Accuracy 0.8913
Epoch 15 Batch 850 Loss 0.5042 Accuracy 0.8913
Epoch 15 Batch 900 Loss 0.5049 Accuracy 0.8912
Epoch 15 Batch 950 Loss 0.5055 Accuracy 0.8911
Epoch 15 Batch 1000 Loss 0.5065 Accuracy 0.8909
Epoch 15 Batch 1050 Loss 0.5069 Accuracy 0.8908
Epoch 15 Batch 1100 Loss 0.5071 Accuracy 0.8908
Epoch 15 Batch 1150 Loss 0.5076 Accuracy 0.8907
Epoch 15 Batch 1200 Loss 0.5078 Accuracy 0.8907
Epoch 15 Batch 1250 Loss 0.5080 Accuracy 0.8907
Epoch 15 Batch 1300 Loss 0.5087 Accuracy 0.8906
Epoch 15 Batch 1350 Loss 0.5093 Accuracy 0.8905
Epoch 15 Batch 1400 Loss 0.5096 Accuracy 0.8904
Epoch 15 Batch 1450 Loss 0.5101 Accuracy 0.8904
Epoch 15 Batch 1500 Loss 0.5106 Accuracy 0.8903

wandb: WARNING Step must only increase in log calls.  Step 15 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.51109105>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8902293>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-11
Epoch 15 Loss 0.5111 Accuracy 0.8902
Time taken for 1 epoch: 36.166096687316895 secs

epoch lasted: 36.169883489608765
Epoch 16 Batch 0 Loss 0.4517 Accuracy 0.9003
Epoch 16 Batch 50 Loss 0.4904 Accuracy 0.8946
Epoch 16 Batch 100 Loss 0.4883 Accuracy 0.8942
Epoch 16 Batch 150 Loss 0.4886 Accuracy 0.8936
Epoch 16 Batch 200 Loss 0.4909 Accuracy 0.8933
Epoch 16 Batch 250 Loss 0.4909 Accuracy 0.8935
Epoch 16 Batch 300 Loss 0.4931 Accuracy 0.8932
Epoch 16 Batch 350 Loss 0.4937 Accuracy 0.8930
Epoch 16 Batch 400 Loss 0.4948 Accuracy 0.8928
Epoch 16 Batch 450 Loss 0.4950 Accuracy 0.8928
Epoch 16 Batch 500 Loss 0.4961 Accuracy 0.8925
Epoch 16 Batch 550 Loss 0.4970 Accuracy 0.8923
Epoch 16 Batch 600 Loss 0.4982 Accuracy 0.8923
Epoch 16 Batch 650 Loss 0.4988 Accuracy 0.8921
Epoch 16 Batch 700 Loss 0.4994 Accuracy 0.8919
Epoch 16 Batch 750 Loss 0.5005 Accuracy 0.8919
Epoch 16 Batch 800 Loss 0.5010 Accuracy 0.8918
Epoch 16 Batch 850 Loss 0.5015 Accuracy 0.8917
discarded batch 881
Epoch 16 Batch 900 Loss 0.5025 Accuracy 0.8916
Epoch 16 Batch 950 Loss 0.5028 Accuracy 0.8916
Epoch 16 Batch 1000 Loss 0.5032 Accuracy 0.8915
Epoch 16 Batch 1050 Loss 0.5036 Accuracy 0.8914
Epoch 16 Batch 1100 Loss 0.5043 Accuracy 0.8913
Epoch 16 Batch 1150 Loss 0.5047 Accuracy 0.8912
Epoch 16 Batch 1200 Loss 0.5052 Accuracy 0.8912
Epoch 16 Batch 1250 Loss 0.5055 Accuracy 0.8912
Epoch 16 Batch 1300 Loss 0.5061 Accuracy 0.8911
Epoch 16 Batch 1350 Loss 0.5070 Accuracy 0.8910
Epoch 16 Batch 1400 Loss 0.5076 Accuracy 0.8909
Epoch 16 Batch 1450 Loss 0.5080 Accuracy 0.8908
Epoch 16 Batch 1500 Loss 0.5084 Accuracy 0.8907

wandb: WARNING Step must only increase in log calls.  Step 16 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.50870264>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8906271>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 23; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.77920043>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86677736>}.

Epoch 16 Loss 0.5087 Accuracy 0.8906
Time taken for 1 epoch: 35.84124755859375 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.7792 Accuracy 0.8668

epoch lasted: 35.995779275894165
Epoch 17 Batch 0 Loss 0.4798 Accuracy 0.9003
Epoch 17 Batch 50 Loss 0.4907 Accuracy 0.8934
Epoch 17 Batch 100 Loss 0.4878 Accuracy 0.8935
Epoch 17 Batch 150 Loss 0.4893 Accuracy 0.8933
Epoch 17 Batch 200 Loss 0.4894 Accuracy 0.8937
Epoch 17 Batch 250 Loss 0.4885 Accuracy 0.8937
Epoch 17 Batch 300 Loss 0.4876 Accuracy 0.8936
Epoch 17 Batch 350 Loss 0.4887 Accuracy 0.8935
Epoch 17 Batch 400 Loss 0.4900 Accuracy 0.8934
discarded batch 411
Epoch 17 Batch 450 Loss 0.4919 Accuracy 0.8931
Epoch 17 Batch 500 Loss 0.4920 Accuracy 0.8931
Epoch 17 Batch 550 Loss 0.4932 Accuracy 0.8928
Epoch 17 Batch 600 Loss 0.4937 Accuracy 0.8928
Epoch 17 Batch 650 Loss 0.4943 Accuracy 0.8927
Epoch 17 Batch 700 Loss 0.4952 Accuracy 0.8925
Epoch 17 Batch 750 Loss 0.4957 Accuracy 0.8925
Epoch 17 Batch 800 Loss 0.4974 Accuracy 0.8923
Epoch 17 Batch 850 Loss 0.4974 Accuracy 0.8924
Epoch 17 Batch 900 Loss 0.4977 Accuracy 0.8923
Epoch 17 Batch 950 Loss 0.4984 Accuracy 0.8921
Epoch 17 Batch 1000 Loss 0.4991 Accuracy 0.8920
Epoch 17 Batch 1050 Loss 0.4998 Accuracy 0.8920
Epoch 17 Batch 1100 Loss 0.5005 Accuracy 0.8919
Epoch 17 Batch 1150 Loss 0.5013 Accuracy 0.8918
Epoch 17 Batch 1200 Loss 0.5018 Accuracy 0.8918
Epoch 17 Batch 1250 Loss 0.5023 Accuracy 0.8917
Epoch 17 Batch 1300 Loss 0.5028 Accuracy 0.8916
Epoch 17 Batch 1350 Loss 0.5034 Accuracy 0.8916
Epoch 17 Batch 1400 Loss 0.5037 Accuracy 0.8915
Epoch 17 Batch 1450 Loss 0.5042 Accuracy 0.8914
Epoch 17 Batch 1500 Loss 0.5048 Accuracy 0.8913

wandb: WARNING Step must only increase in log calls.  Step 17 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.50559765>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8912212>}.

Epoch 17 Loss 0.5056 Accuracy 0.8912
Time taken for 1 epoch: 35.84459567070007 secs

epoch lasted: 35.85041069984436
Epoch 18 Batch 0 Loss 0.4606 Accuracy 0.9070
discarded batch 22
Epoch 18 Batch 50 Loss 0.4805 Accuracy 0.8948
Epoch 18 Batch 100 Loss 0.4797 Accuracy 0.8946
Epoch 18 Batch 150 Loss 0.4825 Accuracy 0.8942
Epoch 18 Batch 200 Loss 0.4813 Accuracy 0.8947
Epoch 18 Batch 250 Loss 0.4821 Accuracy 0.8946
Epoch 18 Batch 300 Loss 0.4853 Accuracy 0.8941
Epoch 18 Batch 350 Loss 0.4862 Accuracy 0.8940
Epoch 18 Batch 400 Loss 0.4878 Accuracy 0.8938
Epoch 18 Batch 450 Loss 0.4884 Accuracy 0.8935
Epoch 18 Batch 500 Loss 0.4895 Accuracy 0.8933
Epoch 18 Batch 550 Loss 0.4900 Accuracy 0.8933
Epoch 18 Batch 600 Loss 0.4908 Accuracy 0.8932
Epoch 18 Batch 650 Loss 0.4920 Accuracy 0.8931
Epoch 18 Batch 700 Loss 0.4925 Accuracy 0.8930
Epoch 18 Batch 750 Loss 0.4930 Accuracy 0.8929
Epoch 18 Batch 800 Loss 0.4934 Accuracy 0.8928
Epoch 18 Batch 850 Loss 0.4941 Accuracy 0.8925
Epoch 18 Batch 900 Loss 0.4947 Accuracy 0.8924
Epoch 18 Batch 950 Loss 0.4954 Accuracy 0.8923
Epoch 18 Batch 1000 Loss 0.4958 Accuracy 0.8922
Epoch 18 Batch 1050 Loss 0.4968 Accuracy 0.8921
Epoch 18 Batch 1100 Loss 0.4976 Accuracy 0.8921
Epoch 18 Batch 1150 Loss 0.4982 Accuracy 0.8920
Epoch 18 Batch 1200 Loss 0.4988 Accuracy 0.8919
Epoch 18 Batch 1250 Loss 0.4992 Accuracy 0.8919
Epoch 18 Batch 1300 Loss 0.4998 Accuracy 0.8917
Epoch 18 Batch 1350 Loss 0.5004 Accuracy 0.8917
Epoch 18 Batch 1400 Loss 0.5008 Accuracy 0.8916
Epoch 18 Batch 1450 Loss 0.5014 Accuracy 0.8915
Epoch 18 Batch 1500 Loss 0.5019 Accuracy 0.8915

wandb: WARNING Step must only increase in log calls.  Step 18 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.5024943>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8913381>}.

Epoch 18 Loss 0.5025 Accuracy 0.8913
Time taken for 1 epoch: 35.82432007789612 secs

epoch lasted: 35.831557512283325
Epoch 19 Batch 0 Loss 0.4655 Accuracy 0.9020
Epoch 19 Batch 50 Loss 0.4736 Accuracy 0.8954
Epoch 19 Batch 100 Loss 0.4724 Accuracy 0.8953
Epoch 19 Batch 150 Loss 0.4765 Accuracy 0.8946
Epoch 19 Batch 200 Loss 0.4764 Accuracy 0.8948
Epoch 19 Batch 250 Loss 0.4796 Accuracy 0.8941
Epoch 19 Batch 300 Loss 0.4821 Accuracy 0.8941
Epoch 19 Batch 350 Loss 0.4825 Accuracy 0.8939
Epoch 19 Batch 400 Loss 0.4830 Accuracy 0.8938
Epoch 19 Batch 450 Loss 0.4832 Accuracy 0.8938
Epoch 19 Batch 500 Loss 0.4844 Accuracy 0.8937
Epoch 19 Batch 550 Loss 0.4856 Accuracy 0.8935
Epoch 19 Batch 600 Loss 0.4865 Accuracy 0.8933
Epoch 19 Batch 650 Loss 0.4875 Accuracy 0.8931
Epoch 19 Batch 700 Loss 0.4887 Accuracy 0.8930
Epoch 19 Batch 750 Loss 0.4895 Accuracy 0.8928
Epoch 19 Batch 800 Loss 0.4906 Accuracy 0.8927
Epoch 19 Batch 850 Loss 0.4913 Accuracy 0.8927
Epoch 19 Batch 900 Loss 0.4920 Accuracy 0.8926
Epoch 19 Batch 950 Loss 0.4929 Accuracy 0.8925
Epoch 19 Batch 1000 Loss 0.4937 Accuracy 0.8924
Epoch 19 Batch 1050 Loss 0.4946 Accuracy 0.8923
discarded batch 1081
Epoch 19 Batch 1100 Loss 0.4953 Accuracy 0.8921
Epoch 19 Batch 1150 Loss 0.4958 Accuracy 0.8921
Epoch 19 Batch 1200 Loss 0.4962 Accuracy 0.8921
Epoch 19 Batch 1250 Loss 0.4966 Accuracy 0.8920
Epoch 19 Batch 1300 Loss 0.4972 Accuracy 0.8920
Epoch 19 Batch 1350 Loss 0.4979 Accuracy 0.8919
Epoch 19 Batch 1400 Loss 0.4982 Accuracy 0.8918
Epoch 19 Batch 1450 Loss 0.4986 Accuracy 0.8918
Epoch 19 Batch 1500 Loss 0.4991 Accuracy 0.8918

wandb: WARNING Step must only increase in log calls.  Step 19 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4998074>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8916705>}.

Epoch 19 Loss 0.4998 Accuracy 0.8917
Time taken for 1 epoch: 35.77266049385071 secs

epoch lasted: 35.77704691886902
Epoch 20 Batch 0 Loss 0.5113 Accuracy 0.8953
Epoch 20 Batch 50 Loss 0.4752 Accuracy 0.8948
Epoch 20 Batch 100 Loss 0.4766 Accuracy 0.8935
Epoch 20 Batch 150 Loss 0.4782 Accuracy 0.8940
Epoch 20 Batch 200 Loss 0.4804 Accuracy 0.8939
Epoch 20 Batch 250 Loss 0.4802 Accuracy 0.8938
Epoch 20 Batch 300 Loss 0.4810 Accuracy 0.8936
Epoch 20 Batch 350 Loss 0.4816 Accuracy 0.8936
Epoch 20 Batch 400 Loss 0.4828 Accuracy 0.8934
Epoch 20 Batch 450 Loss 0.4836 Accuracy 0.8934
Epoch 20 Batch 500 Loss 0.4843 Accuracy 0.8933
Epoch 20 Batch 550 Loss 0.4854 Accuracy 0.8931
Epoch 20 Batch 600 Loss 0.4865 Accuracy 0.8930
Epoch 20 Batch 650 Loss 0.4871 Accuracy 0.8931
Epoch 20 Batch 700 Loss 0.4882 Accuracy 0.8930
Epoch 20 Batch 750 Loss 0.4884 Accuracy 0.8930
discarded batch 765
Epoch 20 Batch 800 Loss 0.4891 Accuracy 0.8930
Epoch 20 Batch 850 Loss 0.4900 Accuracy 0.8929
Epoch 20 Batch 900 Loss 0.4908 Accuracy 0.8928
Epoch 20 Batch 950 Loss 0.4912 Accuracy 0.8928
Epoch 20 Batch 1000 Loss 0.4916 Accuracy 0.8928
Epoch 20 Batch 1050 Loss 0.4917 Accuracy 0.8927
Epoch 20 Batch 1100 Loss 0.4923 Accuracy 0.8927
Epoch 20 Batch 1150 Loss 0.4926 Accuracy 0.8927
Epoch 20 Batch 1200 Loss 0.4932 Accuracy 0.8926
Epoch 20 Batch 1250 Loss 0.4937 Accuracy 0.8925
Epoch 20 Batch 1300 Loss 0.4944 Accuracy 0.8924
Epoch 20 Batch 1350 Loss 0.4947 Accuracy 0.8923
Epoch 20 Batch 1400 Loss 0.4951 Accuracy 0.8922
Epoch 20 Batch 1450 Loss 0.4957 Accuracy 0.8922
Epoch 20 Batch 1500 Loss 0.4960 Accuracy 0.8921

wandb: WARNING Step must only increase in log calls.  Step 20 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4965568>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89205873>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-12
Epoch 20 Loss 0.4966 Accuracy 0.8921
Time taken for 1 epoch: 36.02288293838501 secs

epoch lasted: 36.03263831138611
Epoch 21 Batch 0 Loss 0.4436 Accuracy 0.8970
Epoch 21 Batch 50 Loss 0.4653 Accuracy 0.8984
Epoch 21 Batch 100 Loss 0.4711 Accuracy 0.8972
Epoch 21 Batch 150 Loss 0.4747 Accuracy 0.8961
Epoch 21 Batch 200 Loss 0.4748 Accuracy 0.8962
Epoch 21 Batch 250 Loss 0.4750 Accuracy 0.8960
Epoch 21 Batch 300 Loss 0.4765 Accuracy 0.8957
Epoch 21 Batch 350 Loss 0.4763 Accuracy 0.8957
Epoch 21 Batch 400 Loss 0.4771 Accuracy 0.8956
Epoch 21 Batch 450 Loss 0.4777 Accuracy 0.8954
Epoch 21 Batch 500 Loss 0.4787 Accuracy 0.8954
Epoch 21 Batch 550 Loss 0.4792 Accuracy 0.8952
Epoch 21 Batch 600 Loss 0.4806 Accuracy 0.8950
Epoch 21 Batch 650 Loss 0.4822 Accuracy 0.8947
Epoch 21 Batch 700 Loss 0.4830 Accuracy 0.8944
Epoch 21 Batch 750 Loss 0.4836 Accuracy 0.8944
Epoch 21 Batch 800 Loss 0.4838 Accuracy 0.8944
Epoch 21 Batch 850 Loss 0.4842 Accuracy 0.8943
Epoch 21 Batch 900 Loss 0.4853 Accuracy 0.8941
Epoch 21 Batch 950 Loss 0.4863 Accuracy 0.8941
Epoch 21 Batch 1000 Loss 0.4866 Accuracy 0.8939
Epoch 21 Batch 1050 Loss 0.4872 Accuracy 0.8938
Epoch 21 Batch 1100 Loss 0.4882 Accuracy 0.8937
Epoch 21 Batch 1150 Loss 0.4891 Accuracy 0.8935
Epoch 21 Batch 1200 Loss 0.4898 Accuracy 0.8934
Epoch 21 Batch 1250 Loss 0.4901 Accuracy 0.8933
Epoch 21 Batch 1300 Loss 0.4905 Accuracy 0.8932
Epoch 21 Batch 1350 Loss 0.4911 Accuracy 0.8932
Epoch 21 Batch 1400 Loss 0.4918 Accuracy 0.8931
Epoch 21 Batch 1450 Loss 0.4923 Accuracy 0.8930
Epoch 21 Batch 1500 Loss 0.4929 Accuracy 0.8929
discarded batch 1526

wandb: WARNING Step must only increase in log calls.  Step 21 < 23; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.49323624>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8928105>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 23; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.7811023>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8662237>}.

Epoch 21 Loss 0.4932 Accuracy 0.8928
Time taken for 1 epoch: 35.76987838745117 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.7811 Accuracy 0.8662

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 quan|do |fe|cer |di |sé |stes|sa |né |mag|gio|ne|
e |io |sen|ti’ |chia|ro |son |un |po|e|ra|
e |io |fui |pres|so a |la |sua |na|scon|cia|ne|
                                                                                                                                                                   
 e |an|da|vam |per |en|za |fos|se |fi|ra|
che |non |po|co |tem|po|scia |con |quel |gi|ro|
e |io |a |lui |che ’n |su |per |lo |fon|da|va|
 ché |di |ve|ni|ma |per |lo |mon|do e |na|scon|de|
con |que|sta |pro|ce|tà |del |mon|do |fal|se|
non |è |tan|to |fu |la |sua |na|tu|ra|de|
                                                                                                                                                                   
 che |già |e|ra |la |fi|glia |con|ti|zia|
non |po|scia |che |già |e|glia |di |là |o|ra|
e |que|sto |te|ne|det|to |fos|ser |do|
 ma |per|ch’ io |a |lui |ve|de|re in |sé |ve|ren|za|
se |quel|li |spir|to |di |cui |ve|ni|fe|sto|
e |io |a |lui |ve|der |que|sto |con|ten|de|
                                                                                                                                                                   
 di |que|sta |ca|gion |fu |con|vien |ch’ è |i|sto|
non |fu |det|to |mon|do e |di|sï|an|do|ni|
e |que|sto |fon|do|po |per |ac|cor|go|sto|
 che |ve|de|rai |del |mon|do |giù |per |la |bel|la|
se|gna|men|te |fu |la |gen|te |si |mon|ta|
que|sto |mon|te |fu |la |sua |di|man|gia|gna|
                                                                                                                                                                   
 per |ve|de|re in |sé |e |que|sta |cor|ren|za|
per |ve|ra |già |co|stui |po|sa |die|gna|gna|
di |noi |gi|ra|re e |giu|sti|man|da |men|za|
 e |io |ma|gi|ra|vi|gliar |s’ io |lui |per|ché |que|
già |e|stro |mio |di|nan|zi |che |non |o|ne|
que|sta |gen|te |che |per |la |tua |fi|glia |ca|
                                                                                                                                                                   
 e |di |quel |fon|te |già |e|ra |già |ca|ne|
di |re|gi|ra|men|te |sì |co|tal |o|ca|
e |io |lui |ch’ a |ve|de|sti|zia |si |ba|le|
 che |non |si |fe|ce |tut|ti |con |que|sto |mon|do|
que|sta |gen|te |con |que|sto |mon|te |fon|do|
e |que|sto |gi|na|scen|der |non |si |fon|do|
                                                                                                                                                                   
 ma |per|ché |tu |ve|de|rai |que|sto |fon|do|
con |al|tro |ve|nir |più |al|cun |fi|ni|do|
e |io |sen|ti’ |pen|sier |per |que|sto |fon|do|
 che |non |si |mos|si |mo|re e |per |ve|de|mo|ve|
già |e|ran |ce|re e |la|re e |gi|ra|gio|ve|
e |io |veg|gen|to |gi|noc|chia|ma|ni|fe|
                                                                                                                                                                   
 e |con |lui |che |non |fu |la |sua |pro|fon|da|
e |io |a |lui |ve|der|si a |la |fe|sa|zia|
in|tor|no |la |sua |ra|gion |ch’ è |cru|de|gna|
 di |que|sto |gi|ran|do a |sé |di |que|sto |mon|to|
con |que|sta |ca|gion |di |que|sta |per|se|ra|
e |que|sta |par|te |del |mon|do e |mal |ten|to|
                                                                                                                                                                   
 di |po|scia |che |di |lui |per |que|sto |mon|te|
e |io |lui |per |ve|den|tro a |que|sto |fon|do|
e |io |sen|ti’ |un |giu|sto |mon|do |fon|te|
 di |quel |che |pri|ma e |di |tut|to |fos|se |
la |
per |sua |na|tu|ra |già |fu |sì |to|
e |io |la|re |te|ra|men|te |ve|der |gi|ra|
                                                                                                                                                                    
 di |re|gi|ro |vol|ta |per |non |si |ra|gio|
per |non |si |mos|se |quel|la |che |s’ ap|pa|sto|
in|ten|der |la |gen|te |che ’l |pri|mo |gio|
 e |con |que|sta |te|sta |con |que|sto |ch’ è |or |gio|
non |si |ve|ren|za |del |mon|te |di|stin|zo|
e |que|sto |mon|te |di |qua |giù |con|ten|de|
                                                                                                                                                                   
 di |si |na|tu|ra |di |qua |giù |di|let|to!|
co|min|ciò |el|li a |me |quel |che |tu |por|se|
co|me |fa |far |ché |la |mia |don|na |por|to|
 e |se |non |è |ca|gion |di |là |giù |o|ra|
non |la|scia|te|ne|det|to |se |non |si |mon|te|
e |se |ne |la |val|la |val|le |sue |o|ra|
                                                                                                                                                                   
 di |que|sta |par|te e |tut|ta |più |non |por|ti|
e |io |e|ra |già |mai |è |buo|na |vo|ra|
e |io |a |lui |che ’n |sé |tut|ta |la |val|la|
 che |di |ma|e|stro |mio |ve|de|re e |giu|sti|zia|
po|scia |par|lar |di|nan|zi |ch’ i’ |non |è |po|
que|sto |gi|ran|no |do|ve |ve|der |gi|zia|
                                                                                                                                                                   
 che |di |co|lui |par|lar |que|sta |cor|te|sto|
e |un |prin|ci|pio |mio |ve|nir |sì |ca|ro|
di |que|sti |cor|po |gi|gan|ti |con|ce|sto|
 che |non |vi |man|dò |ma |per|ché |non |si |mon|ti|
e |co|me |que|sta |pri|ma |che |tu |ve|ra|
que|sto |mon|do in |sù |ve|der |non |si |fon|do|
                                                                                                                                                                   
 co|sì |sen |va |e |con |que|ste |pa|ro|la|
que|sta |mon|tar |più |e |que|sti |cor|ren|do|
a |que|sta |gen|te |per |ve|ra |con|da|gna|
 per |ch’ io |non |tor|men|te |di |que|sto |mon|te|gna|
e |ve|gna |ten|ti a |la |sua |ra|ce |mon|di|
ma |per |al|tri|men|te |di |que|sta |gen|te|
                                                                                                                                                                   
 che |già |e|ra|di|nan|zi |da |lui |cen|di|
co|me |que|sta |cor|te |già |e|sce |con|te|
e |io |a |lui |ch’ a |sé |sot|to ’l |mon|do|di|
 e |quel|la |cui |ve|de|stra |gi|men|te |ve|da|
che |ve|nir |con |la |sua |na|tu|ra |ca|glia|
di |quel |gi|ra|vi|glia|ta |sua |com|pa|da|
                                                                                                                                                                   
 per |que|sto |ca|gion |fu |mal |per|do|len|te|
per |ch’ io |mi |fu |già |mai |non |pur |pro|fon|da|
e |io |lui |per |far |ché |la |sua |dan|ni|da|
 e |di |que|sto |gi|na|va |di |ve|der|let|to|
que|sto |gi|na|va |che |già |in|ten|der |que|
fu |gna|men|te |di |co|lui |che |di|man|to|
                                                                                                                                                                   
 di |si |fe|de |la |sua |se|re|ve|de|
di |re|tro a |la |sua |ra|gio|re e |cor|ra |fon|to|
e |io |son |di |lui |che ’n |sé |stes|sa |o|de|

epoch lasted: 519.2152917385101
(1900, 128)
Epoch 1 Batch 0 Loss 0.4922 Accuracy 0.8970
discarded batch 4
Epoch 1 Batch 50 Loss 0.4737 Accuracy 0.8983
Epoch 1 Batch 100 Loss 0.4694 Accuracy 0.8971
Epoch 1 Batch 150 Loss 0.4690 Accuracy 0.8977
Epoch 1 Batch 200 Loss 0.4711 Accuracy 0.8970
Epoch 1 Batch 250 Loss 0.4715 Accuracy 0.8968
Epoch 1 Batch 300 Loss 0.4720 Accuracy 0.8965
Epoch 1 Batch 350 Loss 0.4737 Accuracy 0.8961
Epoch 1 Batch 400 Loss 0.4746 Accuracy 0.8957
Epoch 1 Batch 450 Loss 0.4759 Accuracy 0.8955
Epoch 1 Batch 500 Loss 0.4760 Accuracy 0.8954
Epoch 1 Batch 550 Loss 0.4764 Accuracy 0.8952
Epoch 1 Batch 600 Loss 0.4773 Accuracy 0.8953
Epoch 1 Batch 650 Loss 0.4785 Accuracy 0.8951
Epoch 1 Batch 700 Loss 0.4799 Accuracy 0.8949
Epoch 1 Batch 750 Loss 0.4805 Accuracy 0.8947
Epoch 1 Batch 800 Loss 0.4813 Accuracy 0.8946
Epoch 1 Batch 850 Loss 0.4822 Accuracy 0.8945
Epoch 1 Batch 900 Loss 0.4826 Accuracy 0.8944
Epoch 1 Batch 950 Loss 0.4838 Accuracy 0.8942
Epoch 1 Batch 1000 Loss 0.4842 Accuracy 0.8942
Epoch 1 Batch 1050 Loss 0.4849 Accuracy 0.8941
Epoch 1 Batch 1100 Loss 0.4858 Accuracy 0.8940
Epoch 1 Batch 1150 Loss 0.4863 Accuracy 0.8939
Epoch 1 Batch 1200 Loss 0.4869 Accuracy 0.8938
Epoch 1 Batch 1250 Loss 0.4877 Accuracy 0.8937
Epoch 1 Batch 1300 Loss 0.4883 Accuracy 0.8936
Epoch 1 Batch 1350 Loss 0.4887 Accuracy 0.8935
Epoch 1 Batch 1400 Loss 0.4892 Accuracy 0.8934
Epoch 1 Batch 1450 Loss 0.4896 Accuracy 0.8934
Epoch 1 Batch 1500 Loss 0.4903 Accuracy 0.8933

wandb: WARNING Step must only increase in log calls.  Step 1 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.49072796>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8932105>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 24; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.7811435>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8662237>}.

Epoch 1 Loss 0.4907 Accuracy 0.8932
Time taken for 1 epoch: 35.66631197929382 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.7811 Accuracy 0.8662

epoch lasted: 35.82115149497986
Epoch 2 Batch 0 Loss 0.4760 Accuracy 0.8904
Epoch 2 Batch 50 Loss 0.4638 Accuracy 0.8980
Epoch 2 Batch 100 Loss 0.4686 Accuracy 0.8971
Epoch 2 Batch 150 Loss 0.4676 Accuracy 0.8969
Epoch 2 Batch 200 Loss 0.4682 Accuracy 0.8971
Epoch 2 Batch 250 Loss 0.4694 Accuracy 0.8968
Epoch 2 Batch 300 Loss 0.4712 Accuracy 0.8964
Epoch 2 Batch 350 Loss 0.4725 Accuracy 0.8962
Epoch 2 Batch 400 Loss 0.4726 Accuracy 0.8960
Epoch 2 Batch 450 Loss 0.4732 Accuracy 0.8958
Epoch 2 Batch 500 Loss 0.4740 Accuracy 0.8958
Epoch 2 Batch 550 Loss 0.4754 Accuracy 0.8955
Epoch 2 Batch 600 Loss 0.4760 Accuracy 0.8955
Epoch 2 Batch 650 Loss 0.4765 Accuracy 0.8953
Epoch 2 Batch 700 Loss 0.4773 Accuracy 0.8951
Epoch 2 Batch 750 Loss 0.4776 Accuracy 0.8951
Epoch 2 Batch 800 Loss 0.4782 Accuracy 0.8951
Epoch 2 Batch 850 Loss 0.4786 Accuracy 0.8950
Epoch 2 Batch 900 Loss 0.4787 Accuracy 0.8949
Epoch 2 Batch 950 Loss 0.4793 Accuracy 0.8948
Epoch 2 Batch 1000 Loss 0.4803 Accuracy 0.8946
Epoch 2 Batch 1050 Loss 0.4809 Accuracy 0.8946
Epoch 2 Batch 1100 Loss 0.4815 Accuracy 0.8944
Epoch 2 Batch 1150 Loss 0.4819 Accuracy 0.8944
discarded batch 1177
Epoch 2 Batch 1200 Loss 0.4827 Accuracy 0.8943
Epoch 2 Batch 1250 Loss 0.4833 Accuracy 0.8941
Epoch 2 Batch 1300 Loss 0.4842 Accuracy 0.8940
Epoch 2 Batch 1350 Loss 0.4847 Accuracy 0.8940
Epoch 2 Batch 1400 Loss 0.4853 Accuracy 0.8940
Epoch 2 Batch 1450 Loss 0.4859 Accuracy 0.8939
Epoch 2 Batch 1500 Loss 0.4864 Accuracy 0.8938

wandb: WARNING Step must only increase in log calls.  Step 2 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.48702523>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8937081>}.

Epoch 2 Loss 0.4870 Accuracy 0.8937
Time taken for 1 epoch: 36.36301255226135 secs

epoch lasted: 36.36742687225342
Epoch 3 Batch 0 Loss 0.4522 Accuracy 0.9037
Epoch 3 Batch 50 Loss 0.4667 Accuracy 0.8967
Epoch 3 Batch 100 Loss 0.4623 Accuracy 0.8976
Epoch 3 Batch 150 Loss 0.4627 Accuracy 0.8977
Epoch 3 Batch 200 Loss 0.4645 Accuracy 0.8973
Epoch 3 Batch 250 Loss 0.4652 Accuracy 0.8972
Epoch 3 Batch 300 Loss 0.4662 Accuracy 0.8970
Epoch 3 Batch 350 Loss 0.4670 Accuracy 0.8972
Epoch 3 Batch 400 Loss 0.4671 Accuracy 0.8970
Epoch 3 Batch 450 Loss 0.4683 Accuracy 0.8968
Epoch 3 Batch 500 Loss 0.4702 Accuracy 0.8964
Epoch 3 Batch 550 Loss 0.4714 Accuracy 0.8963
Epoch 3 Batch 600 Loss 0.4726 Accuracy 0.8960
Epoch 3 Batch 650 Loss 0.4737 Accuracy 0.8958
Epoch 3 Batch 700 Loss 0.4740 Accuracy 0.8957
Epoch 3 Batch 750 Loss 0.4747 Accuracy 0.8956
Epoch 3 Batch 800 Loss 0.4766 Accuracy 0.8954
Epoch 3 Batch 850 Loss 0.4773 Accuracy 0.8954
Epoch 3 Batch 900 Loss 0.4778 Accuracy 0.8952
Epoch 3 Batch 950 Loss 0.4785 Accuracy 0.8951
Epoch 3 Batch 1000 Loss 0.4791 Accuracy 0.8950
Epoch 3 Batch 1050 Loss 0.4797 Accuracy 0.8949
Epoch 3 Batch 1100 Loss 0.4800 Accuracy 0.8948
Epoch 3 Batch 1150 Loss 0.4808 Accuracy 0.8947
Epoch 3 Batch 1200 Loss 0.4813 Accuracy 0.8946
Epoch 3 Batch 1250 Loss 0.4817 Accuracy 0.8945
Epoch 3 Batch 1300 Loss 0.4821 Accuracy 0.8945
Epoch 3 Batch 1350 Loss 0.4826 Accuracy 0.8944
Epoch 3 Batch 1400 Loss 0.4834 Accuracy 0.8943
Epoch 3 Batch 1450 Loss 0.4841 Accuracy 0.8942
Epoch 3 Batch 1500 Loss 0.4847 Accuracy 0.8942
discarded batch 1512

wandb: WARNING Step must only increase in log calls.  Step 3 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.48530284>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8940781>}.

Epoch 3 Loss 0.4853 Accuracy 0.8941
Time taken for 1 epoch: 36.319594860076904 secs

epoch lasted: 36.32372236251831
Epoch 4 Batch 0 Loss 0.4679 Accuracy 0.8904
Epoch 4 Batch 50 Loss 0.4505 Accuracy 0.8977
Epoch 4 Batch 100 Loss 0.4605 Accuracy 0.8967
Epoch 4 Batch 150 Loss 0.4613 Accuracy 0.8971
Epoch 4 Batch 200 Loss 0.4623 Accuracy 0.8971
Epoch 4 Batch 250 Loss 0.4640 Accuracy 0.8971
Epoch 4 Batch 300 Loss 0.4639 Accuracy 0.8972
Epoch 4 Batch 350 Loss 0.4654 Accuracy 0.8968
Epoch 4 Batch 400 Loss 0.4665 Accuracy 0.8968
Epoch 4 Batch 450 Loss 0.4676 Accuracy 0.8965
Epoch 4 Batch 500 Loss 0.4688 Accuracy 0.8963
Epoch 4 Batch 550 Loss 0.4701 Accuracy 0.8963
Epoch 4 Batch 600 Loss 0.4708 Accuracy 0.8961
Epoch 4 Batch 650 Loss 0.4707 Accuracy 0.8962
Epoch 4 Batch 700 Loss 0.4715 Accuracy 0.8959
Epoch 4 Batch 750 Loss 0.4722 Accuracy 0.8959
Epoch 4 Batch 800 Loss 0.4729 Accuracy 0.8959
Epoch 4 Batch 850 Loss 0.4734 Accuracy 0.8958
Epoch 4 Batch 900 Loss 0.4740 Accuracy 0.8957
Epoch 4 Batch 950 Loss 0.4748 Accuracy 0.8956
Epoch 4 Batch 1000 Loss 0.4753 Accuracy 0.8955
Epoch 4 Batch 1050 Loss 0.4760 Accuracy 0.8954
Epoch 4 Batch 1100 Loss 0.4767 Accuracy 0.8953
Epoch 4 Batch 1150 Loss 0.4774 Accuracy 0.8952
Epoch 4 Batch 1200 Loss 0.4777 Accuracy 0.8952
Epoch 4 Batch 1250 Loss 0.4784 Accuracy 0.8951
Epoch 4 Batch 1300 Loss 0.4791 Accuracy 0.8950
discarded batch 1316
Epoch 4 Batch 1350 Loss 0.4799 Accuracy 0.8949
Epoch 4 Batch 1400 Loss 0.4807 Accuracy 0.8947
Epoch 4 Batch 1450 Loss 0.4812 Accuracy 0.8947
Epoch 4 Batch 1500 Loss 0.4816 Accuracy 0.8946

wandb: WARNING Step must only increase in log calls.  Step 4 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4817804>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89449626>}.

Epoch 4 Loss 0.4818 Accuracy 0.8945
Time taken for 1 epoch: 36.17686700820923 secs

epoch lasted: 36.187471866607666
Epoch 5 Batch 0 Loss 0.4187 Accuracy 0.9020
Epoch 5 Batch 50 Loss 0.4584 Accuracy 0.8993
Epoch 5 Batch 100 Loss 0.4648 Accuracy 0.8980
Epoch 5 Batch 150 Loss 0.4627 Accuracy 0.8978
Epoch 5 Batch 200 Loss 0.4605 Accuracy 0.8983
Epoch 5 Batch 250 Loss 0.4617 Accuracy 0.8982
Epoch 5 Batch 300 Loss 0.4638 Accuracy 0.8975
Epoch 5 Batch 350 Loss 0.4639 Accuracy 0.8975
discarded batch 396
Epoch 5 Batch 400 Loss 0.4655 Accuracy 0.8972
Epoch 5 Batch 450 Loss 0.4665 Accuracy 0.8971
Epoch 5 Batch 500 Loss 0.4665 Accuracy 0.8971
Epoch 5 Batch 550 Loss 0.4670 Accuracy 0.8970
Epoch 5 Batch 600 Loss 0.4682 Accuracy 0.8967
Epoch 5 Batch 650 Loss 0.4689 Accuracy 0.8965
Epoch 5 Batch 700 Loss 0.4691 Accuracy 0.8965
Epoch 5 Batch 750 Loss 0.4699 Accuracy 0.8962
Epoch 5 Batch 800 Loss 0.4704 Accuracy 0.8961
Epoch 5 Batch 850 Loss 0.4714 Accuracy 0.8958
Epoch 5 Batch 900 Loss 0.4719 Accuracy 0.8958
Epoch 5 Batch 950 Loss 0.4726 Accuracy 0.8956
Epoch 5 Batch 1000 Loss 0.4728 Accuracy 0.8956
Epoch 5 Batch 1050 Loss 0.4735 Accuracy 0.8955
Epoch 5 Batch 1100 Loss 0.4738 Accuracy 0.8955
Epoch 5 Batch 1150 Loss 0.4747 Accuracy 0.8953
Epoch 5 Batch 1200 Loss 0.4754 Accuracy 0.8952
Epoch 5 Batch 1250 Loss 0.4761 Accuracy 0.8951
Epoch 5 Batch 1300 Loss 0.4766 Accuracy 0.8951
Epoch 5 Batch 1350 Loss 0.4774 Accuracy 0.8950
Epoch 5 Batch 1400 Loss 0.4774 Accuracy 0.8950
Epoch 5 Batch 1450 Loss 0.4779 Accuracy 0.8949
Epoch 5 Batch 1500 Loss 0.4785 Accuracy 0.8948

wandb: WARNING Step must only increase in log calls.  Step 5 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.47914872>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8947869>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-13
Epoch 5 Loss 0.4791 Accuracy 0.8948
Time taken for 1 epoch: 36.22892999649048 secs

epoch lasted: 36.232914686203
Epoch 6 Batch 0 Loss 0.4396 Accuracy 0.8937
Epoch 6 Batch 50 Loss 0.4427 Accuracy 0.9001
Epoch 6 Batch 100 Loss 0.4455 Accuracy 0.8998
Epoch 6 Batch 150 Loss 0.4520 Accuracy 0.8990
Epoch 6 Batch 200 Loss 0.4542 Accuracy 0.8984
Epoch 6 Batch 250 Loss 0.4561 Accuracy 0.8981
Epoch 6 Batch 300 Loss 0.4571 Accuracy 0.8980
Epoch 6 Batch 350 Loss 0.4581 Accuracy 0.8979
Epoch 6 Batch 400 Loss 0.4598 Accuracy 0.8977
Epoch 6 Batch 450 Loss 0.4608 Accuracy 0.8976
Epoch 6 Batch 500 Loss 0.4619 Accuracy 0.8976
Epoch 6 Batch 550 Loss 0.4626 Accuracy 0.8975
Epoch 6 Batch 600 Loss 0.4634 Accuracy 0.8974
Epoch 6 Batch 650 Loss 0.4651 Accuracy 0.8972
Epoch 6 Batch 700 Loss 0.4657 Accuracy 0.8971
Epoch 6 Batch 750 Loss 0.4663 Accuracy 0.8970
Epoch 6 Batch 800 Loss 0.4670 Accuracy 0.8970
Epoch 6 Batch 850 Loss 0.4671 Accuracy 0.8969
Epoch 6 Batch 900 Loss 0.4679 Accuracy 0.8968
Epoch 6 Batch 950 Loss 0.4686 Accuracy 0.8966
Epoch 6 Batch 1000 Loss 0.4696 Accuracy 0.8964
Epoch 6 Batch 1050 Loss 0.4704 Accuracy 0.8964
Epoch 6 Batch 1100 Loss 0.4710 Accuracy 0.8963
Epoch 6 Batch 1150 Loss 0.4717 Accuracy 0.8961
Epoch 6 Batch 1200 Loss 0.4726 Accuracy 0.8960
Epoch 6 Batch 1250 Loss 0.4732 Accuracy 0.8959
discarded batch 1271
Epoch 6 Batch 1300 Loss 0.4739 Accuracy 0.8959
Epoch 6 Batch 1350 Loss 0.4745 Accuracy 0.8958
Epoch 6 Batch 1400 Loss 0.4751 Accuracy 0.8957
Epoch 6 Batch 1450 Loss 0.4758 Accuracy 0.8956
Epoch 6 Batch 1500 Loss 0.4763 Accuracy 0.8955

wandb: WARNING Step must only increase in log calls.  Step 6 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.47697935>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8953703>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 24; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.78558>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8651163>}.

Epoch 6 Loss 0.4770 Accuracy 0.8954
Time taken for 1 epoch: 35.73602843284607 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.7856 Accuracy 0.8651

epoch lasted: 35.89087796211243
Epoch 7 Batch 0 Loss 0.4635 Accuracy 0.8854
Epoch 7 Batch 50 Loss 0.4428 Accuracy 0.9013
Epoch 7 Batch 100 Loss 0.4479 Accuracy 0.9003
Epoch 7 Batch 150 Loss 0.4491 Accuracy 0.8997
Epoch 7 Batch 200 Loss 0.4525 Accuracy 0.8990
Epoch 7 Batch 250 Loss 0.4538 Accuracy 0.8986
Epoch 7 Batch 300 Loss 0.4560 Accuracy 0.8987
Epoch 7 Batch 350 Loss 0.4570 Accuracy 0.8985
Epoch 7 Batch 400 Loss 0.4589 Accuracy 0.8981
Epoch 7 Batch 450 Loss 0.4602 Accuracy 0.8979
Epoch 7 Batch 500 Loss 0.4605 Accuracy 0.8978
Epoch 7 Batch 550 Loss 0.4606 Accuracy 0.8978
Epoch 7 Batch 600 Loss 0.4618 Accuracy 0.8975
Epoch 7 Batch 650 Loss 0.4619 Accuracy 0.8976
Epoch 7 Batch 700 Loss 0.4631 Accuracy 0.8973
Epoch 7 Batch 750 Loss 0.4639 Accuracy 0.8972
Epoch 7 Batch 800 Loss 0.4638 Accuracy 0.8971
Epoch 7 Batch 850 Loss 0.4646 Accuracy 0.8970
Epoch 7 Batch 900 Loss 0.4655 Accuracy 0.8969
Epoch 7 Batch 950 Loss 0.4661 Accuracy 0.8968
Epoch 7 Batch 1000 Loss 0.4670 Accuracy 0.8967
Epoch 7 Batch 1050 Loss 0.4680 Accuracy 0.8965
Epoch 7 Batch 1100 Loss 0.4684 Accuracy 0.8965
Epoch 7 Batch 1150 Loss 0.4692 Accuracy 0.8964
Epoch 7 Batch 1200 Loss 0.4699 Accuracy 0.8963
Epoch 7 Batch 1250 Loss 0.4705 Accuracy 0.8962
Epoch 7 Batch 1300 Loss 0.4710 Accuracy 0.8961
Epoch 7 Batch 1350 Loss 0.4717 Accuracy 0.8959
Epoch 7 Batch 1400 Loss 0.4723 Accuracy 0.8959
Epoch 7 Batch 1450 Loss 0.4732 Accuracy 0.8958
discarded batch 1455
Epoch 7 Batch 1500 Loss 0.4738 Accuracy 0.8957

wandb: WARNING Step must only increase in log calls.  Step 7 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.47428328>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89567375>}.

Epoch 7 Loss 0.4743 Accuracy 0.8957
Time taken for 1 epoch: 35.7734591960907 secs

epoch lasted: 35.77761101722717
Epoch 8 Batch 0 Loss 0.4331 Accuracy 0.9053
Epoch 8 Batch 50 Loss 0.4459 Accuracy 0.8988
Epoch 8 Batch 100 Loss 0.4466 Accuracy 0.8990
Epoch 8 Batch 150 Loss 0.4479 Accuracy 0.8990
Epoch 8 Batch 200 Loss 0.4493 Accuracy 0.8992
Epoch 8 Batch 250 Loss 0.4512 Accuracy 0.8987
Epoch 8 Batch 300 Loss 0.4530 Accuracy 0.8982
Epoch 8 Batch 350 Loss 0.4538 Accuracy 0.8981
Epoch 8 Batch 400 Loss 0.4553 Accuracy 0.8979
Epoch 8 Batch 450 Loss 0.4568 Accuracy 0.8977
Epoch 8 Batch 500 Loss 0.4575 Accuracy 0.8978
Epoch 8 Batch 550 Loss 0.4582 Accuracy 0.8978
discarded batch 577
Epoch 8 Batch 600 Loss 0.4593 Accuracy 0.8976
Epoch 8 Batch 650 Loss 0.4602 Accuracy 0.8975
Epoch 8 Batch 700 Loss 0.4607 Accuracy 0.8974
Epoch 8 Batch 750 Loss 0.4613 Accuracy 0.8974
Epoch 8 Batch 800 Loss 0.4619 Accuracy 0.8973
Epoch 8 Batch 850 Loss 0.4630 Accuracy 0.8971
Epoch 8 Batch 900 Loss 0.4635 Accuracy 0.8970
Epoch 8 Batch 950 Loss 0.4641 Accuracy 0.8970
Epoch 8 Batch 1000 Loss 0.4651 Accuracy 0.8968
Epoch 8 Batch 1050 Loss 0.4658 Accuracy 0.8967
Epoch 8 Batch 1100 Loss 0.4665 Accuracy 0.8966
Epoch 8 Batch 1150 Loss 0.4669 Accuracy 0.8965
Epoch 8 Batch 1200 Loss 0.4677 Accuracy 0.8964
Epoch 8 Batch 1250 Loss 0.4682 Accuracy 0.8964
Epoch 8 Batch 1300 Loss 0.4689 Accuracy 0.8963
Epoch 8 Batch 1350 Loss 0.4695 Accuracy 0.8962
Epoch 8 Batch 1400 Loss 0.4699 Accuracy 0.8961
Epoch 8 Batch 1450 Loss 0.4706 Accuracy 0.8961
Epoch 8 Batch 1500 Loss 0.4710 Accuracy 0.8960

wandb: WARNING Step must only increase in log calls.  Step 8 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.47144386>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89596975>}.

Epoch 8 Loss 0.4714 Accuracy 0.8960
Time taken for 1 epoch: 35.73056364059448 secs

epoch lasted: 35.735772371292114
Epoch 9 Batch 0 Loss 0.4607 Accuracy 0.9020
Epoch 9 Batch 50 Loss 0.4389 Accuracy 0.9015
Epoch 9 Batch 100 Loss 0.4440 Accuracy 0.9007
Epoch 9 Batch 150 Loss 0.4476 Accuracy 0.9001
Epoch 9 Batch 200 Loss 0.4494 Accuracy 0.8996
Epoch 9 Batch 250 Loss 0.4495 Accuracy 0.8992
Epoch 9 Batch 300 Loss 0.4501 Accuracy 0.8992
Epoch 9 Batch 350 Loss 0.4517 Accuracy 0.8992
Epoch 9 Batch 400 Loss 0.4527 Accuracy 0.8988
discarded batch 430
Epoch 9 Batch 450 Loss 0.4527 Accuracy 0.8989
Epoch 9 Batch 500 Loss 0.4540 Accuracy 0.8987
Epoch 9 Batch 550 Loss 0.4552 Accuracy 0.8986
Epoch 9 Batch 600 Loss 0.4568 Accuracy 0.8983
Epoch 9 Batch 650 Loss 0.4575 Accuracy 0.8983
Epoch 9 Batch 700 Loss 0.4578 Accuracy 0.8982
Epoch 9 Batch 750 Loss 0.4586 Accuracy 0.8980
Epoch 9 Batch 800 Loss 0.4598 Accuracy 0.8978
Epoch 9 Batch 850 Loss 0.4603 Accuracy 0.8977
Epoch 9 Batch 900 Loss 0.4610 Accuracy 0.8976
Epoch 9 Batch 950 Loss 0.4621 Accuracy 0.8975
Epoch 9 Batch 1000 Loss 0.4626 Accuracy 0.8973
Epoch 9 Batch 1050 Loss 0.4630 Accuracy 0.8972
Epoch 9 Batch 1100 Loss 0.4636 Accuracy 0.8971
Epoch 9 Batch 1150 Loss 0.4643 Accuracy 0.8970
Epoch 9 Batch 1200 Loss 0.4651 Accuracy 0.8969
Epoch 9 Batch 1250 Loss 0.4659 Accuracy 0.8968
Epoch 9 Batch 1300 Loss 0.4664 Accuracy 0.8967
Epoch 9 Batch 1350 Loss 0.4668 Accuracy 0.8967
Epoch 9 Batch 1400 Loss 0.4674 Accuracy 0.8966
Epoch 9 Batch 1450 Loss 0.4681 Accuracy 0.8965
Epoch 9 Batch 1500 Loss 0.4688 Accuracy 0.8964

wandb: WARNING Step must only increase in log calls.  Step 9 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.46922517>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8963193>}.

Epoch 9 Loss 0.4692 Accuracy 0.8963
Time taken for 1 epoch: 35.842490673065186 secs

epoch lasted: 35.85020685195923
Epoch 10 Batch 0 Loss 0.4361 Accuracy 0.9037
Epoch 10 Batch 50 Loss 0.4418 Accuracy 0.9012
Epoch 10 Batch 100 Loss 0.4460 Accuracy 0.9005
Epoch 10 Batch 150 Loss 0.4477 Accuracy 0.9001
Epoch 10 Batch 200 Loss 0.4477 Accuracy 0.9004
Epoch 10 Batch 250 Loss 0.4482 Accuracy 0.9002
Epoch 10 Batch 300 Loss 0.4486 Accuracy 0.9000
Epoch 10 Batch 350 Loss 0.4504 Accuracy 0.8996
Epoch 10 Batch 400 Loss 0.4509 Accuracy 0.8994
Epoch 10 Batch 450 Loss 0.4520 Accuracy 0.8992
discarded batch 452
Epoch 10 Batch 500 Loss 0.4524 Accuracy 0.8990
Epoch 10 Batch 550 Loss 0.4527 Accuracy 0.8991
Epoch 10 Batch 600 Loss 0.4538 Accuracy 0.8989
Epoch 10 Batch 650 Loss 0.4539 Accuracy 0.8989
Epoch 10 Batch 700 Loss 0.4544 Accuracy 0.8988
Epoch 10 Batch 750 Loss 0.4551 Accuracy 0.8986
Epoch 10 Batch 800 Loss 0.4564 Accuracy 0.8984
Epoch 10 Batch 850 Loss 0.4570 Accuracy 0.8982
Epoch 10 Batch 900 Loss 0.4579 Accuracy 0.8981
Epoch 10 Batch 950 Loss 0.4586 Accuracy 0.8980
Epoch 10 Batch 1000 Loss 0.4591 Accuracy 0.8979
Epoch 10 Batch 1050 Loss 0.4599 Accuracy 0.8977
Epoch 10 Batch 1100 Loss 0.4609 Accuracy 0.8976
Epoch 10 Batch 1150 Loss 0.4615 Accuracy 0.8975
Epoch 10 Batch 1200 Loss 0.4622 Accuracy 0.8975
Epoch 10 Batch 1250 Loss 0.4629 Accuracy 0.8975
Epoch 10 Batch 1300 Loss 0.4633 Accuracy 0.8974
Epoch 10 Batch 1350 Loss 0.4643 Accuracy 0.8972
Epoch 10 Batch 1400 Loss 0.4651 Accuracy 0.8971
Epoch 10 Batch 1450 Loss 0.4659 Accuracy 0.8970
Epoch 10 Batch 1500 Loss 0.4665 Accuracy 0.8969

wandb: WARNING Step must only increase in log calls.  Step 10 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.46727416>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.896818>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-14
Epoch 10 Loss 0.4673 Accuracy 0.8968
Time taken for 1 epoch: 36.24608397483826 secs

epoch lasted: 36.25107717514038
Epoch 11 Batch 0 Loss 0.4384 Accuracy 0.8987
Epoch 11 Batch 50 Loss 0.4456 Accuracy 0.8990
Epoch 11 Batch 100 Loss 0.4447 Accuracy 0.8991
Epoch 11 Batch 150 Loss 0.4455 Accuracy 0.8992
Epoch 11 Batch 200 Loss 0.4473 Accuracy 0.8990
Epoch 11 Batch 250 Loss 0.4479 Accuracy 0.8991
Epoch 11 Batch 300 Loss 0.4472 Accuracy 0.8994
Epoch 11 Batch 350 Loss 0.4479 Accuracy 0.8994
Epoch 11 Batch 400 Loss 0.4489 Accuracy 0.8992
Epoch 11 Batch 450 Loss 0.4502 Accuracy 0.8989
Epoch 11 Batch 500 Loss 0.4503 Accuracy 0.8990
Epoch 11 Batch 550 Loss 0.4512 Accuracy 0.8987
Epoch 11 Batch 600 Loss 0.4516 Accuracy 0.8987
Epoch 11 Batch 650 Loss 0.4518 Accuracy 0.8986
Epoch 11 Batch 700 Loss 0.4528 Accuracy 0.8985
discarded batch 706
Epoch 11 Batch 750 Loss 0.4537 Accuracy 0.8984
Epoch 11 Batch 800 Loss 0.4546 Accuracy 0.8982
Epoch 11 Batch 850 Loss 0.4552 Accuracy 0.8981
Epoch 11 Batch 900 Loss 0.4558 Accuracy 0.8981
Epoch 11 Batch 950 Loss 0.4562 Accuracy 0.8980
Epoch 11 Batch 1000 Loss 0.4576 Accuracy 0.8979
Epoch 11 Batch 1050 Loss 0.4584 Accuracy 0.8978
Epoch 11 Batch 1100 Loss 0.4592 Accuracy 0.8977
Epoch 11 Batch 1150 Loss 0.4601 Accuracy 0.8976
Epoch 11 Batch 1200 Loss 0.4610 Accuracy 0.8974
Epoch 11 Batch 1250 Loss 0.4617 Accuracy 0.8973
Epoch 11 Batch 1300 Loss 0.4620 Accuracy 0.8973
Epoch 11 Batch 1350 Loss 0.4626 Accuracy 0.8972
Epoch 11 Batch 1400 Loss 0.4632 Accuracy 0.8971
Epoch 11 Batch 1450 Loss 0.4640 Accuracy 0.8970
Epoch 11 Batch 1500 Loss 0.4646 Accuracy 0.8968

wandb: WARNING Step must only increase in log calls.  Step 11 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.46541333>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89677405>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 24; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.792617>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86544853>}.

Epoch 11 Loss 0.4654 Accuracy 0.8968
Time taken for 1 epoch: 36.32806873321533 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.7926 Accuracy 0.8654

epoch lasted: 36.48318910598755
Epoch 12 Batch 0 Loss 0.4535 Accuracy 0.8920
Epoch 12 Batch 50 Loss 0.4351 Accuracy 0.9009
Epoch 12 Batch 100 Loss 0.4360 Accuracy 0.9018
Epoch 12 Batch 150 Loss 0.4385 Accuracy 0.9015
Epoch 12 Batch 200 Loss 0.4413 Accuracy 0.9011
Epoch 12 Batch 250 Loss 0.4419 Accuracy 0.9009
Epoch 12 Batch 300 Loss 0.4422 Accuracy 0.9006
Epoch 12 Batch 350 Loss 0.4438 Accuracy 0.9000
Epoch 12 Batch 400 Loss 0.4447 Accuracy 0.8999
Epoch 12 Batch 450 Loss 0.4454 Accuracy 0.8998
Epoch 12 Batch 500 Loss 0.4470 Accuracy 0.8997
Epoch 12 Batch 550 Loss 0.4484 Accuracy 0.8995
Epoch 12 Batch 600 Loss 0.4495 Accuracy 0.8994
Epoch 12 Batch 650 Loss 0.4507 Accuracy 0.8993
Epoch 12 Batch 700 Loss 0.4514 Accuracy 0.8992
Epoch 12 Batch 750 Loss 0.4523 Accuracy 0.8990
Epoch 12 Batch 800 Loss 0.4529 Accuracy 0.8989
Epoch 12 Batch 850 Loss 0.4544 Accuracy 0.8987
Epoch 12 Batch 900 Loss 0.4554 Accuracy 0.8986
discarded batch 908
Epoch 12 Batch 950 Loss 0.4559 Accuracy 0.8986
Epoch 12 Batch 1000 Loss 0.4565 Accuracy 0.8985
Epoch 12 Batch 1050 Loss 0.4565 Accuracy 0.8985
Epoch 12 Batch 1100 Loss 0.4573 Accuracy 0.8983
Epoch 12 Batch 1150 Loss 0.4578 Accuracy 0.8982
Epoch 12 Batch 1200 Loss 0.4588 Accuracy 0.8980
Epoch 12 Batch 1250 Loss 0.4594 Accuracy 0.8979
Epoch 12 Batch 1300 Loss 0.4600 Accuracy 0.8978
Epoch 12 Batch 1350 Loss 0.4607 Accuracy 0.8977
Epoch 12 Batch 1400 Loss 0.4612 Accuracy 0.8976
Epoch 12 Batch 1450 Loss 0.4620 Accuracy 0.8975
Epoch 12 Batch 1500 Loss 0.4625 Accuracy 0.8974

wandb: WARNING Step must only increase in log calls.  Step 12 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.46310738>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8973381>}.

Epoch 12 Loss 0.4631 Accuracy 0.8973
Time taken for 1 epoch: 36.19819450378418 secs

epoch lasted: 36.204498052597046
Epoch 13 Batch 0 Loss 0.4289 Accuracy 0.9037
Epoch 13 Batch 50 Loss 0.4379 Accuracy 0.9021
Epoch 13 Batch 100 Loss 0.4416 Accuracy 0.9008
Epoch 13 Batch 150 Loss 0.4424 Accuracy 0.9008
Epoch 13 Batch 200 Loss 0.4428 Accuracy 0.9007
Epoch 13 Batch 250 Loss 0.4429 Accuracy 0.9005
Epoch 13 Batch 300 Loss 0.4423 Accuracy 0.9006
Epoch 13 Batch 350 Loss 0.4430 Accuracy 0.9004
Epoch 13 Batch 400 Loss 0.4444 Accuracy 0.9004
Epoch 13 Batch 450 Loss 0.4446 Accuracy 0.9003
Epoch 13 Batch 500 Loss 0.4452 Accuracy 0.9001
Epoch 13 Batch 550 Loss 0.4463 Accuracy 0.8999
Epoch 13 Batch 600 Loss 0.4469 Accuracy 0.8998
Epoch 13 Batch 650 Loss 0.4477 Accuracy 0.8997
Epoch 13 Batch 700 Loss 0.4479 Accuracy 0.8997
Epoch 13 Batch 750 Loss 0.4491 Accuracy 0.8995
Epoch 13 Batch 800 Loss 0.4502 Accuracy 0.8994
Epoch 13 Batch 850 Loss 0.4506 Accuracy 0.8992
Epoch 13 Batch 900 Loss 0.4516 Accuracy 0.8991
Epoch 13 Batch 950 Loss 0.4522 Accuracy 0.8990
discarded batch 976
Epoch 13 Batch 1000 Loss 0.4531 Accuracy 0.8989
Epoch 13 Batch 1050 Loss 0.4538 Accuracy 0.8988
Epoch 13 Batch 1100 Loss 0.4541 Accuracy 0.8987
Epoch 13 Batch 1150 Loss 0.4548 Accuracy 0.8987
Epoch 13 Batch 1200 Loss 0.4555 Accuracy 0.8986
Epoch 13 Batch 1250 Loss 0.4564 Accuracy 0.8984
Epoch 13 Batch 1300 Loss 0.4571 Accuracy 0.8983
Epoch 13 Batch 1350 Loss 0.4579 Accuracy 0.8981
Epoch 13 Batch 1400 Loss 0.4585 Accuracy 0.8980
Epoch 13 Batch 1450 Loss 0.4594 Accuracy 0.8979
Epoch 13 Batch 1500 Loss 0.4598 Accuracy 0.8978

wandb: WARNING Step must only increase in log calls.  Step 13 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.460273>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8977135>}.

Epoch 13 Loss 0.4603 Accuracy 0.8977
Time taken for 1 epoch: 36.12636160850525 secs

epoch lasted: 36.1306734085083
Epoch 14 Batch 0 Loss 0.4404 Accuracy 0.8987
Epoch 14 Batch 50 Loss 0.4414 Accuracy 0.9001
Epoch 14 Batch 100 Loss 0.4360 Accuracy 0.9006
Epoch 14 Batch 150 Loss 0.4383 Accuracy 0.9008
Epoch 14 Batch 200 Loss 0.4379 Accuracy 0.9005
Epoch 14 Batch 250 Loss 0.4385 Accuracy 0.9006
Epoch 14 Batch 300 Loss 0.4388 Accuracy 0.9009
Epoch 14 Batch 350 Loss 0.4391 Accuracy 0.9009
Epoch 14 Batch 400 Loss 0.4408 Accuracy 0.9005
Epoch 14 Batch 450 Loss 0.4418 Accuracy 0.9004
Epoch 14 Batch 500 Loss 0.4431 Accuracy 0.9003
Epoch 14 Batch 550 Loss 0.4433 Accuracy 0.9001
Epoch 14 Batch 600 Loss 0.4442 Accuracy 0.9000
Epoch 14 Batch 650 Loss 0.4449 Accuracy 0.9000
discarded batch 694
Epoch 14 Batch 700 Loss 0.4462 Accuracy 0.8999
Epoch 14 Batch 750 Loss 0.4470 Accuracy 0.8997
Epoch 14 Batch 800 Loss 0.4474 Accuracy 0.8997
Epoch 14 Batch 850 Loss 0.4485 Accuracy 0.8995
Epoch 14 Batch 900 Loss 0.4493 Accuracy 0.8994
Epoch 14 Batch 950 Loss 0.4502 Accuracy 0.8992
Epoch 14 Batch 1000 Loss 0.4513 Accuracy 0.8991
Epoch 14 Batch 1050 Loss 0.4518 Accuracy 0.8990
Epoch 14 Batch 1100 Loss 0.4528 Accuracy 0.8988
Epoch 14 Batch 1150 Loss 0.4534 Accuracy 0.8987
Epoch 14 Batch 1200 Loss 0.4543 Accuracy 0.8986
Epoch 14 Batch 1250 Loss 0.4549 Accuracy 0.8985
Epoch 14 Batch 1300 Loss 0.4555 Accuracy 0.8985
Epoch 14 Batch 1350 Loss 0.4562 Accuracy 0.8984
Epoch 14 Batch 1400 Loss 0.4569 Accuracy 0.8982
Epoch 14 Batch 1450 Loss 0.4573 Accuracy 0.8981
Epoch 14 Batch 1500 Loss 0.4579 Accuracy 0.8981

wandb: WARNING Step must only increase in log calls.  Step 14 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.45824897>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89802015>}.

Epoch 14 Loss 0.4582 Accuracy 0.8980
Time taken for 1 epoch: 36.3523428440094 secs

epoch lasted: 36.356512784957886
Epoch 15 Batch 0 Loss 0.4728 Accuracy 0.8870
Epoch 15 Batch 50 Loss 0.4291 Accuracy 0.9021
Epoch 15 Batch 100 Loss 0.4276 Accuracy 0.9013
Epoch 15 Batch 150 Loss 0.4301 Accuracy 0.9015
Epoch 15 Batch 200 Loss 0.4321 Accuracy 0.9014
Epoch 15 Batch 250 Loss 0.4320 Accuracy 0.9017
discarded batch 269
Epoch 15 Batch 300 Loss 0.4322 Accuracy 0.9020
Epoch 15 Batch 350 Loss 0.4340 Accuracy 0.9017
Epoch 15 Batch 400 Loss 0.4351 Accuracy 0.9014
Epoch 15 Batch 450 Loss 0.4362 Accuracy 0.9012
Epoch 15 Batch 500 Loss 0.4376 Accuracy 0.9010
Epoch 15 Batch 550 Loss 0.4386 Accuracy 0.9007
Epoch 15 Batch 600 Loss 0.4406 Accuracy 0.9003
Epoch 15 Batch 650 Loss 0.4415 Accuracy 0.9003
Epoch 15 Batch 700 Loss 0.4424 Accuracy 0.9002
Epoch 15 Batch 750 Loss 0.4436 Accuracy 0.9000
Epoch 15 Batch 800 Loss 0.4443 Accuracy 0.8999
Epoch 15 Batch 850 Loss 0.4452 Accuracy 0.8997
Epoch 15 Batch 900 Loss 0.4465 Accuracy 0.8995
Epoch 15 Batch 950 Loss 0.4475 Accuracy 0.8994
Epoch 15 Batch 1000 Loss 0.4479 Accuracy 0.8994
Epoch 15 Batch 1050 Loss 0.4484 Accuracy 0.8994
Epoch 15 Batch 1100 Loss 0.4490 Accuracy 0.8993
Epoch 15 Batch 1150 Loss 0.4502 Accuracy 0.8992
Epoch 15 Batch 1200 Loss 0.4510 Accuracy 0.8991
Epoch 15 Batch 1250 Loss 0.4516 Accuracy 0.8990
Epoch 15 Batch 1300 Loss 0.4524 Accuracy 0.8989
Epoch 15 Batch 1350 Loss 0.4524 Accuracy 0.8988
Epoch 15 Batch 1400 Loss 0.4531 Accuracy 0.8987
Epoch 15 Batch 1450 Loss 0.4540 Accuracy 0.8986
Epoch 15 Batch 1500 Loss 0.4547 Accuracy 0.8985

wandb: WARNING Step must only increase in log calls.  Step 15 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.45500717>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89837295>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-15
Epoch 15 Loss 0.4550 Accuracy 0.8984
Time taken for 1 epoch: 36.238972187042236 secs

epoch lasted: 36.24442434310913
Epoch 16 Batch 0 Loss 0.4151 Accuracy 0.9020
discarded batch 18
Epoch 16 Batch 50 Loss 0.4256 Accuracy 0.9024
Epoch 16 Batch 100 Loss 0.4252 Accuracy 0.9033
Epoch 16 Batch 150 Loss 0.4267 Accuracy 0.9033
Epoch 16 Batch 200 Loss 0.4288 Accuracy 0.9030
Epoch 16 Batch 250 Loss 0.4296 Accuracy 0.9028
Epoch 16 Batch 300 Loss 0.4328 Accuracy 0.9024
Epoch 16 Batch 350 Loss 0.4350 Accuracy 0.9019
Epoch 16 Batch 400 Loss 0.4361 Accuracy 0.9017
Epoch 16 Batch 450 Loss 0.4374 Accuracy 0.9016
Epoch 16 Batch 500 Loss 0.4387 Accuracy 0.9014
Epoch 16 Batch 550 Loss 0.4397 Accuracy 0.9012
Epoch 16 Batch 600 Loss 0.4399 Accuracy 0.9012
Epoch 16 Batch 650 Loss 0.4404 Accuracy 0.9010
Epoch 16 Batch 700 Loss 0.4412 Accuracy 0.9008
Epoch 16 Batch 750 Loss 0.4421 Accuracy 0.9007
Epoch 16 Batch 800 Loss 0.4425 Accuracy 0.9005
Epoch 16 Batch 850 Loss 0.4433 Accuracy 0.9003
Epoch 16 Batch 900 Loss 0.4436 Accuracy 0.9003
Epoch 16 Batch 950 Loss 0.4446 Accuracy 0.9000
Epoch 16 Batch 1000 Loss 0.4455 Accuracy 0.9000
Epoch 16 Batch 1050 Loss 0.4463 Accuracy 0.8998
Epoch 16 Batch 1100 Loss 0.4468 Accuracy 0.8998
Epoch 16 Batch 1150 Loss 0.4478 Accuracy 0.8997
Epoch 16 Batch 1200 Loss 0.4483 Accuracy 0.8996
Epoch 16 Batch 1250 Loss 0.4491 Accuracy 0.8995
Epoch 16 Batch 1300 Loss 0.4499 Accuracy 0.8993
Epoch 16 Batch 1350 Loss 0.4505 Accuracy 0.8993
Epoch 16 Batch 1400 Loss 0.4513 Accuracy 0.8991
Epoch 16 Batch 1450 Loss 0.4519 Accuracy 0.8991
Epoch 16 Batch 1500 Loss 0.4524 Accuracy 0.8990

wandb: WARNING Step must only increase in log calls.  Step 16 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4533206>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8988502>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 24; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.7999658>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8654484>}.

Epoch 16 Loss 0.4533 Accuracy 0.8989
Time taken for 1 epoch: 36.166765451431274 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.8000 Accuracy 0.8654

epoch lasted: 36.32068610191345
Epoch 17 Batch 0 Loss 0.4332 Accuracy 0.8920
Epoch 17 Batch 50 Loss 0.4333 Accuracy 0.9013
Epoch 17 Batch 100 Loss 0.4329 Accuracy 0.9016
Epoch 17 Batch 150 Loss 0.4324 Accuracy 0.9016
Epoch 17 Batch 200 Loss 0.4330 Accuracy 0.9017
Epoch 17 Batch 250 Loss 0.4323 Accuracy 0.9019
discarded batch 287
Epoch 17 Batch 300 Loss 0.4321 Accuracy 0.9019
Epoch 17 Batch 350 Loss 0.4334 Accuracy 0.9018
Epoch 17 Batch 400 Loss 0.4335 Accuracy 0.9017
Epoch 17 Batch 450 Loss 0.4346 Accuracy 0.9016
Epoch 17 Batch 500 Loss 0.4352 Accuracy 0.9015
Epoch 17 Batch 550 Loss 0.4359 Accuracy 0.9014
Epoch 17 Batch 600 Loss 0.4363 Accuracy 0.9013
Epoch 17 Batch 650 Loss 0.4375 Accuracy 0.9011
Epoch 17 Batch 700 Loss 0.4383 Accuracy 0.9011
Epoch 17 Batch 750 Loss 0.4389 Accuracy 0.9009
Epoch 17 Batch 800 Loss 0.4399 Accuracy 0.9006
Epoch 17 Batch 850 Loss 0.4406 Accuracy 0.9005
Epoch 17 Batch 900 Loss 0.4416 Accuracy 0.9004
Epoch 17 Batch 950 Loss 0.4430 Accuracy 0.9002
Epoch 17 Batch 1000 Loss 0.4434 Accuracy 0.9002
Epoch 17 Batch 1050 Loss 0.4437 Accuracy 0.9001
Epoch 17 Batch 1100 Loss 0.4445 Accuracy 0.9000
Epoch 17 Batch 1150 Loss 0.4455 Accuracy 0.8999
Epoch 17 Batch 1200 Loss 0.4460 Accuracy 0.8998
Epoch 17 Batch 1250 Loss 0.4469 Accuracy 0.8997
Epoch 17 Batch 1300 Loss 0.4478 Accuracy 0.8995
Epoch 17 Batch 1350 Loss 0.4485 Accuracy 0.8994
Epoch 17 Batch 1400 Loss 0.4488 Accuracy 0.8994
Epoch 17 Batch 1450 Loss 0.4496 Accuracy 0.8993
Epoch 17 Batch 1500 Loss 0.4502 Accuracy 0.8992

wandb: WARNING Step must only increase in log calls.  Step 17 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.45091367>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8990979>}.

Epoch 17 Loss 0.4509 Accuracy 0.8991
Time taken for 1 epoch: 36.28839302062988 secs

epoch lasted: 36.29253149032593
Epoch 18 Batch 0 Loss 0.3823 Accuracy 0.9020
Epoch 18 Batch 50 Loss 0.4264 Accuracy 0.9038
Epoch 18 Batch 100 Loss 0.4275 Accuracy 0.9032
Epoch 18 Batch 150 Loss 0.4271 Accuracy 0.9030
Epoch 18 Batch 200 Loss 0.4265 Accuracy 0.9026
Epoch 18 Batch 250 Loss 0.4278 Accuracy 0.9025
Epoch 18 Batch 300 Loss 0.4272 Accuracy 0.9025
Epoch 18 Batch 350 Loss 0.4290 Accuracy 0.9024
Epoch 18 Batch 400 Loss 0.4296 Accuracy 0.9025
Epoch 18 Batch 450 Loss 0.4306 Accuracy 0.9025
Epoch 18 Batch 500 Loss 0.4315 Accuracy 0.9022
Epoch 18 Batch 550 Loss 0.4317 Accuracy 0.9021
Epoch 18 Batch 600 Loss 0.4325 Accuracy 0.9021
Epoch 18 Batch 650 Loss 0.4336 Accuracy 0.9020
Epoch 18 Batch 700 Loss 0.4353 Accuracy 0.9017
Epoch 18 Batch 750 Loss 0.4363 Accuracy 0.9015
Epoch 18 Batch 800 Loss 0.4371 Accuracy 0.9014
Epoch 18 Batch 850 Loss 0.4385 Accuracy 0.9012
Epoch 18 Batch 900 Loss 0.4391 Accuracy 0.9011
Epoch 18 Batch 950 Loss 0.4398 Accuracy 0.9009
Epoch 18 Batch 1000 Loss 0.4406 Accuracy 0.9008
discarded batch 1036
Epoch 18 Batch 1050 Loss 0.4413 Accuracy 0.9006
Epoch 18 Batch 1100 Loss 0.4419 Accuracy 0.9006
Epoch 18 Batch 1150 Loss 0.4426 Accuracy 0.9005
Epoch 18 Batch 1200 Loss 0.4433 Accuracy 0.9004
Epoch 18 Batch 1250 Loss 0.4441 Accuracy 0.9003
Epoch 18 Batch 1300 Loss 0.4451 Accuracy 0.9001
Epoch 18 Batch 1350 Loss 0.4459 Accuracy 0.8999
Epoch 18 Batch 1400 Loss 0.4464 Accuracy 0.8999
Epoch 18 Batch 1450 Loss 0.4472 Accuracy 0.8998
Epoch 18 Batch 1500 Loss 0.4480 Accuracy 0.8997

wandb: WARNING Step must only increase in log calls.  Step 18 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.44854653>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8995311>}.

Epoch 18 Loss 0.4485 Accuracy 0.8995
Time taken for 1 epoch: 36.228596210479736 secs

epoch lasted: 36.2329363822937
Epoch 19 Batch 0 Loss 0.4284 Accuracy 0.8953
Epoch 19 Batch 50 Loss 0.4234 Accuracy 0.9034
Epoch 19 Batch 100 Loss 0.4248 Accuracy 0.9030
Epoch 19 Batch 150 Loss 0.4246 Accuracy 0.9034
Epoch 19 Batch 200 Loss 0.4265 Accuracy 0.9029
Epoch 19 Batch 250 Loss 0.4272 Accuracy 0.9027
Epoch 19 Batch 300 Loss 0.4276 Accuracy 0.9030
Epoch 19 Batch 350 Loss 0.4293 Accuracy 0.9027
Epoch 19 Batch 400 Loss 0.4295 Accuracy 0.9026
Epoch 19 Batch 450 Loss 0.4297 Accuracy 0.9023
Epoch 19 Batch 500 Loss 0.4304 Accuracy 0.9023
Epoch 19 Batch 550 Loss 0.4319 Accuracy 0.9021
Epoch 19 Batch 600 Loss 0.4331 Accuracy 0.9018
Epoch 19 Batch 650 Loss 0.4342 Accuracy 0.9016
Epoch 19 Batch 700 Loss 0.4349 Accuracy 0.9016
Epoch 19 Batch 750 Loss 0.4354 Accuracy 0.9016
Epoch 19 Batch 800 Loss 0.4358 Accuracy 0.9015
Epoch 19 Batch 850 Loss 0.4368 Accuracy 0.9013
Epoch 19 Batch 900 Loss 0.4379 Accuracy 0.9011
Epoch 19 Batch 950 Loss 0.4389 Accuracy 0.9010
Epoch 19 Batch 1000 Loss 0.4400 Accuracy 0.9008
Epoch 19 Batch 1050 Loss 0.4407 Accuracy 0.9007
Epoch 19 Batch 1100 Loss 0.4412 Accuracy 0.9006
Epoch 19 Batch 1150 Loss 0.4420 Accuracy 0.9005
Epoch 19 Batch 1200 Loss 0.4430 Accuracy 0.9004
Epoch 19 Batch 1250 Loss 0.4436 Accuracy 0.9003
Epoch 19 Batch 1300 Loss 0.4441 Accuracy 0.9002
Epoch 19 Batch 1350 Loss 0.4452 Accuracy 0.9000
Epoch 19 Batch 1400 Loss 0.4459 Accuracy 0.8999
Epoch 19 Batch 1450 Loss 0.4463 Accuracy 0.8998
discarded batch 1465
Epoch 19 Batch 1500 Loss 0.4465 Accuracy 0.8998

wandb: WARNING Step must only increase in log calls.  Step 19 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4472677>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.89968985>}.

Epoch 19 Loss 0.4473 Accuracy 0.8997
Time taken for 1 epoch: 36.040322065353394 secs

epoch lasted: 36.044930934906006
Epoch 20 Batch 0 Loss 0.4339 Accuracy 0.9070
Epoch 20 Batch 50 Loss 0.4248 Accuracy 0.9045
Epoch 20 Batch 100 Loss 0.4241 Accuracy 0.9040
Epoch 20 Batch 150 Loss 0.4237 Accuracy 0.9039
Epoch 20 Batch 200 Loss 0.4249 Accuracy 0.9036
Epoch 20 Batch 250 Loss 0.4244 Accuracy 0.9038
Epoch 20 Batch 300 Loss 0.4252 Accuracy 0.9037
Epoch 20 Batch 350 Loss 0.4272 Accuracy 0.9035
Epoch 20 Batch 400 Loss 0.4280 Accuracy 0.9034
Epoch 20 Batch 450 Loss 0.4287 Accuracy 0.9030
Epoch 20 Batch 500 Loss 0.4306 Accuracy 0.9025
Epoch 20 Batch 550 Loss 0.4315 Accuracy 0.9023
Epoch 20 Batch 600 Loss 0.4335 Accuracy 0.9020
Epoch 20 Batch 650 Loss 0.4338 Accuracy 0.9020
Epoch 20 Batch 700 Loss 0.4348 Accuracy 0.9018
Epoch 20 Batch 750 Loss 0.4353 Accuracy 0.9016
Epoch 20 Batch 800 Loss 0.4360 Accuracy 0.9014
Epoch 20 Batch 850 Loss 0.4367 Accuracy 0.9013
Epoch 20 Batch 900 Loss 0.4372 Accuracy 0.9012
Epoch 20 Batch 950 Loss 0.4378 Accuracy 0.9011
Epoch 20 Batch 1000 Loss 0.4383 Accuracy 0.9011
Epoch 20 Batch 1050 Loss 0.4393 Accuracy 0.9008
Epoch 20 Batch 1100 Loss 0.4397 Accuracy 0.9007
discarded batch 1121
Epoch 20 Batch 1150 Loss 0.4404 Accuracy 0.9005
Epoch 20 Batch 1200 Loss 0.4414 Accuracy 0.9004
Epoch 20 Batch 1250 Loss 0.4418 Accuracy 0.9004
Epoch 20 Batch 1300 Loss 0.4427 Accuracy 0.9003
Epoch 20 Batch 1350 Loss 0.4435 Accuracy 0.9003
Epoch 20 Batch 1400 Loss 0.4441 Accuracy 0.9001
Epoch 20 Batch 1450 Loss 0.4447 Accuracy 0.9001
Epoch 20 Batch 1500 Loss 0.4452 Accuracy 0.9000

wandb: WARNING Step must only increase in log calls.  Step 20 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.44589213>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8999118>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-16
Epoch 20 Loss 0.4459 Accuracy 0.8999
Time taken for 1 epoch: 35.94595289230347 secs

epoch lasted: 35.949923515319824
Epoch 21 Batch 0 Loss 0.3634 Accuracy 0.9236
Epoch 21 Batch 50 Loss 0.4151 Accuracy 0.9035
Epoch 21 Batch 100 Loss 0.4209 Accuracy 0.9034
Epoch 21 Batch 150 Loss 0.4244 Accuracy 0.9028
Epoch 21 Batch 200 Loss 0.4234 Accuracy 0.9031
Epoch 21 Batch 250 Loss 0.4253 Accuracy 0.9029
Epoch 21 Batch 300 Loss 0.4263 Accuracy 0.9030
Epoch 21 Batch 350 Loss 0.4268 Accuracy 0.9031
Epoch 21 Batch 400 Loss 0.4267 Accuracy 0.9029
Epoch 21 Batch 450 Loss 0.4267 Accuracy 0.9030
Epoch 21 Batch 500 Loss 0.4280 Accuracy 0.9026
Epoch 21 Batch 550 Loss 0.4289 Accuracy 0.9024
Epoch 21 Batch 600 Loss 0.4296 Accuracy 0.9023
Epoch 21 Batch 650 Loss 0.4297 Accuracy 0.9022
Epoch 21 Batch 700 Loss 0.4309 Accuracy 0.9021
Epoch 21 Batch 750 Loss 0.4319 Accuracy 0.9020
Epoch 21 Batch 800 Loss 0.4329 Accuracy 0.9018
Epoch 21 Batch 850 Loss 0.4340 Accuracy 0.9016
Epoch 21 Batch 900 Loss 0.4349 Accuracy 0.9016
Epoch 21 Batch 950 Loss 0.4361 Accuracy 0.9014
Epoch 21 Batch 1000 Loss 0.4368 Accuracy 0.9013
Epoch 21 Batch 1050 Loss 0.4379 Accuracy 0.9012
Epoch 21 Batch 1100 Loss 0.4388 Accuracy 0.9010
Epoch 21 Batch 1150 Loss 0.4393 Accuracy 0.9009
Epoch 21 Batch 1200 Loss 0.4402 Accuracy 0.9008
Epoch 21 Batch 1250 Loss 0.4408 Accuracy 0.9008
Epoch 21 Batch 1300 Loss 0.4413 Accuracy 0.9007
discarded batch 1346
Epoch 21 Batch 1350 Loss 0.4418 Accuracy 0.9006
Epoch 21 Batch 1400 Loss 0.4424 Accuracy 0.9005
Epoch 21 Batch 1450 Loss 0.4430 Accuracy 0.9004
Epoch 21 Batch 1500 Loss 0.4437 Accuracy 0.9003

wandb: WARNING Step must only increase in log calls.  Step 21 < 24; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.44427755>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9002432>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 24; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8068663>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86578065>}.

Epoch 21 Loss 0.4443 Accuracy 0.9002
Time taken for 1 epoch: 35.73220443725586 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.8069 Accuracy 0.8658

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 io |vi|d’ io |co|min|ciai |co|min|ciò |an|ti|
quan|to |pos|s’ io |non |sa|ria |per |lo |mon|do|
che |non |fos|si |vol|te |se |quel|la |ca|fi|da|
                                                                                                                                                                   
 e |io |fui |e |se |non |fos|se a |lo |fon|do|
non |è |co|min|ciò |el|li |si |di|pi|da|
né |per |che |son |ben |con |es|ser |mal |prin|ci|
 si |mo|ver |se|con|giun|ta e |di |sé |la |ce|de|
per |la |don|na |mia |con |la |sua |ra|di|ce|
si |fe|ce |si |con|da |sé |con |quel|la |de|
                                                                                                                                                                   
 poi |che |già |mez|zo |del |mon|do |fal|se|ce|
si |le|ti|ca |mi |dis|se |non |di|ste|se|
non |è |ciò |che |per |ve|nir |con |do|ve |se|
 e |gen|t’ è |con |in|ten|der |non |si |con|ce|le|
ma |dim|mi |ten|de|cre|det|te |se|gua|ce|
ma |per |di|ce |ma|dre |ch’ è |in |que|sto |fon|do|
                                                                                                                                                                  
 ché |noi |a |la |don|na |mia |don|na |fon|do|
per |ch’ io |ti |ve|nir |per |cui |tan|te |fon|do|
ben |puoi |fa|cea |ché |non |fos|se a |re|con|do|
e |io |vi|di |sé |non |cre|di |que|sto |mon|do in |giu|
con |que|sta |pri|ma |re|tro |se|ren|der |lie|to|
e |io |con |que|sto |lo|co |se|con|do|
                                                                                                                                                                   
 e |io |ma|ra|vi|gliar |per|so|vra |mal |mo|
e |io |ma|e|stro |mio |du|ca |dis|si|
a |la |mia |don|na |che |non |que|sta |si |mo|
 e |l’ al|to |buo|na |del |mon|do |per |la |pro|ce|
si |te|sta |pri|ma |
co|lor |ca|der |cer|
e |quel |cer|ca|gion |che |non |per |sua |na|ce|
                                                                                                                                                                   
 per |la |don|na |mia |don|na |che |s’ ap|pun|ta|
co|sì |bea|tri|ce e |io |e |quei |fat|to|
non |è |chi |è |che |son |ce|ci|de|stra |cin|ta|
e |di |que|sto |sto|ro e |ve|nir |qua |di |sot|to |que|
di |re|ve|nu|to |di |sé |non |si |mo|nio|
e |vi|di un |fat|to |con |quel|la |di|man|da|
                                                                                                                                                                   
 ma |per|ché |que|sti |per |que|sto |fon|do|pa|
co|me |que|sto |fon|do a |la |sua |cor|ni|da|
e |io |ri|vol|si a |me |li|ber|ta e |gio|pa|
e |non |si |fe|ce |ca|gion |che |si |mo|ver |fon|do|
co|sì |con|ten|to |spir|to |che |si |die|de|
ma |per|ché |la |mia |con|vien |che |si |fon|do|
                                                                                                                                                                   
 per |non |fu |a |que|sta |cal|le|ce |ca|de|
non |fu |det|to |mi |pa|ren|za |far |fon|do|
ma |io |fui |man|dar |per |la |lar|ga |pro|ra|
 e |di |cui |a |sé |mia |don|na |mia |co|sto|re|
per |ve|ren|za |mia |don|na |mia |che |le|ga|
non |son |man|da |ve|nu|ta |con |la |go|gna|
                                                                                                                                                                   
 non |fu |al|tri |ca|ra |già |mai |ne |le|ga|
né |cre|det|to |più |che |più |fu |con|ten|ne|
ben |si |di|sï|an|cor |per |ac|cen|ni|gna|
 e |que|sta |mia |don|na |di |là |giù |di|man|da|
con |que|sta |gen|te |con |la |sua |se|con|da|
e |io |in|ten|za |mia |don|na |fon|da|gna|
                                                                                                                                                                   
 per |cui |tan|te |fu |co|sì |di|sï|a|ma|
e |quel|la |gen|za |di |fuor |di|man|da|gna|
che |con |que|sto |fon|de|stra |qua |gi|ro|ma|
 non |vi |si |fe|ce |per |non |è |ve|der |gua|li|
se|con|vien |che |di |dio |a |sé |con|do |se|
ben |di|man|da|te |non |in|fer|man|ni|to|
                                                                                                                                                                   
 e |ve|de|va |per |ve|de|re e |non |fal|se|
que|sta |dol|ce |suon |che |cia|scun |con|fi|sto|
in|fin |che |gi|ne |l’ e|tà |po|ca |cal|se|
 in|ten|de|re e |vi|va |gen|to |mi |mo|ne|se|
con |la |gen|te |che |per |lo |mon|do |scu|na|
con|vien |con |que|sta |gen|ti |di|ve|de|gno|
                                                                                                                                                                   
 con |que|sto |fon|der |que|sto |mon|do in |gi|na|
po|scia |ch’ io |mi |pa|dre |mi |fu |con|ce|gno|
e |que|sto |mon|te a |que|sto |fon|der |gio|na|
in|ten|za |mia |se|guen|do |ve|gna |più |sù |be|ni|
per |le |ve|nir |con |le |pa|ro|le |gen|to|
con |le |fa |che |non |in|ten|za |re|mo|ni|
                                                                                                                                                                   
 ma |dis|se |que|sta |non |son |di |par|ti|to|
co|me |fu |e |io |e |per |que|sta |pro|fon|de|
non |è |ciò |che |per |cui |più |si |mo|to|
 ma |per |non |si |mo|ver |con |la |sua |don|na |don|na|
co|lui |ve|ra |già |per |le |gi|ra|di|
con |que|sta |gen|te |fu |det|ta e |di|man|to|
                                                                                                                                                                   
 per |non |fu |già |per |lo |fon|da |de|cre|di|
di |che |si |mo|re e |più |que|sto |fon|da|to|
di |que|sto |mon|do |que|ste |re|tro a |que|di|
 co|sì |che |non |in|ten|der |non |son |quel|la |val|
ma |per|ché |non |tor|na|tu|ra |se|con|do|
e |io |fui |con |es|ser |ve|ni|ce |mon|do|
                                                                                                                                                                   
 e |ve|ni|te |già |mai |né |al|tri |gua|da|
e |io |a |lui |ve|ren|za |mia |ra|gio|con|do|
in|fin |che ’l |mon|do |per |la |sua |fa|ma|
 con |que|sta |gen|te |del |mon|te a |be|ni|fe|de|
quin|ci |le|va|glia |con |es|ser |di|mo|re|
non |si |mo|vea |più |non |in|fin |do|len|to|
                                                                                                                                                                   
 ma |non |fu |da |lei |ma |que|sta |sua |fe|re|
ma |non |fu |al|tri|sta |pri|ma |che |pen|to|
e |quel|la |cui |di |co|per|ché ’l |fon|de|re|
e |già |in|ten|za |ve|ren|der |non |si |con|ve|ri|
non |si |vol|se a |ri|tà |con |la |cui |se|con|
e |con |le |pa|rer |più |non |si |con|ve|ri|
                                                                                                                                                                   
 ma |non |è |giun|te |per |quel|le |leg|ge|gno|
né |cre|a|ta |ch’ al |te |che ’l |mio |in|ten|to|
ma |non |è |suo |per |ve|ren|za |di|ce|gno|mo|

epoch lasted: 520.6910018920898
(1900, 128)
Epoch 1 Batch 0 Loss 0.4095 Accuracy 0.9053
Epoch 1 Batch 50 Loss 0.4192 Accuracy 0.9065
Epoch 1 Batch 100 Loss 0.4207 Accuracy 0.9046
Epoch 1 Batch 150 Loss 0.4206 Accuracy 0.9040
Epoch 1 Batch 200 Loss 0.4215 Accuracy 0.9041
Epoch 1 Batch 250 Loss 0.4225 Accuracy 0.9037
Epoch 1 Batch 300 Loss 0.4227 Accuracy 0.9037
Epoch 1 Batch 350 Loss 0.4232 Accuracy 0.9036
Epoch 1 Batch 400 Loss 0.4241 Accuracy 0.9035
Epoch 1 Batch 450 Loss 0.4252 Accuracy 0.9033
Epoch 1 Batch 500 Loss 0.4265 Accuracy 0.9031
Epoch 1 Batch 550 Loss 0.4275 Accuracy 0.9030
Epoch 1 Batch 600 Loss 0.4284 Accuracy 0.9027
Epoch 1 Batch 650 Loss 0.4289 Accuracy 0.9026
Epoch 1 Batch 700 Loss 0.4294 Accuracy 0.9025
Epoch 1 Batch 750 Loss 0.4306 Accuracy 0.9022
Epoch 1 Batch 800 Loss 0.4316 Accuracy 0.9021
Epoch 1 Batch 850 Loss 0.4323 Accuracy 0.9019
Epoch 1 Batch 900 Loss 0.4328 Accuracy 0.9019
Epoch 1 Batch 950 Loss 0.4337 Accuracy 0.9017
Epoch 1 Batch 1000 Loss 0.4346 Accuracy 0.9016
Epoch 1 Batch 1050 Loss 0.4354 Accuracy 0.9015
Epoch 1 Batch 1100 Loss 0.4362 Accuracy 0.9014
Epoch 1 Batch 1150 Loss 0.4369 Accuracy 0.9012
Epoch 1 Batch 1200 Loss 0.4376 Accuracy 0.9011
Epoch 1 Batch 1250 Loss 0.4385 Accuracy 0.9010
Epoch 1 Batch 1300 Loss 0.4391 Accuracy 0.9009
Epoch 1 Batch 1350 Loss 0.4396 Accuracy 0.9009
Epoch 1 Batch 1400 Loss 0.4403 Accuracy 0.9007
discarded batch 1425
Epoch 1 Batch 1450 Loss 0.4410 Accuracy 0.9006
Epoch 1 Batch 1500 Loss 0.4415 Accuracy 0.9006

wandb: WARNING Step must only increase in log calls.  Step 1 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.44203755>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90046734>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 25; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.80761075>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86555916>}.

Epoch 1 Loss 0.4420 Accuracy 0.9005
Time taken for 1 epoch: 35.527353286743164 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.8076 Accuracy 0.8656

epoch lasted: 35.68475317955017
Epoch 2 Batch 0 Loss 0.4149 Accuracy 0.9070
Epoch 2 Batch 50 Loss 0.4145 Accuracy 0.9056
Epoch 2 Batch 100 Loss 0.4175 Accuracy 0.9051
Epoch 2 Batch 150 Loss 0.4199 Accuracy 0.9046
Epoch 2 Batch 200 Loss 0.4218 Accuracy 0.9040
Epoch 2 Batch 250 Loss 0.4213 Accuracy 0.9039
Epoch 2 Batch 300 Loss 0.4218 Accuracy 0.9038
Epoch 2 Batch 350 Loss 0.4234 Accuracy 0.9034
Epoch 2 Batch 400 Loss 0.4232 Accuracy 0.9035
Epoch 2 Batch 450 Loss 0.4240 Accuracy 0.9033
Epoch 2 Batch 500 Loss 0.4247 Accuracy 0.9032
Epoch 2 Batch 550 Loss 0.4259 Accuracy 0.9030
Epoch 2 Batch 600 Loss 0.4275 Accuracy 0.9027
Epoch 2 Batch 650 Loss 0.4279 Accuracy 0.9026
Epoch 2 Batch 700 Loss 0.4284 Accuracy 0.9025
Epoch 2 Batch 750 Loss 0.4292 Accuracy 0.9024
discarded batch 796
Epoch 2 Batch 800 Loss 0.4299 Accuracy 0.9023
Epoch 2 Batch 850 Loss 0.4304 Accuracy 0.9022
Epoch 2 Batch 900 Loss 0.4313 Accuracy 0.9020
Epoch 2 Batch 950 Loss 0.4322 Accuracy 0.9020
Epoch 2 Batch 1000 Loss 0.4327 Accuracy 0.9019
Epoch 2 Batch 1050 Loss 0.4334 Accuracy 0.9017
Epoch 2 Batch 1100 Loss 0.4338 Accuracy 0.9017
Epoch 2 Batch 1150 Loss 0.4347 Accuracy 0.9015
Epoch 2 Batch 1200 Loss 0.4356 Accuracy 0.9014
Epoch 2 Batch 1250 Loss 0.4360 Accuracy 0.9013
Epoch 2 Batch 1300 Loss 0.4367 Accuracy 0.9012
Epoch 2 Batch 1350 Loss 0.4373 Accuracy 0.9011
Epoch 2 Batch 1400 Loss 0.4380 Accuracy 0.9010
Epoch 2 Batch 1450 Loss 0.4387 Accuracy 0.9008
Epoch 2 Batch 1500 Loss 0.4393 Accuracy 0.9007

wandb: WARNING Step must only increase in log calls.  Step 2 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.43984357>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90068823>}.

Epoch 2 Loss 0.4398 Accuracy 0.9007
Time taken for 1 epoch: 35.908101320266724 secs

epoch lasted: 35.912837982177734
Epoch 3 Batch 0 Loss 0.4183 Accuracy 0.9120
Epoch 3 Batch 50 Loss 0.4107 Accuracy 0.9060
Epoch 3 Batch 100 Loss 0.4111 Accuracy 0.9054
Epoch 3 Batch 150 Loss 0.4117 Accuracy 0.9053
Epoch 3 Batch 200 Loss 0.4135 Accuracy 0.9051
Epoch 3 Batch 250 Loss 0.4143 Accuracy 0.9049
Epoch 3 Batch 300 Loss 0.4165 Accuracy 0.9046
Epoch 3 Batch 350 Loss 0.4181 Accuracy 0.9044
Epoch 3 Batch 400 Loss 0.4190 Accuracy 0.9043
Epoch 3 Batch 450 Loss 0.4201 Accuracy 0.9041
Epoch 3 Batch 500 Loss 0.4215 Accuracy 0.9038
discarded batch 512
Epoch 3 Batch 550 Loss 0.4223 Accuracy 0.9036
Epoch 3 Batch 600 Loss 0.4239 Accuracy 0.9033
Epoch 3 Batch 650 Loss 0.4246 Accuracy 0.9032
Epoch 3 Batch 700 Loss 0.4257 Accuracy 0.9030
Epoch 3 Batch 750 Loss 0.4264 Accuracy 0.9029
Epoch 3 Batch 800 Loss 0.4274 Accuracy 0.9028
Epoch 3 Batch 850 Loss 0.4281 Accuracy 0.9027
Epoch 3 Batch 900 Loss 0.4286 Accuracy 0.9026
Epoch 3 Batch 950 Loss 0.4293 Accuracy 0.9025
Epoch 3 Batch 1000 Loss 0.4302 Accuracy 0.9024
Epoch 3 Batch 1050 Loss 0.4306 Accuracy 0.9023
Epoch 3 Batch 1100 Loss 0.4312 Accuracy 0.9022
Epoch 3 Batch 1150 Loss 0.4321 Accuracy 0.9021
Epoch 3 Batch 1200 Loss 0.4327 Accuracy 0.9020
Epoch 3 Batch 1250 Loss 0.4338 Accuracy 0.9018
Epoch 3 Batch 1300 Loss 0.4346 Accuracy 0.9018
Epoch 3 Batch 1350 Loss 0.4350 Accuracy 0.9016
Epoch 3 Batch 1400 Loss 0.4358 Accuracy 0.9015
Epoch 3 Batch 1450 Loss 0.4366 Accuracy 0.9014
Epoch 3 Batch 1500 Loss 0.4372 Accuracy 0.9013

wandb: WARNING Step must only increase in log calls.  Step 3 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.43792102>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90122336>}.

Epoch 3 Loss 0.4379 Accuracy 0.9012
Time taken for 1 epoch: 35.73585748672485 secs

epoch lasted: 35.74039316177368
Epoch 4 Batch 0 Loss 0.3922 Accuracy 0.9070
Epoch 4 Batch 50 Loss 0.4056 Accuracy 0.9063
Epoch 4 Batch 100 Loss 0.4047 Accuracy 0.9068
Epoch 4 Batch 150 Loss 0.4101 Accuracy 0.9056
Epoch 4 Batch 200 Loss 0.4115 Accuracy 0.9055
Epoch 4 Batch 250 Loss 0.4125 Accuracy 0.9051
Epoch 4 Batch 300 Loss 0.4140 Accuracy 0.9048
discarded batch 330
Epoch 4 Batch 350 Loss 0.4157 Accuracy 0.9045
Epoch 4 Batch 400 Loss 0.4174 Accuracy 0.9040
Epoch 4 Batch 450 Loss 0.4184 Accuracy 0.9039
Epoch 4 Batch 500 Loss 0.4191 Accuracy 0.9039
Epoch 4 Batch 550 Loss 0.4205 Accuracy 0.9037
Epoch 4 Batch 600 Loss 0.4214 Accuracy 0.9035
Epoch 4 Batch 650 Loss 0.4230 Accuracy 0.9033
Epoch 4 Batch 700 Loss 0.4238 Accuracy 0.9031
Epoch 4 Batch 750 Loss 0.4250 Accuracy 0.9029
Epoch 4 Batch 800 Loss 0.4256 Accuracy 0.9027
Epoch 4 Batch 850 Loss 0.4264 Accuracy 0.9027
Epoch 4 Batch 900 Loss 0.4271 Accuracy 0.9025
Epoch 4 Batch 950 Loss 0.4279 Accuracy 0.9024
Epoch 4 Batch 1000 Loss 0.4286 Accuracy 0.9023
Epoch 4 Batch 1050 Loss 0.4293 Accuracy 0.9022
Epoch 4 Batch 1100 Loss 0.4303 Accuracy 0.9021
Epoch 4 Batch 1150 Loss 0.4309 Accuracy 0.9019
Epoch 4 Batch 1200 Loss 0.4317 Accuracy 0.9018
Epoch 4 Batch 1250 Loss 0.4326 Accuracy 0.9017
Epoch 4 Batch 1300 Loss 0.4332 Accuracy 0.9016
Epoch 4 Batch 1350 Loss 0.4337 Accuracy 0.9016
Epoch 4 Batch 1400 Loss 0.4343 Accuracy 0.9015
Epoch 4 Batch 1450 Loss 0.4350 Accuracy 0.9014
Epoch 4 Batch 1500 Loss 0.4356 Accuracy 0.9013

wandb: WARNING Step must only increase in log calls.  Step 4 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.43618068>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9011934>}.

Epoch 4 Loss 0.4362 Accuracy 0.9012
Time taken for 1 epoch: 35.75847244262695 secs

epoch lasted: 35.763351917266846
Epoch 5 Batch 0 Loss 0.4218 Accuracy 0.8920
Epoch 5 Batch 50 Loss 0.4129 Accuracy 0.9056
Epoch 5 Batch 100 Loss 0.4117 Accuracy 0.9061
Epoch 5 Batch 150 Loss 0.4116 Accuracy 0.9055
Epoch 5 Batch 200 Loss 0.4107 Accuracy 0.9055
Epoch 5 Batch 250 Loss 0.4113 Accuracy 0.9052
Epoch 5 Batch 300 Loss 0.4130 Accuracy 0.9051
Epoch 5 Batch 350 Loss 0.4143 Accuracy 0.9049
Epoch 5 Batch 400 Loss 0.4155 Accuracy 0.9049
Epoch 5 Batch 450 Loss 0.4163 Accuracy 0.9047
Epoch 5 Batch 500 Loss 0.4174 Accuracy 0.9045
Epoch 5 Batch 550 Loss 0.4187 Accuracy 0.9042
Epoch 5 Batch 600 Loss 0.4203 Accuracy 0.9041
Epoch 5 Batch 650 Loss 0.4213 Accuracy 0.9040
Epoch 5 Batch 700 Loss 0.4220 Accuracy 0.9038
Epoch 5 Batch 750 Loss 0.4224 Accuracy 0.9036
Epoch 5 Batch 800 Loss 0.4228 Accuracy 0.9036
Epoch 5 Batch 850 Loss 0.4238 Accuracy 0.9034
Epoch 5 Batch 900 Loss 0.4245 Accuracy 0.9033
Epoch 5 Batch 950 Loss 0.4252 Accuracy 0.9031
Epoch 5 Batch 1000 Loss 0.4260 Accuracy 0.9030
Epoch 5 Batch 1050 Loss 0.4269 Accuracy 0.9029
Epoch 5 Batch 1100 Loss 0.4277 Accuracy 0.9027
discarded batch 1118
Epoch 5 Batch 1150 Loss 0.4288 Accuracy 0.9026
Epoch 5 Batch 1200 Loss 0.4299 Accuracy 0.9024
Epoch 5 Batch 1250 Loss 0.4306 Accuracy 0.9023
Epoch 5 Batch 1300 Loss 0.4311 Accuracy 0.9022
Epoch 5 Batch 1350 Loss 0.4316 Accuracy 0.9021
Epoch 5 Batch 1400 Loss 0.4321 Accuracy 0.9021
Epoch 5 Batch 1450 Loss 0.4328 Accuracy 0.9019
Epoch 5 Batch 1500 Loss 0.4336 Accuracy 0.9019

wandb: WARNING Step must only increase in log calls.  Step 5 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4342825>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9017456>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-17
Epoch 5 Loss 0.4343 Accuracy 0.9017
Time taken for 1 epoch: 36.00502109527588 secs

epoch lasted: 36.010265827178955
Epoch 6 Batch 0 Loss 0.3539 Accuracy 0.9136
Epoch 6 Batch 50 Loss 0.4145 Accuracy 0.9057
Epoch 6 Batch 100 Loss 0.4161 Accuracy 0.9052
Epoch 6 Batch 150 Loss 0.4117 Accuracy 0.9056
Epoch 6 Batch 200 Loss 0.4110 Accuracy 0.9055
discarded batch 237
Epoch 6 Batch 250 Loss 0.4113 Accuracy 0.9054
Epoch 6 Batch 300 Loss 0.4122 Accuracy 0.9053
Epoch 6 Batch 350 Loss 0.4128 Accuracy 0.9053
Epoch 6 Batch 400 Loss 0.4135 Accuracy 0.9052
Epoch 6 Batch 450 Loss 0.4148 Accuracy 0.9049
Epoch 6 Batch 500 Loss 0.4158 Accuracy 0.9048
Epoch 6 Batch 550 Loss 0.4165 Accuracy 0.9047
Epoch 6 Batch 600 Loss 0.4169 Accuracy 0.9046
Epoch 6 Batch 650 Loss 0.4181 Accuracy 0.9044
Epoch 6 Batch 700 Loss 0.4190 Accuracy 0.9042
Epoch 6 Batch 750 Loss 0.4202 Accuracy 0.9041
Epoch 6 Batch 800 Loss 0.4210 Accuracy 0.9039
Epoch 6 Batch 850 Loss 0.4224 Accuracy 0.9037
Epoch 6 Batch 900 Loss 0.4232 Accuracy 0.9035
Epoch 6 Batch 950 Loss 0.4242 Accuracy 0.9034
Epoch 6 Batch 1000 Loss 0.4246 Accuracy 0.9034
Epoch 6 Batch 1050 Loss 0.4250 Accuracy 0.9032
Epoch 6 Batch 1100 Loss 0.4254 Accuracy 0.9030
Epoch 6 Batch 1150 Loss 0.4264 Accuracy 0.9029
Epoch 6 Batch 1200 Loss 0.4275 Accuracy 0.9026
Epoch 6 Batch 1250 Loss 0.4282 Accuracy 0.9025
Epoch 6 Batch 1300 Loss 0.4289 Accuracy 0.9024
Epoch 6 Batch 1350 Loss 0.4297 Accuracy 0.9022
Epoch 6 Batch 1400 Loss 0.4305 Accuracy 0.9022
Epoch 6 Batch 1450 Loss 0.4311 Accuracy 0.9021
Epoch 6 Batch 1500 Loss 0.4316 Accuracy 0.9020

wandb: WARNING Step must only increase in log calls.  Step 6 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.43207476>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90199655>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 25; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.81646734>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86544853>}.

Epoch 6 Loss 0.4321 Accuracy 0.9020
Time taken for 1 epoch: 35.974639892578125 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.8165 Accuracy 0.8654

epoch lasted: 36.129534006118774
Epoch 7 Batch 0 Loss 0.4069 Accuracy 0.8970
Epoch 7 Batch 50 Loss 0.3975 Accuracy 0.9084
Epoch 7 Batch 100 Loss 0.3974 Accuracy 0.9078
Epoch 7 Batch 150 Loss 0.4004 Accuracy 0.9072
Epoch 7 Batch 200 Loss 0.4035 Accuracy 0.9064
Epoch 7 Batch 250 Loss 0.4057 Accuracy 0.9063
Epoch 7 Batch 300 Loss 0.4067 Accuracy 0.9060
Epoch 7 Batch 350 Loss 0.4089 Accuracy 0.9056
Epoch 7 Batch 400 Loss 0.4105 Accuracy 0.9053
Epoch 7 Batch 450 Loss 0.4122 Accuracy 0.9050
Epoch 7 Batch 500 Loss 0.4134 Accuracy 0.9048
Epoch 7 Batch 550 Loss 0.4150 Accuracy 0.9046
Epoch 7 Batch 600 Loss 0.4156 Accuracy 0.9045
Epoch 7 Batch 650 Loss 0.4161 Accuracy 0.9044
Epoch 7 Batch 700 Loss 0.4174 Accuracy 0.9042
Epoch 7 Batch 750 Loss 0.4184 Accuracy 0.9041
Epoch 7 Batch 800 Loss 0.4189 Accuracy 0.9040
Epoch 7 Batch 850 Loss 0.4199 Accuracy 0.9038
Epoch 7 Batch 900 Loss 0.4211 Accuracy 0.9037
Epoch 7 Batch 950 Loss 0.4221 Accuracy 0.9035
Epoch 7 Batch 1000 Loss 0.4231 Accuracy 0.9034
Epoch 7 Batch 1050 Loss 0.4236 Accuracy 0.9033
Epoch 7 Batch 1100 Loss 0.4243 Accuracy 0.9032
Epoch 7 Batch 1150 Loss 0.4252 Accuracy 0.9031
Epoch 7 Batch 1200 Loss 0.4258 Accuracy 0.9030
Epoch 7 Batch 1250 Loss 0.4271 Accuracy 0.9028
Epoch 7 Batch 1300 Loss 0.4278 Accuracy 0.9027
Epoch 7 Batch 1350 Loss 0.4286 Accuracy 0.9026
Epoch 7 Batch 1400 Loss 0.4293 Accuracy 0.9025
discarded batch 1415
Epoch 7 Batch 1450 Loss 0.4300 Accuracy 0.9024
Epoch 7 Batch 1500 Loss 0.4303 Accuracy 0.9024

wandb: WARNING Step must only increase in log calls.  Step 7 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.43072265>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.902314>}.

Epoch 7 Loss 0.4307 Accuracy 0.9023
Time taken for 1 epoch: 35.76929473876953 secs

epoch lasted: 35.781533002853394
Epoch 8 Batch 0 Loss 0.3712 Accuracy 0.9169
Epoch 8 Batch 50 Loss 0.4070 Accuracy 0.9069
Epoch 8 Batch 100 Loss 0.4071 Accuracy 0.9064
Epoch 8 Batch 150 Loss 0.4043 Accuracy 0.9064
Epoch 8 Batch 200 Loss 0.4041 Accuracy 0.9062
Epoch 8 Batch 250 Loss 0.4074 Accuracy 0.9056
Epoch 8 Batch 300 Loss 0.4088 Accuracy 0.9053
Epoch 8 Batch 350 Loss 0.4084 Accuracy 0.9054
Epoch 8 Batch 400 Loss 0.4087 Accuracy 0.9054
Epoch 8 Batch 450 Loss 0.4104 Accuracy 0.9054
Epoch 8 Batch 500 Loss 0.4117 Accuracy 0.9051
Epoch 8 Batch 550 Loss 0.4123 Accuracy 0.9049
Epoch 8 Batch 600 Loss 0.4129 Accuracy 0.9049
Epoch 8 Batch 650 Loss 0.4143 Accuracy 0.9049
Epoch 8 Batch 700 Loss 0.4157 Accuracy 0.9046
Epoch 8 Batch 750 Loss 0.4169 Accuracy 0.9043
Epoch 8 Batch 800 Loss 0.4173 Accuracy 0.9042
Epoch 8 Batch 850 Loss 0.4175 Accuracy 0.9042
Epoch 8 Batch 900 Loss 0.4180 Accuracy 0.9042
discarded batch 907
Epoch 8 Batch 950 Loss 0.4191 Accuracy 0.9040
Epoch 8 Batch 1000 Loss 0.4198 Accuracy 0.9038
Epoch 8 Batch 1050 Loss 0.4207 Accuracy 0.9037
Epoch 8 Batch 1100 Loss 0.4216 Accuracy 0.9036
Epoch 8 Batch 1150 Loss 0.4227 Accuracy 0.9034
Epoch 8 Batch 1200 Loss 0.4234 Accuracy 0.9034
Epoch 8 Batch 1250 Loss 0.4239 Accuracy 0.9033
Epoch 8 Batch 1300 Loss 0.4246 Accuracy 0.9032
Epoch 8 Batch 1350 Loss 0.4252 Accuracy 0.9031
Epoch 8 Batch 1400 Loss 0.4257 Accuracy 0.9030
Epoch 8 Batch 1450 Loss 0.4263 Accuracy 0.9029
Epoch 8 Batch 1500 Loss 0.4272 Accuracy 0.9028

wandb: WARNING Step must only increase in log calls.  Step 8 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.42800704>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9026915>}.

Epoch 8 Loss 0.4280 Accuracy 0.9027
Time taken for 1 epoch: 35.738853454589844 secs

epoch lasted: 35.744033098220825
Epoch 9 Batch 0 Loss 0.4046 Accuracy 0.9120
Epoch 9 Batch 50 Loss 0.3999 Accuracy 0.9074
Epoch 9 Batch 100 Loss 0.4007 Accuracy 0.9076
Epoch 9 Batch 150 Loss 0.4004 Accuracy 0.9075
Epoch 9 Batch 200 Loss 0.3997 Accuracy 0.9075
Epoch 9 Batch 250 Loss 0.4028 Accuracy 0.9068
Epoch 9 Batch 300 Loss 0.4047 Accuracy 0.9065
Epoch 9 Batch 350 Loss 0.4072 Accuracy 0.9060
Epoch 9 Batch 400 Loss 0.4087 Accuracy 0.9057
Epoch 9 Batch 450 Loss 0.4095 Accuracy 0.9055
Epoch 9 Batch 500 Loss 0.4106 Accuracy 0.9050
Epoch 9 Batch 550 Loss 0.4116 Accuracy 0.9050
Epoch 9 Batch 600 Loss 0.4119 Accuracy 0.9048
Epoch 9 Batch 650 Loss 0.4122 Accuracy 0.9048
Epoch 9 Batch 700 Loss 0.4131 Accuracy 0.9046
discarded batch 734
Epoch 9 Batch 750 Loss 0.4144 Accuracy 0.9044
Epoch 9 Batch 800 Loss 0.4156 Accuracy 0.9043
Epoch 9 Batch 850 Loss 0.4164 Accuracy 0.9041
Epoch 9 Batch 900 Loss 0.4176 Accuracy 0.9040
Epoch 9 Batch 950 Loss 0.4185 Accuracy 0.9039
Epoch 9 Batch 1000 Loss 0.4192 Accuracy 0.9038
Epoch 9 Batch 1050 Loss 0.4197 Accuracy 0.9037
Epoch 9 Batch 1100 Loss 0.4204 Accuracy 0.9036
Epoch 9 Batch 1150 Loss 0.4212 Accuracy 0.9034
Epoch 9 Batch 1200 Loss 0.4219 Accuracy 0.9033
Epoch 9 Batch 1250 Loss 0.4230 Accuracy 0.9031
Epoch 9 Batch 1300 Loss 0.4237 Accuracy 0.9030
Epoch 9 Batch 1350 Loss 0.4239 Accuracy 0.9029
Epoch 9 Batch 1400 Loss 0.4250 Accuracy 0.9028
Epoch 9 Batch 1450 Loss 0.4256 Accuracy 0.9026
Epoch 9 Batch 1500 Loss 0.4262 Accuracy 0.9026

wandb: WARNING Step must only increase in log calls.  Step 9 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.42677534>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.902551>}.

Epoch 9 Loss 0.4268 Accuracy 0.9026
Time taken for 1 epoch: 36.20117139816284 secs

epoch lasted: 36.20603394508362
Epoch 10 Batch 0 Loss 0.3970 Accuracy 0.9003
Epoch 10 Batch 50 Loss 0.3923 Accuracy 0.9088
Epoch 10 Batch 100 Loss 0.3940 Accuracy 0.9094
Epoch 10 Batch 150 Loss 0.3983 Accuracy 0.9081
Epoch 10 Batch 200 Loss 0.4009 Accuracy 0.9077
Epoch 10 Batch 250 Loss 0.4031 Accuracy 0.9072
Epoch 10 Batch 300 Loss 0.4038 Accuracy 0.9070
Epoch 10 Batch 350 Loss 0.4062 Accuracy 0.9064
Epoch 10 Batch 400 Loss 0.4069 Accuracy 0.9062
Epoch 10 Batch 450 Loss 0.4077 Accuracy 0.9061
discarded batch 485
Epoch 10 Batch 500 Loss 0.4083 Accuracy 0.9061
Epoch 10 Batch 550 Loss 0.4090 Accuracy 0.9059
Epoch 10 Batch 600 Loss 0.4093 Accuracy 0.9058
Epoch 10 Batch 650 Loss 0.4104 Accuracy 0.9056
Epoch 10 Batch 700 Loss 0.4116 Accuracy 0.9054
Epoch 10 Batch 750 Loss 0.4118 Accuracy 0.9054
Epoch 10 Batch 800 Loss 0.4124 Accuracy 0.9051
Epoch 10 Batch 850 Loss 0.4135 Accuracy 0.9049
Epoch 10 Batch 900 Loss 0.4145 Accuracy 0.9047
Epoch 10 Batch 950 Loss 0.4149 Accuracy 0.9047
Epoch 10 Batch 1000 Loss 0.4163 Accuracy 0.9044
Epoch 10 Batch 1050 Loss 0.4174 Accuracy 0.9043
Epoch 10 Batch 1100 Loss 0.4182 Accuracy 0.9042
Epoch 10 Batch 1150 Loss 0.4192 Accuracy 0.9041
Epoch 10 Batch 1200 Loss 0.4203 Accuracy 0.9039
Epoch 10 Batch 1250 Loss 0.4211 Accuracy 0.9038
Epoch 10 Batch 1300 Loss 0.4217 Accuracy 0.9037
Epoch 10 Batch 1350 Loss 0.4223 Accuracy 0.9036
Epoch 10 Batch 1400 Loss 0.4229 Accuracy 0.9034
Epoch 10 Batch 1450 Loss 0.4236 Accuracy 0.9033
Epoch 10 Batch 1500 Loss 0.4244 Accuracy 0.9032

wandb: WARNING Step must only increase in log calls.  Step 10 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4249269>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9031119>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-18
Epoch 10 Loss 0.4249 Accuracy 0.9031
Time taken for 1 epoch: 36.44927167892456 secs

epoch lasted: 36.45332193374634
Epoch 11 Batch 0 Loss 0.4453 Accuracy 0.8970
Epoch 11 Batch 50 Loss 0.3960 Accuracy 0.9070
Epoch 11 Batch 100 Loss 0.3993 Accuracy 0.9072
Epoch 11 Batch 150 Loss 0.4015 Accuracy 0.9062
Epoch 11 Batch 200 Loss 0.4024 Accuracy 0.9062
Epoch 11 Batch 250 Loss 0.4026 Accuracy 0.9066
Epoch 11 Batch 300 Loss 0.4032 Accuracy 0.9066
Epoch 11 Batch 350 Loss 0.4046 Accuracy 0.9062
Epoch 11 Batch 400 Loss 0.4054 Accuracy 0.9062
Epoch 11 Batch 450 Loss 0.4058 Accuracy 0.9059
Epoch 11 Batch 500 Loss 0.4067 Accuracy 0.9058
Epoch 11 Batch 550 Loss 0.4081 Accuracy 0.9056
Epoch 11 Batch 600 Loss 0.4084 Accuracy 0.9057
Epoch 11 Batch 650 Loss 0.4091 Accuracy 0.9057
Epoch 11 Batch 700 Loss 0.4101 Accuracy 0.9054
Epoch 11 Batch 750 Loss 0.4109 Accuracy 0.9053
Epoch 11 Batch 800 Loss 0.4118 Accuracy 0.9052
Epoch 11 Batch 850 Loss 0.4131 Accuracy 0.9049
Epoch 11 Batch 900 Loss 0.4142 Accuracy 0.9048
Epoch 11 Batch 950 Loss 0.4151 Accuracy 0.9046
Epoch 11 Batch 1000 Loss 0.4157 Accuracy 0.9046
Epoch 11 Batch 1050 Loss 0.4164 Accuracy 0.9045
Epoch 11 Batch 1100 Loss 0.4172 Accuracy 0.9044
Epoch 11 Batch 1150 Loss 0.4179 Accuracy 0.9042
Epoch 11 Batch 1200 Loss 0.4188 Accuracy 0.9041
Epoch 11 Batch 1250 Loss 0.4193 Accuracy 0.9040
Epoch 11 Batch 1300 Loss 0.4199 Accuracy 0.9039
Epoch 11 Batch 1350 Loss 0.4205 Accuracy 0.9038
discarded batch 1351
Epoch 11 Batch 1400 Loss 0.4211 Accuracy 0.9037
Epoch 11 Batch 1450 Loss 0.4218 Accuracy 0.9036
Epoch 11 Batch 1500 Loss 0.4224 Accuracy 0.9035

wandb: WARNING Step must only increase in log calls.  Step 11 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.42311954>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9033918>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 25; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8255814>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86544853>}.

Epoch 11 Loss 0.4231 Accuracy 0.9034
Time taken for 1 epoch: 36.08946204185486 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.8256 Accuracy 0.8654

epoch lasted: 36.247910022735596
Epoch 12 Batch 0 Loss 0.3980 Accuracy 0.9070
Epoch 12 Batch 50 Loss 0.3909 Accuracy 0.9085
Epoch 12 Batch 100 Loss 0.3948 Accuracy 0.9088
Epoch 12 Batch 150 Loss 0.3956 Accuracy 0.9088
Epoch 12 Batch 200 Loss 0.3989 Accuracy 0.9080
Epoch 12 Batch 250 Loss 0.4026 Accuracy 0.9075
Epoch 12 Batch 300 Loss 0.4039 Accuracy 0.9071
Epoch 12 Batch 350 Loss 0.4052 Accuracy 0.9069
Epoch 12 Batch 400 Loss 0.4062 Accuracy 0.9066
Epoch 12 Batch 450 Loss 0.4073 Accuracy 0.9062
Epoch 12 Batch 500 Loss 0.4077 Accuracy 0.9061
Epoch 12 Batch 550 Loss 0.4079 Accuracy 0.9061
Epoch 12 Batch 600 Loss 0.4082 Accuracy 0.9060
Epoch 12 Batch 650 Loss 0.4095 Accuracy 0.9059
Epoch 12 Batch 700 Loss 0.4104 Accuracy 0.9057
Epoch 12 Batch 750 Loss 0.4113 Accuracy 0.9056
Epoch 12 Batch 800 Loss 0.4122 Accuracy 0.9054
Epoch 12 Batch 850 Loss 0.4132 Accuracy 0.9053
Epoch 12 Batch 900 Loss 0.4142 Accuracy 0.9051
Epoch 12 Batch 950 Loss 0.4144 Accuracy 0.9051
Epoch 12 Batch 1000 Loss 0.4151 Accuracy 0.9049
Epoch 12 Batch 1050 Loss 0.4157 Accuracy 0.9048
Epoch 12 Batch 1100 Loss 0.4168 Accuracy 0.9046
Epoch 12 Batch 1150 Loss 0.4174 Accuracy 0.9045
Epoch 12 Batch 1200 Loss 0.4184 Accuracy 0.9043
Epoch 12 Batch 1250 Loss 0.4191 Accuracy 0.9043
Epoch 12 Batch 1300 Loss 0.4195 Accuracy 0.9042
Epoch 12 Batch 1350 Loss 0.4203 Accuracy 0.9040
Epoch 12 Batch 1400 Loss 0.4210 Accuracy 0.9039
Epoch 12 Batch 1450 Loss 0.4214 Accuracy 0.9039
Epoch 12 Batch 1500 Loss 0.4220 Accuracy 0.9038
discarded batch 1513

wandb: WARNING Step must only increase in log calls.  Step 12 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.42255402>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90368235>}.

Epoch 12 Loss 0.4226 Accuracy 0.9037
Time taken for 1 epoch: 35.73988485336304 secs

epoch lasted: 35.74402666091919
Epoch 13 Batch 0 Loss 0.4552 Accuracy 0.9053
Epoch 13 Batch 50 Loss 0.3984 Accuracy 0.9085
Epoch 13 Batch 100 Loss 0.3960 Accuracy 0.9084
Epoch 13 Batch 150 Loss 0.3985 Accuracy 0.9078
Epoch 13 Batch 200 Loss 0.3983 Accuracy 0.9078
Epoch 13 Batch 250 Loss 0.3988 Accuracy 0.9075
Epoch 13 Batch 300 Loss 0.3998 Accuracy 0.9074
Epoch 13 Batch 350 Loss 0.4015 Accuracy 0.9070
Epoch 13 Batch 400 Loss 0.4024 Accuracy 0.9067
Epoch 13 Batch 450 Loss 0.4033 Accuracy 0.9065
Epoch 13 Batch 500 Loss 0.4043 Accuracy 0.9063
Epoch 13 Batch 550 Loss 0.4062 Accuracy 0.9059
Epoch 13 Batch 600 Loss 0.4066 Accuracy 0.9059
Epoch 13 Batch 650 Loss 0.4077 Accuracy 0.9057
Epoch 13 Batch 700 Loss 0.4081 Accuracy 0.9056
Epoch 13 Batch 750 Loss 0.4086 Accuracy 0.9056
Epoch 13 Batch 800 Loss 0.4094 Accuracy 0.9055
Epoch 13 Batch 850 Loss 0.4102 Accuracy 0.9053
Epoch 13 Batch 900 Loss 0.4113 Accuracy 0.9051
Epoch 13 Batch 950 Loss 0.4121 Accuracy 0.9051
Epoch 13 Batch 1000 Loss 0.4126 Accuracy 0.9050
Epoch 13 Batch 1050 Loss 0.4134 Accuracy 0.9048
Epoch 13 Batch 1100 Loss 0.4146 Accuracy 0.9047
Epoch 13 Batch 1150 Loss 0.4153 Accuracy 0.9047
Epoch 13 Batch 1200 Loss 0.4162 Accuracy 0.9045
Epoch 13 Batch 1250 Loss 0.4167 Accuracy 0.9044
Epoch 13 Batch 1300 Loss 0.4176 Accuracy 0.9043
Epoch 13 Batch 1350 Loss 0.4188 Accuracy 0.9041
discarded batch 1354
Epoch 13 Batch 1400 Loss 0.4194 Accuracy 0.9040
Epoch 13 Batch 1450 Loss 0.4199 Accuracy 0.9039
Epoch 13 Batch 1500 Loss 0.4205 Accuracy 0.9038

wandb: WARNING Step must only increase in log calls.  Step 13 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.42108685>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9037167>}.

Epoch 13 Loss 0.4211 Accuracy 0.9037
Time taken for 1 epoch: 35.79039025306702 secs

epoch lasted: 35.794795751571655
Epoch 14 Batch 0 Loss 0.4065 Accuracy 0.9053
Epoch 14 Batch 50 Loss 0.3875 Accuracy 0.9083
Epoch 14 Batch 100 Loss 0.3895 Accuracy 0.9084
Epoch 14 Batch 150 Loss 0.3927 Accuracy 0.9082
Epoch 14 Batch 200 Loss 0.3940 Accuracy 0.9081
Epoch 14 Batch 250 Loss 0.3945 Accuracy 0.9082
Epoch 14 Batch 300 Loss 0.3957 Accuracy 0.9080
Epoch 14 Batch 350 Loss 0.3973 Accuracy 0.9080
Epoch 14 Batch 400 Loss 0.3990 Accuracy 0.9076
Epoch 14 Batch 450 Loss 0.4005 Accuracy 0.9074
Epoch 14 Batch 500 Loss 0.4016 Accuracy 0.9072
Epoch 14 Batch 550 Loss 0.4027 Accuracy 0.9071
Epoch 14 Batch 600 Loss 0.4034 Accuracy 0.9069
Epoch 14 Batch 650 Loss 0.4049 Accuracy 0.9067
Epoch 14 Batch 700 Loss 0.4059 Accuracy 0.9064
Epoch 14 Batch 750 Loss 0.4066 Accuracy 0.9062
Epoch 14 Batch 800 Loss 0.4078 Accuracy 0.9060
Epoch 14 Batch 850 Loss 0.4084 Accuracy 0.9059
discarded batch 868
Epoch 14 Batch 900 Loss 0.4091 Accuracy 0.9059
Epoch 14 Batch 950 Loss 0.4098 Accuracy 0.9057
Epoch 14 Batch 1000 Loss 0.4107 Accuracy 0.9055
Epoch 14 Batch 1050 Loss 0.4111 Accuracy 0.9054
Epoch 14 Batch 1100 Loss 0.4118 Accuracy 0.9054
Epoch 14 Batch 1150 Loss 0.4123 Accuracy 0.9052
Epoch 14 Batch 1200 Loss 0.4133 Accuracy 0.9051
Epoch 14 Batch 1250 Loss 0.4138 Accuracy 0.9049
Epoch 14 Batch 1300 Loss 0.4147 Accuracy 0.9048
Epoch 14 Batch 1350 Loss 0.4154 Accuracy 0.9046
Epoch 14 Batch 1400 Loss 0.4160 Accuracy 0.9045
Epoch 14 Batch 1450 Loss 0.4166 Accuracy 0.9045
Epoch 14 Batch 1500 Loss 0.4174 Accuracy 0.9044

wandb: WARNING Step must only increase in log calls.  Step 14 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.41784814>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90434295>}.

Epoch 14 Loss 0.4178 Accuracy 0.9043
Time taken for 1 epoch: 35.71383547782898 secs

epoch lasted: 35.729522705078125
Epoch 15 Batch 0 Loss 0.4007 Accuracy 0.9103
Epoch 15 Batch 50 Loss 0.3917 Accuracy 0.9081
Epoch 15 Batch 100 Loss 0.3953 Accuracy 0.9079
Epoch 15 Batch 150 Loss 0.3955 Accuracy 0.9077
Epoch 15 Batch 200 Loss 0.3945 Accuracy 0.9080
Epoch 15 Batch 250 Loss 0.3961 Accuracy 0.9079
Epoch 15 Batch 300 Loss 0.3981 Accuracy 0.9075
Epoch 15 Batch 350 Loss 0.3985 Accuracy 0.9074
Epoch 15 Batch 400 Loss 0.3983 Accuracy 0.9073
Epoch 15 Batch 450 Loss 0.3997 Accuracy 0.9071
discarded batch 455
Epoch 15 Batch 500 Loss 0.4010 Accuracy 0.9068
Epoch 15 Batch 550 Loss 0.4019 Accuracy 0.9068
Epoch 15 Batch 600 Loss 0.4033 Accuracy 0.9066
Epoch 15 Batch 650 Loss 0.4041 Accuracy 0.9065
Epoch 15 Batch 700 Loss 0.4047 Accuracy 0.9063
Epoch 15 Batch 750 Loss 0.4059 Accuracy 0.9060
Epoch 15 Batch 800 Loss 0.4066 Accuracy 0.9059
Epoch 15 Batch 850 Loss 0.4078 Accuracy 0.9058
Epoch 15 Batch 900 Loss 0.4081 Accuracy 0.9057
Epoch 15 Batch 950 Loss 0.4086 Accuracy 0.9055
Epoch 15 Batch 1000 Loss 0.4093 Accuracy 0.9054
Epoch 15 Batch 1050 Loss 0.4101 Accuracy 0.9053
Epoch 15 Batch 1100 Loss 0.4109 Accuracy 0.9052
Epoch 15 Batch 1150 Loss 0.4117 Accuracy 0.9051
Epoch 15 Batch 1200 Loss 0.4129 Accuracy 0.9049
Epoch 15 Batch 1250 Loss 0.4132 Accuracy 0.9048
Epoch 15 Batch 1300 Loss 0.4138 Accuracy 0.9047
Epoch 15 Batch 1350 Loss 0.4143 Accuracy 0.9046
Epoch 15 Batch 1400 Loss 0.4148 Accuracy 0.9044
Epoch 15 Batch 1450 Loss 0.4155 Accuracy 0.9043
Epoch 15 Batch 1500 Loss 0.4160 Accuracy 0.9042

wandb: WARNING Step must only increase in log calls.  Step 15 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.41672987>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90408665>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-19
Epoch 15 Loss 0.4167 Accuracy 0.9041
Time taken for 1 epoch: 35.89846062660217 secs

epoch lasted: 35.90258002281189
Epoch 16 Batch 0 Loss 0.3732 Accuracy 0.9219
Epoch 16 Batch 50 Loss 0.3878 Accuracy 0.9109
Epoch 16 Batch 100 Loss 0.3888 Accuracy 0.9098
Epoch 16 Batch 150 Loss 0.3918 Accuracy 0.9092
Epoch 16 Batch 200 Loss 0.3930 Accuracy 0.9083
Epoch 16 Batch 250 Loss 0.3943 Accuracy 0.9081
Epoch 16 Batch 300 Loss 0.3945 Accuracy 0.9081
Epoch 16 Batch 350 Loss 0.3956 Accuracy 0.9079
Epoch 16 Batch 400 Loss 0.3965 Accuracy 0.9077
Epoch 16 Batch 450 Loss 0.3975 Accuracy 0.9075
Epoch 16 Batch 500 Loss 0.3990 Accuracy 0.9073
Epoch 16 Batch 550 Loss 0.4004 Accuracy 0.9070
discarded batch 594
Epoch 16 Batch 600 Loss 0.4016 Accuracy 0.9067
Epoch 16 Batch 650 Loss 0.4027 Accuracy 0.9065
Epoch 16 Batch 700 Loss 0.4034 Accuracy 0.9064
Epoch 16 Batch 750 Loss 0.4042 Accuracy 0.9064
Epoch 16 Batch 800 Loss 0.4048 Accuracy 0.9063
Epoch 16 Batch 850 Loss 0.4060 Accuracy 0.9061
Epoch 16 Batch 900 Loss 0.4068 Accuracy 0.9059
Epoch 16 Batch 950 Loss 0.4075 Accuracy 0.9058
Epoch 16 Batch 1000 Loss 0.4085 Accuracy 0.9057
Epoch 16 Batch 1050 Loss 0.4089 Accuracy 0.9056
Epoch 16 Batch 1100 Loss 0.4093 Accuracy 0.9055
Epoch 16 Batch 1150 Loss 0.4103 Accuracy 0.9053
Epoch 16 Batch 1200 Loss 0.4112 Accuracy 0.9052
Epoch 16 Batch 1250 Loss 0.4117 Accuracy 0.9052
Epoch 16 Batch 1300 Loss 0.4127 Accuracy 0.9050
Epoch 16 Batch 1350 Loss 0.4134 Accuracy 0.9049
Epoch 16 Batch 1400 Loss 0.4139 Accuracy 0.9049
Epoch 16 Batch 1450 Loss 0.4147 Accuracy 0.9047
Epoch 16 Batch 1500 Loss 0.4155 Accuracy 0.9045

wandb: WARNING Step must only increase in log calls.  Step 16 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4160187>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9044448>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 25; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8272345>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86622375>}.

Epoch 16 Loss 0.4160 Accuracy 0.9044
Time taken for 1 epoch: 35.77234506607056 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.8272 Accuracy 0.8662

epoch lasted: 35.92727994918823
Epoch 17 Batch 0 Loss 0.3836 Accuracy 0.9103
Epoch 17 Batch 50 Loss 0.3890 Accuracy 0.9096
Epoch 17 Batch 100 Loss 0.3903 Accuracy 0.9093
Epoch 17 Batch 150 Loss 0.3924 Accuracy 0.9084
Epoch 17 Batch 200 Loss 0.3926 Accuracy 0.9085
Epoch 17 Batch 250 Loss 0.3930 Accuracy 0.9083
Epoch 17 Batch 300 Loss 0.3947 Accuracy 0.9084
Epoch 17 Batch 350 Loss 0.3957 Accuracy 0.9082
Epoch 17 Batch 400 Loss 0.3984 Accuracy 0.9078
Epoch 17 Batch 450 Loss 0.3990 Accuracy 0.9077
Epoch 17 Batch 500 Loss 0.3995 Accuracy 0.9076
Epoch 17 Batch 550 Loss 0.3997 Accuracy 0.9075
Epoch 17 Batch 600 Loss 0.3997 Accuracy 0.9074
Epoch 17 Batch 650 Loss 0.4012 Accuracy 0.9070
Epoch 17 Batch 700 Loss 0.4022 Accuracy 0.9069
Epoch 17 Batch 750 Loss 0.4031 Accuracy 0.9067
Epoch 17 Batch 800 Loss 0.4043 Accuracy 0.9064
Epoch 17 Batch 850 Loss 0.4053 Accuracy 0.9063
Epoch 17 Batch 900 Loss 0.4063 Accuracy 0.9061
Epoch 17 Batch 950 Loss 0.4067 Accuracy 0.9061
Epoch 17 Batch 1000 Loss 0.4074 Accuracy 0.9060
Epoch 17 Batch 1050 Loss 0.4078 Accuracy 0.9059
Epoch 17 Batch 1100 Loss 0.4084 Accuracy 0.9058
Epoch 17 Batch 1150 Loss 0.4094 Accuracy 0.9057
Epoch 17 Batch 1200 Loss 0.4098 Accuracy 0.9057
Epoch 17 Batch 1250 Loss 0.4106 Accuracy 0.9055
Epoch 17 Batch 1300 Loss 0.4116 Accuracy 0.9053
Epoch 17 Batch 1350 Loss 0.4122 Accuracy 0.9052
Epoch 17 Batch 1400 Loss 0.4128 Accuracy 0.9052
Epoch 17 Batch 1450 Loss 0.4135 Accuracy 0.9051
discarded batch 1458
Epoch 17 Batch 1500 Loss 0.4139 Accuracy 0.9050

wandb: WARNING Step must only increase in log calls.  Step 17 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4145212>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9049199>}.

Epoch 17 Loss 0.4145 Accuracy 0.9049
Time taken for 1 epoch: 35.885456800460815 secs

epoch lasted: 35.8915798664093
Epoch 18 Batch 0 Loss 0.3749 Accuracy 0.9136
Epoch 18 Batch 50 Loss 0.3840 Accuracy 0.9092
Epoch 18 Batch 100 Loss 0.3824 Accuracy 0.9096
Epoch 18 Batch 150 Loss 0.3857 Accuracy 0.9093
Epoch 18 Batch 200 Loss 0.3871 Accuracy 0.9091
Epoch 18 Batch 250 Loss 0.3896 Accuracy 0.9087
Epoch 18 Batch 300 Loss 0.3890 Accuracy 0.9089
Epoch 18 Batch 350 Loss 0.3899 Accuracy 0.9087
Epoch 18 Batch 400 Loss 0.3914 Accuracy 0.9087
Epoch 18 Batch 450 Loss 0.3928 Accuracy 0.9085
Epoch 18 Batch 500 Loss 0.3930 Accuracy 0.9084
Epoch 18 Batch 550 Loss 0.3939 Accuracy 0.9082
Epoch 18 Batch 600 Loss 0.3945 Accuracy 0.9081
discarded batch 632
Epoch 18 Batch 650 Loss 0.3954 Accuracy 0.9080
Epoch 18 Batch 700 Loss 0.3966 Accuracy 0.9078
Epoch 18 Batch 750 Loss 0.3981 Accuracy 0.9076
Epoch 18 Batch 800 Loss 0.3991 Accuracy 0.9074
Epoch 18 Batch 850 Loss 0.4001 Accuracy 0.9072
Epoch 18 Batch 900 Loss 0.4010 Accuracy 0.9071
Epoch 18 Batch 950 Loss 0.4020 Accuracy 0.9069
Epoch 18 Batch 1000 Loss 0.4030 Accuracy 0.9067
Epoch 18 Batch 1050 Loss 0.4041 Accuracy 0.9065
Epoch 18 Batch 1100 Loss 0.4050 Accuracy 0.9063
Epoch 18 Batch 1150 Loss 0.4059 Accuracy 0.9061
Epoch 18 Batch 1200 Loss 0.4069 Accuracy 0.9060
Epoch 18 Batch 1250 Loss 0.4079 Accuracy 0.9059
Epoch 18 Batch 1300 Loss 0.4088 Accuracy 0.9057
Epoch 18 Batch 1350 Loss 0.4093 Accuracy 0.9056
Epoch 18 Batch 1400 Loss 0.4097 Accuracy 0.9056
Epoch 18 Batch 1450 Loss 0.4102 Accuracy 0.9055
Epoch 18 Batch 1500 Loss 0.4110 Accuracy 0.9054

wandb: WARNING Step must only increase in log calls.  Step 18 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.41179183>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90531135>}.

Epoch 18 Loss 0.4118 Accuracy 0.9053
Time taken for 1 epoch: 36.01844358444214 secs

epoch lasted: 36.02399730682373
Epoch 19 Batch 0 Loss 0.4543 Accuracy 0.9053
Epoch 19 Batch 50 Loss 0.3816 Accuracy 0.9102
Epoch 19 Batch 100 Loss 0.3807 Accuracy 0.9104
Epoch 19 Batch 150 Loss 0.3841 Accuracy 0.9100
Epoch 19 Batch 200 Loss 0.3864 Accuracy 0.9097
Epoch 19 Batch 250 Loss 0.3868 Accuracy 0.9098
Epoch 19 Batch 300 Loss 0.3898 Accuracy 0.9089
Epoch 19 Batch 350 Loss 0.3911 Accuracy 0.9087
Epoch 19 Batch 400 Loss 0.3928 Accuracy 0.9085
Epoch 19 Batch 450 Loss 0.3935 Accuracy 0.9083
Epoch 19 Batch 500 Loss 0.3941 Accuracy 0.9081
Epoch 19 Batch 550 Loss 0.3952 Accuracy 0.9079
Epoch 19 Batch 600 Loss 0.3966 Accuracy 0.9078
Epoch 19 Batch 650 Loss 0.3976 Accuracy 0.9076
Epoch 19 Batch 700 Loss 0.3989 Accuracy 0.9074
Epoch 19 Batch 750 Loss 0.3997 Accuracy 0.9073
Epoch 19 Batch 800 Loss 0.4003 Accuracy 0.9072
Epoch 19 Batch 850 Loss 0.4010 Accuracy 0.9071
Epoch 19 Batch 900 Loss 0.4023 Accuracy 0.9068
Epoch 19 Batch 950 Loss 0.4032 Accuracy 0.9067
Epoch 19 Batch 1000 Loss 0.4040 Accuracy 0.9066
Epoch 19 Batch 1050 Loss 0.4046 Accuracy 0.9065
discarded batch 1055
Epoch 19 Batch 1100 Loss 0.4052 Accuracy 0.9064
Epoch 19 Batch 1150 Loss 0.4058 Accuracy 0.9062
Epoch 19 Batch 1200 Loss 0.4065 Accuracy 0.9061
Epoch 19 Batch 1250 Loss 0.4071 Accuracy 0.9060
Epoch 19 Batch 1300 Loss 0.4079 Accuracy 0.9058
Epoch 19 Batch 1350 Loss 0.4084 Accuracy 0.9057
Epoch 19 Batch 1400 Loss 0.4090 Accuracy 0.9056
Epoch 19 Batch 1450 Loss 0.4099 Accuracy 0.9055
Epoch 19 Batch 1500 Loss 0.4104 Accuracy 0.9054

wandb: WARNING Step must only increase in log calls.  Step 19 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.41121083>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90529096>}.

Epoch 19 Loss 0.4112 Accuracy 0.9053
Time taken for 1 epoch: 36.367977142333984 secs

epoch lasted: 36.373756647109985
Epoch 20 Batch 0 Loss 0.4218 Accuracy 0.8904
Epoch 20 Batch 50 Loss 0.3776 Accuracy 0.9101
Epoch 20 Batch 100 Loss 0.3855 Accuracy 0.9091
Epoch 20 Batch 150 Loss 0.3882 Accuracy 0.9092
Epoch 20 Batch 200 Loss 0.3892 Accuracy 0.9091
Epoch 20 Batch 250 Loss 0.3893 Accuracy 0.9089
Epoch 20 Batch 300 Loss 0.3912 Accuracy 0.9085
Epoch 20 Batch 350 Loss 0.3916 Accuracy 0.9084
Epoch 20 Batch 400 Loss 0.3926 Accuracy 0.9081
Epoch 20 Batch 450 Loss 0.3936 Accuracy 0.9080
Epoch 20 Batch 500 Loss 0.3948 Accuracy 0.9076
Epoch 20 Batch 550 Loss 0.3967 Accuracy 0.9074
Epoch 20 Batch 600 Loss 0.3972 Accuracy 0.9073
Epoch 20 Batch 650 Loss 0.3975 Accuracy 0.9072
Epoch 20 Batch 700 Loss 0.3982 Accuracy 0.9070
Epoch 20 Batch 750 Loss 0.3990 Accuracy 0.9070
Epoch 20 Batch 800 Loss 0.3999 Accuracy 0.9069
discarded batch 837
Epoch 20 Batch 850 Loss 0.4007 Accuracy 0.9068
Epoch 20 Batch 900 Loss 0.4014 Accuracy 0.9068
Epoch 20 Batch 950 Loss 0.4022 Accuracy 0.9066
Epoch 20 Batch 1000 Loss 0.4030 Accuracy 0.9065
Epoch 20 Batch 1050 Loss 0.4035 Accuracy 0.9065
Epoch 20 Batch 1100 Loss 0.4042 Accuracy 0.9064
Epoch 20 Batch 1150 Loss 0.4049 Accuracy 0.9062
Epoch 20 Batch 1200 Loss 0.4057 Accuracy 0.9062
Epoch 20 Batch 1250 Loss 0.4063 Accuracy 0.9060
Epoch 20 Batch 1300 Loss 0.4071 Accuracy 0.9059
Epoch 20 Batch 1350 Loss 0.4076 Accuracy 0.9058
Epoch 20 Batch 1400 Loss 0.4084 Accuracy 0.9056
Epoch 20 Batch 1450 Loss 0.4091 Accuracy 0.9055
Epoch 20 Batch 1500 Loss 0.4095 Accuracy 0.9054

wandb: WARNING Step must only increase in log calls.  Step 20 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.41011298>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9053135>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-20
Epoch 20 Loss 0.4101 Accuracy 0.9053
Time taken for 1 epoch: 36.45523428916931 secs

epoch lasted: 36.45943236351013
Epoch 21 Batch 0 Loss 0.3830 Accuracy 0.9020
Epoch 21 Batch 50 Loss 0.3794 Accuracy 0.9104
Epoch 21 Batch 100 Loss 0.3813 Accuracy 0.9095
Epoch 21 Batch 150 Loss 0.3824 Accuracy 0.9095
Epoch 21 Batch 200 Loss 0.3828 Accuracy 0.9099
Epoch 21 Batch 250 Loss 0.3841 Accuracy 0.9094
Epoch 21 Batch 300 Loss 0.3856 Accuracy 0.9089
Epoch 21 Batch 350 Loss 0.3874 Accuracy 0.9087
Epoch 21 Batch 400 Loss 0.3892 Accuracy 0.9086
Epoch 21 Batch 450 Loss 0.3901 Accuracy 0.9085
Epoch 21 Batch 500 Loss 0.3912 Accuracy 0.9084
Epoch 21 Batch 550 Loss 0.3919 Accuracy 0.9084
Epoch 21 Batch 600 Loss 0.3923 Accuracy 0.9083
Epoch 21 Batch 650 Loss 0.3939 Accuracy 0.9082
Epoch 21 Batch 700 Loss 0.3947 Accuracy 0.9080
Epoch 21 Batch 750 Loss 0.3960 Accuracy 0.9077
Epoch 21 Batch 800 Loss 0.3970 Accuracy 0.9075
Epoch 21 Batch 850 Loss 0.3975 Accuracy 0.9075
Epoch 21 Batch 900 Loss 0.3993 Accuracy 0.9073
discarded batch 911
Epoch 21 Batch 950 Loss 0.3999 Accuracy 0.9071
Epoch 21 Batch 1000 Loss 0.4007 Accuracy 0.9070
Epoch 21 Batch 1050 Loss 0.4015 Accuracy 0.9069
Epoch 21 Batch 1100 Loss 0.4025 Accuracy 0.9067
Epoch 21 Batch 1150 Loss 0.4031 Accuracy 0.9066
Epoch 21 Batch 1200 Loss 0.4037 Accuracy 0.9065
Epoch 21 Batch 1250 Loss 0.4044 Accuracy 0.9064
Epoch 21 Batch 1300 Loss 0.4049 Accuracy 0.9063
Epoch 21 Batch 1350 Loss 0.4051 Accuracy 0.9062
Epoch 21 Batch 1400 Loss 0.4059 Accuracy 0.9061
Epoch 21 Batch 1450 Loss 0.4070 Accuracy 0.9060
Epoch 21 Batch 1500 Loss 0.4075 Accuracy 0.9059

wandb: WARNING Step must only increase in log calls.  Step 21 < 25; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.40822697>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9057982>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 25; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8284141>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8663345>}.

Epoch 21 Loss 0.4082 Accuracy 0.9058
Time taken for 1 epoch: 35.89729881286621 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.8284 Accuracy 0.8663

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 po|scia |ch’ io |gi|ro |fuor |da |lei |ri|vol|ti|re|
che |li oc|chi |miei |pas|sa|reb|be |li |col|le|
io |dis|si |vol|gi|nan|zi a |li oc|chi |sie|re|
                                                                                                                                                                   
 e |io |a |ri|ma|se e |ri|vol|te |vol|le|
ma |non |so |ve|der |non |pos|so |ri|spuo|se|
ma |dim|mi |quel |che |tu |vuo’ |ch’ i’ |o|mol|le|
ma |quei |che |li|be|ne o|mai |non |si |co|lor |ve|de|
per |lo |co|me a |si|mi|glia |di |ca|de|gno|
ma |non |si |con|ce|pe|rò |ch’ i’ |o|de|re|
                                                                                                                                                                   
 ma |quei |che |per |la |gen|te |con |la |val|le|
per |ch’ i’ |ho |ve|dea |da |lei |si |mo|le|re|
ma |per |la |sua |cor|sa |che |non |si |pa|ce|
se|gnor |che |tut|to ’l |mon|te |le |gen|te |ve|ste|se|
non |po|sa |di |là |do|ve |tu |com|pa|
ma |per|ché |pur |con |lei |ma |quei |fu |lo|re|gno|
                                                                                                                                                                   
 non |pos|son |na|va |non |vo’ |che |di|sce|ma|
né |cre|dea |da |lui |che |so|pra |re|gno|le|
e |io |e|ra |già |mai |non |è |più |bas|si|
co|sì |que|sta |gen|te |che |per |cui |gi|ran|do|
con |que|sta |gen|te |di |là |sù |non |si |mo|ve|
ma |con |tut|ta |fu |per |cui |non |si |mo|do|
                                                                                                                                                                   
 ma |io |li |fu |a |me |per |lo |fon|do|ve|
quan|do |mi |ce|rò |nel |ve|nir |del |mon|do|
a |l’ u|ni|ver|go|scia|to e |l’ al|tra |fo|co|
 e |l’ al|tre |che |ne |fa|ce|le|men|te |te|gno|
ma |per |la |mia |co|lor |non |può |ca|i|ma|
ma |per |le |ve|ni|ce |mia |ca|sa |leg|ge|
                                                                                                                                                                   
 ma |io |a |lui |che |non |fu |ma|ri|ma|
ma |non |fe|ce |mia |ra|vi|ta |per |quel |ca|ge|
ma |per |te |si |mos|sa |non |può |ca|sti|ma|
e |già |mai |a |gui|sa |let|to a |lei |con|si|cu|ra|
e |quel|la |par|te |che |tut|te |qual |là |do|
e |io |a |cui |ve|der |la |mi|glia |mo|ra|
                                                                                                                                                                   
 e |di |co|lui |par|te |quel|la |fu |rat|to|
e |quel|la |par|te |sen |va |di |pro|fon|da|
non |par |mia |don|na e |die|tro e |si |di|let|to|
 che |non |son |na|scon|dir |ma |io |non |son |bel|le|
ma |per|do|ve |per |lo |per |ma|e|stro |mon|ta|
ma |per |lo |co|me |chi |son |con|giun|to|
                                                                                                                                                                   
 ma |io |le|va|por |do|ve |san|za |de|gno|
non |vol|te |di |cui |con |la |pri|mo |rot|to|
ma |mia |na|tu|ra |nul|la |col|pa |fa|ce|
non |si |fe|ce|le|ce |mia |don|na |di |sé |pro|ce|
non |co|me a |cui |non |pur |co|sì |be|a|to|
ma |non |è |ma |re|tro a |sé |la |me|mo|ce|
                                                                                                                                                                   
 ma |non |pur |con |que|sto |mon|ta |gio|na|sco|
per |con|vien |che |la |fa|cea |da |l’ ac|ce|ce|
ma |co|me a |cui |san|za |vo|ce |gio|na|sco|
e |non |è |quei |che |ve|de|stra |ca|gion |fu |mer|ca|
in|co|lui |fu |la |mia |don|na |fa|ti|ca|
e |con |in|te|ma |per |ve|dea |più |por|ca|
                                                                                                                                                                   
 con |al|tri|na |tri|sta |fos|se |com’ |è |do|
non |è |be|ne o|mai |la |don|na |che |tor|ca|
e |già |di |cui |per |lo|co |si |con|do|do|
e |io |e|sti|man|da |mia |ca|gion |di |co|sto|gna|
ben |far |di |là |o|gne |ben |di|vi|di|ce|
e |io |e|stro |dis|se |quel|la |leg|ge|gna|
                                                                                                                                                                   
 per |ma|la|men|te |già |per |ma|ra|vi|ce|
e |io |veg|gen|te |già |mai |non |si |pro|ce|
e |io |vi |mo|stra|va |né |per |fi|gu|ce|
 non |è |l’ ar|ca |dis|se |quel|le |ve|ren|dei|
o |don|na |di |là |do|v’ io |sta|la|gri|dan|do|
que|sto |man|co|me a |cui |tan|to |fu |pria|
                                                                                                                                                                    
 con |u|dir |li |rag|gia|ta |di |sot|ti|co|
e |dis|se ’l |mon|do |ca|po |di |so|spi|ri|
e |io |ma|e|stro |san|za |ch’ è |o|ne|co|
e |co|sì |per |ma|e|stro |dì |e |men |che |van|ti|
ma |quel|la |don|na |mia |che |più |di|let|to|
per |cui |ma|dre |ve|ren|za |non |si |puo|te|
                                                                                                                                                                   
 co|sì |a |cui |tan|to |fu |di|sï|an|to|
co|me ’l |sol |più |che |ta|men|te |fu |do|
co|me |fa |l’ uom |cui |lor |per |en|tro |sof|fer|to|
 per |le |sue |a |cui |di |là |do|ve |s’ a|spet|to|
e |se |li|be|re |di |noi |ca|ro |giu|so|
ma |per |que|sta |gen|te |fu |più |di|let|to|
                                                                                                                                                                   
 e |io |le|va |non |cre|det|ta |le|ti|ro|
non |son |ca|ro |sce|rà |la |mia |le|ga|to|
ma |non |pur |per |te |che |si |può |di|vi|ro|
ma |per|ché |pur |co|lui |che |per |la |pri|ma |ce|pe|
da |quel|la |cui |cri|sto |mon|te a|mo|ra |se|
non |que|sti |la|gri|dò |né |sì |fe|ce|pe|
                                                                                                                                                                   
 ma |poi |che |gen|te |sì |com’ |io |ar|go|
né |per |ch’ io |a |lui |già |e|ran |con |que|sto|re|
lo |mio |ve|ren|za |mia |don|na |di |gio|ga|
 e |io |che |la |mia |don|na e |non |vi |gi|ra|va|
ma |per |par|la|sciò |già |per |que|sto |mon|te|
ma |
ma |per |chi |già |mai |non |si |mo|va|
                                                                                                                                                                   
 e |io |a |lui |con |que|sti |per |con|fon|te|
con |tut|ti |già |par|ti |li al|tri |che |va|ga|
si |fe|cer |di |lu|ce |non |vi |si |fon|di|
 ma |per |la |te|ma |per |mo|stra |più |s’ a|spet|ta|
ma |per |lo |mon|te |fu |a |lui |con|giun|to|
con |tan|to ’l |mon|te |fu |del |suo |di|let|to|
                                                                                                                                                                   
 per |mo|stra|va |con |la |sua |ra|gio|ga|to|
non |è |ma |per |lo |me|glio |fu |det|ta |vi|
che |sie|te |del |le|re e |o |ben |si |pa|re|

epoch lasted: 519.7005200386047
(1900, 128)
Epoch 1 Batch 0 Loss 0.3862 Accuracy 0.9186
Epoch 1 Batch 50 Loss 0.3807 Accuracy 0.9117
Epoch 1 Batch 100 Loss 0.3786 Accuracy 0.9112
Epoch 1 Batch 150 Loss 0.3808 Accuracy 0.9104
Epoch 1 Batch 200 Loss 0.3830 Accuracy 0.9105
Epoch 1 Batch 250 Loss 0.3854 Accuracy 0.9101
Epoch 1 Batch 300 Loss 0.3865 Accuracy 0.9098
Epoch 1 Batch 350 Loss 0.3879 Accuracy 0.9094
Epoch 1 Batch 400 Loss 0.3897 Accuracy 0.9092
Epoch 1 Batch 450 Loss 0.3904 Accuracy 0.9090
Epoch 1 Batch 500 Loss 0.3920 Accuracy 0.9089
discarded batch 538
Epoch 1 Batch 550 Loss 0.3928 Accuracy 0.9086
Epoch 1 Batch 600 Loss 0.3937 Accuracy 0.9084
Epoch 1 Batch 650 Loss 0.3944 Accuracy 0.9084
Epoch 1 Batch 700 Loss 0.3955 Accuracy 0.9082
Epoch 1 Batch 750 Loss 0.3962 Accuracy 0.9080
Epoch 1 Batch 800 Loss 0.3973 Accuracy 0.9077
Epoch 1 Batch 850 Loss 0.3978 Accuracy 0.9076
Epoch 1 Batch 900 Loss 0.3988 Accuracy 0.9075
Epoch 1 Batch 950 Loss 0.3993 Accuracy 0.9074
Epoch 1 Batch 1000 Loss 0.3999 Accuracy 0.9073
Epoch 1 Batch 1050 Loss 0.4005 Accuracy 0.9072
Epoch 1 Batch 1100 Loss 0.4011 Accuracy 0.9071
Epoch 1 Batch 1150 Loss 0.4019 Accuracy 0.9070
Epoch 1 Batch 1200 Loss 0.4020 Accuracy 0.9069
Epoch 1 Batch 1250 Loss 0.4028 Accuracy 0.9069
Epoch 1 Batch 1300 Loss 0.4039 Accuracy 0.9067
Epoch 1 Batch 1350 Loss 0.4046 Accuracy 0.9065
Epoch 1 Batch 1400 Loss 0.4055 Accuracy 0.9064
Epoch 1 Batch 1450 Loss 0.4060 Accuracy 0.9063
Epoch 1 Batch 1500 Loss 0.4066 Accuracy 0.9062

wandb: WARNING Step must only increase in log calls.  Step 1 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.407197>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9060824>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 26; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.835063>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86489475>}.

Epoch 1 Loss 0.4072 Accuracy 0.9061
Time taken for 1 epoch: 36.03545570373535 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.8351 Accuracy 0.8649

epoch lasted: 36.19442868232727
Epoch 2 Batch 0 Loss 0.4060 Accuracy 0.8953
Epoch 2 Batch 50 Loss 0.3783 Accuracy 0.9115
Epoch 2 Batch 100 Loss 0.3767 Accuracy 0.9113
Epoch 2 Batch 150 Loss 0.3801 Accuracy 0.9108
Epoch 2 Batch 200 Loss 0.3801 Accuracy 0.9109
Epoch 2 Batch 250 Loss 0.3810 Accuracy 0.9106
Epoch 2 Batch 300 Loss 0.3824 Accuracy 0.9105
Epoch 2 Batch 350 Loss 0.3829 Accuracy 0.9104
Epoch 2 Batch 400 Loss 0.3842 Accuracy 0.9101
Epoch 2 Batch 450 Loss 0.3860 Accuracy 0.9098
Epoch 2 Batch 500 Loss 0.3871 Accuracy 0.9096
Epoch 2 Batch 550 Loss 0.3880 Accuracy 0.9095
Epoch 2 Batch 600 Loss 0.3891 Accuracy 0.9091
discarded batch 627
Epoch 2 Batch 650 Loss 0.3902 Accuracy 0.9090
Epoch 2 Batch 700 Loss 0.3910 Accuracy 0.9088
Epoch 2 Batch 750 Loss 0.3924 Accuracy 0.9086
Epoch 2 Batch 800 Loss 0.3932 Accuracy 0.9084
Epoch 2 Batch 850 Loss 0.3940 Accuracy 0.9083
Epoch 2 Batch 900 Loss 0.3947 Accuracy 0.9081
Epoch 2 Batch 950 Loss 0.3956 Accuracy 0.9080
Epoch 2 Batch 1000 Loss 0.3962 Accuracy 0.9079
Epoch 2 Batch 1050 Loss 0.3970 Accuracy 0.9078
Epoch 2 Batch 1100 Loss 0.3980 Accuracy 0.9075
Epoch 2 Batch 1150 Loss 0.3987 Accuracy 0.9074
Epoch 2 Batch 1200 Loss 0.3996 Accuracy 0.9073
Epoch 2 Batch 1250 Loss 0.4001 Accuracy 0.9072
Epoch 2 Batch 1300 Loss 0.4012 Accuracy 0.9069
Epoch 2 Batch 1350 Loss 0.4021 Accuracy 0.9068
Epoch 2 Batch 1400 Loss 0.4030 Accuracy 0.9067
Epoch 2 Batch 1450 Loss 0.4039 Accuracy 0.9066
Epoch 2 Batch 1500 Loss 0.4045 Accuracy 0.9065

wandb: WARNING Step must only increase in log calls.  Step 2 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.40528008>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9063987>}.

Epoch 2 Loss 0.4053 Accuracy 0.9064
Time taken for 1 epoch: 35.73851537704468 secs

epoch lasted: 35.74267053604126
Epoch 3 Batch 0 Loss 0.3746 Accuracy 0.9037
Epoch 3 Batch 50 Loss 0.3746 Accuracy 0.9137
Epoch 3 Batch 100 Loss 0.3785 Accuracy 0.9120
Epoch 3 Batch 150 Loss 0.3784 Accuracy 0.9107
Epoch 3 Batch 200 Loss 0.3791 Accuracy 0.9107
Epoch 3 Batch 250 Loss 0.3791 Accuracy 0.9107
Epoch 3 Batch 300 Loss 0.3801 Accuracy 0.9103
discarded batch 315
Epoch 3 Batch 350 Loss 0.3820 Accuracy 0.9101
Epoch 3 Batch 400 Loss 0.3821 Accuracy 0.9101
Epoch 3 Batch 450 Loss 0.3837 Accuracy 0.9098
Epoch 3 Batch 500 Loss 0.3845 Accuracy 0.9096
Epoch 3 Batch 550 Loss 0.3862 Accuracy 0.9094
Epoch 3 Batch 600 Loss 0.3872 Accuracy 0.9092
Epoch 3 Batch 650 Loss 0.3882 Accuracy 0.9090
Epoch 3 Batch 700 Loss 0.3896 Accuracy 0.9087
Epoch 3 Batch 750 Loss 0.3902 Accuracy 0.9087
Epoch 3 Batch 800 Loss 0.3912 Accuracy 0.9086
Epoch 3 Batch 850 Loss 0.3928 Accuracy 0.9083
Epoch 3 Batch 900 Loss 0.3937 Accuracy 0.9081
Epoch 3 Batch 950 Loss 0.3949 Accuracy 0.9079
Epoch 3 Batch 1000 Loss 0.3955 Accuracy 0.9078
Epoch 3 Batch 1050 Loss 0.3960 Accuracy 0.9076
Epoch 3 Batch 1100 Loss 0.3968 Accuracy 0.9074
Epoch 3 Batch 1150 Loss 0.3977 Accuracy 0.9073
Epoch 3 Batch 1200 Loss 0.3983 Accuracy 0.9072
Epoch 3 Batch 1250 Loss 0.3990 Accuracy 0.9071
Epoch 3 Batch 1300 Loss 0.3998 Accuracy 0.9071
Epoch 3 Batch 1350 Loss 0.4006 Accuracy 0.9069
Epoch 3 Batch 1400 Loss 0.4014 Accuracy 0.9068
Epoch 3 Batch 1450 Loss 0.4021 Accuracy 0.9067
Epoch 3 Batch 1500 Loss 0.4027 Accuracy 0.9066

wandb: WARNING Step must only increase in log calls.  Step 3 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.40355983>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9064963>}.

Epoch 3 Loss 0.4036 Accuracy 0.9065
Time taken for 1 epoch: 35.850563049316406 secs

epoch lasted: 35.85472226142883
Epoch 4 Batch 0 Loss 0.3972 Accuracy 0.9136
Epoch 4 Batch 50 Loss 0.3694 Accuracy 0.9133
Epoch 4 Batch 100 Loss 0.3700 Accuracy 0.9130
Epoch 4 Batch 150 Loss 0.3753 Accuracy 0.9117
Epoch 4 Batch 200 Loss 0.3755 Accuracy 0.9113
Epoch 4 Batch 250 Loss 0.3773 Accuracy 0.9110
Epoch 4 Batch 300 Loss 0.3773 Accuracy 0.9107
Epoch 4 Batch 350 Loss 0.3802 Accuracy 0.9102
Epoch 4 Batch 400 Loss 0.3807 Accuracy 0.9102
Epoch 4 Batch 450 Loss 0.3814 Accuracy 0.9101
discarded batch 483
Epoch 4 Batch 500 Loss 0.3827 Accuracy 0.9098
Epoch 4 Batch 550 Loss 0.3844 Accuracy 0.9096
Epoch 4 Batch 600 Loss 0.3858 Accuracy 0.9094
Epoch 4 Batch 650 Loss 0.3867 Accuracy 0.9093
Epoch 4 Batch 700 Loss 0.3878 Accuracy 0.9091
Epoch 4 Batch 750 Loss 0.3888 Accuracy 0.9089
Epoch 4 Batch 800 Loss 0.3898 Accuracy 0.9086
Epoch 4 Batch 850 Loss 0.3909 Accuracy 0.9085
Epoch 4 Batch 900 Loss 0.3917 Accuracy 0.9085
Epoch 4 Batch 950 Loss 0.3927 Accuracy 0.9083
Epoch 4 Batch 1000 Loss 0.3936 Accuracy 0.9081
Epoch 4 Batch 1050 Loss 0.3943 Accuracy 0.9080
Epoch 4 Batch 1100 Loss 0.3949 Accuracy 0.9079
Epoch 4 Batch 1150 Loss 0.3955 Accuracy 0.9078
Epoch 4 Batch 1200 Loss 0.3963 Accuracy 0.9078
Epoch 4 Batch 1250 Loss 0.3970 Accuracy 0.9076
Epoch 4 Batch 1300 Loss 0.3978 Accuracy 0.9075
Epoch 4 Batch 1350 Loss 0.3985 Accuracy 0.9073
Epoch 4 Batch 1400 Loss 0.3993 Accuracy 0.9072
Epoch 4 Batch 1450 Loss 0.3999 Accuracy 0.9071
Epoch 4 Batch 1500 Loss 0.4006 Accuracy 0.9071

wandb: WARNING Step must only increase in log calls.  Step 4 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.401183>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9069542>}.

Epoch 4 Loss 0.4012 Accuracy 0.9070
Time taken for 1 epoch: 35.80481147766113 secs

epoch lasted: 35.808929204940796
Epoch 5 Batch 0 Loss 0.3945 Accuracy 0.9037
Epoch 5 Batch 50 Loss 0.3775 Accuracy 0.9109
Epoch 5 Batch 100 Loss 0.3755 Accuracy 0.9106
Epoch 5 Batch 150 Loss 0.3751 Accuracy 0.9105
Epoch 5 Batch 200 Loss 0.3780 Accuracy 0.9103
Epoch 5 Batch 250 Loss 0.3788 Accuracy 0.9103
Epoch 5 Batch 300 Loss 0.3793 Accuracy 0.9101
Epoch 5 Batch 350 Loss 0.3795 Accuracy 0.9103
Epoch 5 Batch 400 Loss 0.3805 Accuracy 0.9103
Epoch 5 Batch 450 Loss 0.3811 Accuracy 0.9101
Epoch 5 Batch 500 Loss 0.3819 Accuracy 0.9101
Epoch 5 Batch 550 Loss 0.3829 Accuracy 0.9099
Epoch 5 Batch 600 Loss 0.3838 Accuracy 0.9097
Epoch 5 Batch 650 Loss 0.3847 Accuracy 0.9096
Epoch 5 Batch 700 Loss 0.3863 Accuracy 0.9093
Epoch 5 Batch 750 Loss 0.3869 Accuracy 0.9093
Epoch 5 Batch 800 Loss 0.3881 Accuracy 0.9091
Epoch 5 Batch 850 Loss 0.3892 Accuracy 0.9090
Epoch 5 Batch 900 Loss 0.3900 Accuracy 0.9088
Epoch 5 Batch 950 Loss 0.3908 Accuracy 0.9087
Epoch 5 Batch 1000 Loss 0.3916 Accuracy 0.9086
Epoch 5 Batch 1050 Loss 0.3929 Accuracy 0.9084
Epoch 5 Batch 1100 Loss 0.3938 Accuracy 0.9083
Epoch 5 Batch 1150 Loss 0.3947 Accuracy 0.9082
Epoch 5 Batch 1200 Loss 0.3957 Accuracy 0.9080
Epoch 5 Batch 1250 Loss 0.3962 Accuracy 0.9080
Epoch 5 Batch 1300 Loss 0.3969 Accuracy 0.9079
Epoch 5 Batch 1350 Loss 0.3981 Accuracy 0.9076
Epoch 5 Batch 1400 Loss 0.3991 Accuracy 0.9075
discarded batch 1433
Epoch 5 Batch 1450 Loss 0.3999 Accuracy 0.9074
Epoch 5 Batch 1500 Loss 0.4008 Accuracy 0.9072

wandb: WARNING Step must only increase in log calls.  Step 5 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.40105832>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90715796>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-21
Epoch 5 Loss 0.4011 Accuracy 0.9072
Time taken for 1 epoch: 36.02936816215515 secs

epoch lasted: 36.03351092338562
Epoch 6 Batch 0 Loss 0.4006 Accuracy 0.9153
Epoch 6 Batch 50 Loss 0.3631 Accuracy 0.9127
Epoch 6 Batch 100 Loss 0.3690 Accuracy 0.9131
Epoch 6 Batch 150 Loss 0.3701 Accuracy 0.9124
Epoch 6 Batch 200 Loss 0.3725 Accuracy 0.9121
Epoch 6 Batch 250 Loss 0.3753 Accuracy 0.9118
Epoch 6 Batch 300 Loss 0.3762 Accuracy 0.9116
Epoch 6 Batch 350 Loss 0.3780 Accuracy 0.9112
Epoch 6 Batch 400 Loss 0.3790 Accuracy 0.9110
discarded batch 408
Epoch 6 Batch 450 Loss 0.3810 Accuracy 0.9107
Epoch 6 Batch 500 Loss 0.3825 Accuracy 0.9105
Epoch 6 Batch 550 Loss 0.3835 Accuracy 0.9102
Epoch 6 Batch 600 Loss 0.3842 Accuracy 0.9101
Epoch 6 Batch 650 Loss 0.3847 Accuracy 0.9100
Epoch 6 Batch 700 Loss 0.3857 Accuracy 0.9097
Epoch 6 Batch 750 Loss 0.3867 Accuracy 0.9096
Epoch 6 Batch 800 Loss 0.3878 Accuracy 0.9092
Epoch 6 Batch 850 Loss 0.3887 Accuracy 0.9092
Epoch 6 Batch 900 Loss 0.3901 Accuracy 0.9089
Epoch 6 Batch 950 Loss 0.3908 Accuracy 0.9088
Epoch 6 Batch 1000 Loss 0.3914 Accuracy 0.9086
Epoch 6 Batch 1050 Loss 0.3921 Accuracy 0.9085
Epoch 6 Batch 1100 Loss 0.3928 Accuracy 0.9084
Epoch 6 Batch 1150 Loss 0.3936 Accuracy 0.9082
Epoch 6 Batch 1200 Loss 0.3946 Accuracy 0.9081
Epoch 6 Batch 1250 Loss 0.3955 Accuracy 0.9079
Epoch 6 Batch 1300 Loss 0.3961 Accuracy 0.9078
Epoch 6 Batch 1350 Loss 0.3969 Accuracy 0.9077
Epoch 6 Batch 1400 Loss 0.3977 Accuracy 0.9075
Epoch 6 Batch 1450 Loss 0.3985 Accuracy 0.9074
Epoch 6 Batch 1500 Loss 0.3992 Accuracy 0.9072

wandb: WARNING Step must only increase in log calls.  Step 6 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3997803>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90717083>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 26; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.84271157>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86500555>}.

Epoch 6 Loss 0.3998 Accuracy 0.9072
Time taken for 1 epoch: 35.74437117576599 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.8427 Accuracy 0.8650

epoch lasted: 35.904637813568115
Epoch 7 Batch 0 Loss 0.3470 Accuracy 0.9103
Epoch 7 Batch 50 Loss 0.3735 Accuracy 0.9115
Epoch 7 Batch 100 Loss 0.3773 Accuracy 0.9111
Epoch 7 Batch 150 Loss 0.3760 Accuracy 0.9112
Epoch 7 Batch 200 Loss 0.3758 Accuracy 0.9113
Epoch 7 Batch 250 Loss 0.3774 Accuracy 0.9108
Epoch 7 Batch 300 Loss 0.3783 Accuracy 0.9105
Epoch 7 Batch 350 Loss 0.3799 Accuracy 0.9103
Epoch 7 Batch 400 Loss 0.3794 Accuracy 0.9104
Epoch 7 Batch 450 Loss 0.3802 Accuracy 0.9101
Epoch 7 Batch 500 Loss 0.3803 Accuracy 0.9101
Epoch 7 Batch 550 Loss 0.3810 Accuracy 0.9098
Epoch 7 Batch 600 Loss 0.3822 Accuracy 0.9097
Epoch 7 Batch 650 Loss 0.3836 Accuracy 0.9095
Epoch 7 Batch 700 Loss 0.3845 Accuracy 0.9093
Epoch 7 Batch 750 Loss 0.3854 Accuracy 0.9092
Epoch 7 Batch 800 Loss 0.3867 Accuracy 0.9089
Epoch 7 Batch 850 Loss 0.3867 Accuracy 0.9089
Epoch 7 Batch 900 Loss 0.3874 Accuracy 0.9088
Epoch 7 Batch 950 Loss 0.3883 Accuracy 0.9086
discarded batch 984
Epoch 7 Batch 1000 Loss 0.3892 Accuracy 0.9085
Epoch 7 Batch 1050 Loss 0.3903 Accuracy 0.9084
Epoch 7 Batch 1100 Loss 0.3915 Accuracy 0.9082
Epoch 7 Batch 1150 Loss 0.3923 Accuracy 0.9081
Epoch 7 Batch 1200 Loss 0.3930 Accuracy 0.9080
Epoch 7 Batch 1250 Loss 0.3940 Accuracy 0.9078
Epoch 7 Batch 1300 Loss 0.3948 Accuracy 0.9077
Epoch 7 Batch 1350 Loss 0.3960 Accuracy 0.9075
Epoch 7 Batch 1400 Loss 0.3970 Accuracy 0.9074
Epoch 7 Batch 1450 Loss 0.3976 Accuracy 0.9073
Epoch 7 Batch 1500 Loss 0.3984 Accuracy 0.9072

wandb: WARNING Step must only increase in log calls.  Step 7 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3993474>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90704215>}.

Epoch 7 Loss 0.3993 Accuracy 0.9070
Time taken for 1 epoch: 35.85506629943848 secs

epoch lasted: 35.86729097366333
Epoch 8 Batch 0 Loss 0.3416 Accuracy 0.9153
Epoch 8 Batch 50 Loss 0.3633 Accuracy 0.9119
Epoch 8 Batch 100 Loss 0.3629 Accuracy 0.9126
Epoch 8 Batch 150 Loss 0.3628 Accuracy 0.9129
Epoch 8 Batch 200 Loss 0.3678 Accuracy 0.9118
Epoch 8 Batch 250 Loss 0.3698 Accuracy 0.9118
Epoch 8 Batch 300 Loss 0.3713 Accuracy 0.9115
Epoch 8 Batch 350 Loss 0.3739 Accuracy 0.9110
Epoch 8 Batch 400 Loss 0.3749 Accuracy 0.9110
Epoch 8 Batch 450 Loss 0.3771 Accuracy 0.9107
Epoch 8 Batch 500 Loss 0.3780 Accuracy 0.9104
Epoch 8 Batch 550 Loss 0.3791 Accuracy 0.9103
Epoch 8 Batch 600 Loss 0.3798 Accuracy 0.9102
Epoch 8 Batch 650 Loss 0.3808 Accuracy 0.9101
Epoch 8 Batch 700 Loss 0.3816 Accuracy 0.9101
Epoch 8 Batch 750 Loss 0.3827 Accuracy 0.9098
Epoch 8 Batch 800 Loss 0.3838 Accuracy 0.9097
Epoch 8 Batch 850 Loss 0.3845 Accuracy 0.9095
Epoch 8 Batch 900 Loss 0.3857 Accuracy 0.9094
Epoch 8 Batch 950 Loss 0.3868 Accuracy 0.9092
Epoch 8 Batch 1000 Loss 0.3878 Accuracy 0.9089
Epoch 8 Batch 1050 Loss 0.3889 Accuracy 0.9088
Epoch 8 Batch 1100 Loss 0.3897 Accuracy 0.9087
Epoch 8 Batch 1150 Loss 0.3908 Accuracy 0.9085
Epoch 8 Batch 1200 Loss 0.3912 Accuracy 0.9085
discarded batch 1221
Epoch 8 Batch 1250 Loss 0.3918 Accuracy 0.9083
Epoch 8 Batch 1300 Loss 0.3922 Accuracy 0.9082
Epoch 8 Batch 1350 Loss 0.3935 Accuracy 0.9081
Epoch 8 Batch 1400 Loss 0.3941 Accuracy 0.9080
Epoch 8 Batch 1450 Loss 0.3951 Accuracy 0.9079
Epoch 8 Batch 1500 Loss 0.3958 Accuracy 0.9078

wandb: WARNING Step must only increase in log calls.  Step 8 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.39658406>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9076695>}.

Epoch 8 Loss 0.3966 Accuracy 0.9077
Time taken for 1 epoch: 35.813589572906494 secs

epoch lasted: 35.81893062591553
Epoch 9 Batch 0 Loss 0.4369 Accuracy 0.8870
Epoch 9 Batch 50 Loss 0.3706 Accuracy 0.9116
Epoch 9 Batch 100 Loss 0.3654 Accuracy 0.9125
Epoch 9 Batch 150 Loss 0.3683 Accuracy 0.9119
Epoch 9 Batch 200 Loss 0.3694 Accuracy 0.9122
Epoch 9 Batch 250 Loss 0.3711 Accuracy 0.9118
Epoch 9 Batch 300 Loss 0.3723 Accuracy 0.9115
Epoch 9 Batch 350 Loss 0.3738 Accuracy 0.9111
Epoch 9 Batch 400 Loss 0.3764 Accuracy 0.9109
Epoch 9 Batch 450 Loss 0.3788 Accuracy 0.9104
Epoch 9 Batch 500 Loss 0.3797 Accuracy 0.9100
Epoch 9 Batch 550 Loss 0.3809 Accuracy 0.9099
Epoch 9 Batch 600 Loss 0.3813 Accuracy 0.9099
Epoch 9 Batch 650 Loss 0.3823 Accuracy 0.9097
Epoch 9 Batch 700 Loss 0.3833 Accuracy 0.9096
Epoch 9 Batch 750 Loss 0.3843 Accuracy 0.9095
Epoch 9 Batch 800 Loss 0.3847 Accuracy 0.9095
Epoch 9 Batch 850 Loss 0.3854 Accuracy 0.9093
Epoch 9 Batch 900 Loss 0.3863 Accuracy 0.9091
Epoch 9 Batch 950 Loss 0.3875 Accuracy 0.9089
Epoch 9 Batch 1000 Loss 0.3885 Accuracy 0.9087
Epoch 9 Batch 1050 Loss 0.3894 Accuracy 0.9085
Epoch 9 Batch 1100 Loss 0.3899 Accuracy 0.9084
Epoch 9 Batch 1150 Loss 0.3908 Accuracy 0.9082
Epoch 9 Batch 1200 Loss 0.3916 Accuracy 0.9081
Epoch 9 Batch 1250 Loss 0.3925 Accuracy 0.9079
Epoch 9 Batch 1300 Loss 0.3932 Accuracy 0.9078
Epoch 9 Batch 1350 Loss 0.3939 Accuracy 0.9077
discarded batch 1354
Epoch 9 Batch 1400 Loss 0.3945 Accuracy 0.9076
Epoch 9 Batch 1450 Loss 0.3950 Accuracy 0.9076
Epoch 9 Batch 1500 Loss 0.3957 Accuracy 0.9074

wandb: WARNING Step must only increase in log calls.  Step 9 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3963889>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90735316>}.

Epoch 9 Loss 0.3964 Accuracy 0.9074
Time taken for 1 epoch: 35.86663889884949 secs

epoch lasted: 35.87336444854736
Epoch 10 Batch 0 Loss 0.3891 Accuracy 0.9136
Epoch 10 Batch 50 Loss 0.3743 Accuracy 0.9113
Epoch 10 Batch 100 Loss 0.3708 Accuracy 0.9119
Epoch 10 Batch 150 Loss 0.3709 Accuracy 0.9118
Epoch 10 Batch 200 Loss 0.3741 Accuracy 0.9113
Epoch 10 Batch 250 Loss 0.3742 Accuracy 0.9115
Epoch 10 Batch 300 Loss 0.3759 Accuracy 0.9111
Epoch 10 Batch 350 Loss 0.3770 Accuracy 0.9108
Epoch 10 Batch 400 Loss 0.3778 Accuracy 0.9108
discarded batch 420
Epoch 10 Batch 450 Loss 0.3783 Accuracy 0.9107
Epoch 10 Batch 500 Loss 0.3797 Accuracy 0.9104
Epoch 10 Batch 550 Loss 0.3808 Accuracy 0.9101
Epoch 10 Batch 600 Loss 0.3814 Accuracy 0.9100
Epoch 10 Batch 650 Loss 0.3826 Accuracy 0.9098
Epoch 10 Batch 700 Loss 0.3828 Accuracy 0.9098
Epoch 10 Batch 750 Loss 0.3834 Accuracy 0.9096
Epoch 10 Batch 800 Loss 0.3843 Accuracy 0.9095
Epoch 10 Batch 850 Loss 0.3847 Accuracy 0.9094
Epoch 10 Batch 900 Loss 0.3854 Accuracy 0.9093
Epoch 10 Batch 950 Loss 0.3862 Accuracy 0.9092
Epoch 10 Batch 1000 Loss 0.3869 Accuracy 0.9091
Epoch 10 Batch 1050 Loss 0.3878 Accuracy 0.9090
Epoch 10 Batch 1100 Loss 0.3883 Accuracy 0.9090
Epoch 10 Batch 1150 Loss 0.3888 Accuracy 0.9088
Epoch 10 Batch 1200 Loss 0.3891 Accuracy 0.9088
Epoch 10 Batch 1250 Loss 0.3901 Accuracy 0.9086
Epoch 10 Batch 1300 Loss 0.3909 Accuracy 0.9085
Epoch 10 Batch 1350 Loss 0.3916 Accuracy 0.9084
Epoch 10 Batch 1400 Loss 0.3921 Accuracy 0.9083
Epoch 10 Batch 1450 Loss 0.3930 Accuracy 0.9081
Epoch 10 Batch 1500 Loss 0.3938 Accuracy 0.9080

wandb: WARNING Step must only increase in log calls.  Step 10 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3946407>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9079365>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-22
Epoch 10 Loss 0.3946 Accuracy 0.9079
Time taken for 1 epoch: 36.002511501312256 secs

epoch lasted: 36.00662922859192
Epoch 11 Batch 0 Loss 0.3115 Accuracy 0.9236
discarded batch 42
Epoch 11 Batch 50 Loss 0.3584 Accuracy 0.9146
Epoch 11 Batch 100 Loss 0.3637 Accuracy 0.9129
Epoch 11 Batch 150 Loss 0.3665 Accuracy 0.9130
Epoch 11 Batch 200 Loss 0.3689 Accuracy 0.9123
Epoch 11 Batch 250 Loss 0.3699 Accuracy 0.9122
Epoch 11 Batch 300 Loss 0.3700 Accuracy 0.9121
Epoch 11 Batch 350 Loss 0.3712 Accuracy 0.9119
Epoch 11 Batch 400 Loss 0.3734 Accuracy 0.9116
Epoch 11 Batch 450 Loss 0.3745 Accuracy 0.9113
Epoch 11 Batch 500 Loss 0.3753 Accuracy 0.9111
Epoch 11 Batch 550 Loss 0.3770 Accuracy 0.9108
Epoch 11 Batch 600 Loss 0.3779 Accuracy 0.9107
Epoch 11 Batch 650 Loss 0.3785 Accuracy 0.9106
Epoch 11 Batch 700 Loss 0.3793 Accuracy 0.9104
Epoch 11 Batch 750 Loss 0.3795 Accuracy 0.9105
Epoch 11 Batch 800 Loss 0.3804 Accuracy 0.9104
Epoch 11 Batch 850 Loss 0.3815 Accuracy 0.9102
Epoch 11 Batch 900 Loss 0.3819 Accuracy 0.9102
Epoch 11 Batch 950 Loss 0.3831 Accuracy 0.9100
Epoch 11 Batch 1000 Loss 0.3841 Accuracy 0.9098
Epoch 11 Batch 1050 Loss 0.3850 Accuracy 0.9097
Epoch 11 Batch 1100 Loss 0.3855 Accuracy 0.9096
Epoch 11 Batch 1150 Loss 0.3862 Accuracy 0.9094
Epoch 11 Batch 1200 Loss 0.3872 Accuracy 0.9092
Epoch 11 Batch 1250 Loss 0.3882 Accuracy 0.9091
Epoch 11 Batch 1300 Loss 0.3892 Accuracy 0.9090
Epoch 11 Batch 1350 Loss 0.3900 Accuracy 0.9089
Epoch 11 Batch 1400 Loss 0.3905 Accuracy 0.9087
Epoch 11 Batch 1450 Loss 0.3912 Accuracy 0.9086
Epoch 11 Batch 1500 Loss 0.3917 Accuracy 0.9085

wandb: WARNING Step must only increase in log calls.  Step 11 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.39231634>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9083966>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 26; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.85019696>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86445194>}.

Epoch 11 Loss 0.3923 Accuracy 0.9084
Time taken for 1 epoch: 35.77193021774292 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.8502 Accuracy 0.8645

epoch lasted: 35.93204402923584
Epoch 12 Batch 0 Loss 0.3259 Accuracy 0.9203
Epoch 12 Batch 50 Loss 0.3749 Accuracy 0.9111
Epoch 12 Batch 100 Loss 0.3687 Accuracy 0.9129
Epoch 12 Batch 150 Loss 0.3733 Accuracy 0.9113
Epoch 12 Batch 200 Loss 0.3718 Accuracy 0.9119
Epoch 12 Batch 250 Loss 0.3737 Accuracy 0.9112
Epoch 12 Batch 300 Loss 0.3746 Accuracy 0.9111
Epoch 12 Batch 350 Loss 0.3751 Accuracy 0.9107
Epoch 12 Batch 400 Loss 0.3755 Accuracy 0.9107
Epoch 12 Batch 450 Loss 0.3762 Accuracy 0.9107
Epoch 12 Batch 500 Loss 0.3772 Accuracy 0.9106
Epoch 12 Batch 550 Loss 0.3780 Accuracy 0.9105
Epoch 12 Batch 600 Loss 0.3782 Accuracy 0.9102
Epoch 12 Batch 650 Loss 0.3795 Accuracy 0.9101
Epoch 12 Batch 700 Loss 0.3808 Accuracy 0.9099
Epoch 12 Batch 750 Loss 0.3816 Accuracy 0.9097
Epoch 12 Batch 800 Loss 0.3826 Accuracy 0.9095
Epoch 12 Batch 850 Loss 0.3834 Accuracy 0.9093
Epoch 12 Batch 900 Loss 0.3838 Accuracy 0.9094
Epoch 12 Batch 950 Loss 0.3845 Accuracy 0.9093
Epoch 12 Batch 1000 Loss 0.3847 Accuracy 0.9093
Epoch 12 Batch 1050 Loss 0.3856 Accuracy 0.9092
Epoch 12 Batch 1100 Loss 0.3865 Accuracy 0.9090
Epoch 12 Batch 1150 Loss 0.3870 Accuracy 0.9090
Epoch 12 Batch 1200 Loss 0.3877 Accuracy 0.9089
Epoch 12 Batch 1250 Loss 0.3884 Accuracy 0.9088
Epoch 12 Batch 1300 Loss 0.3891 Accuracy 0.9086
discarded batch 1342
Epoch 12 Batch 1350 Loss 0.3898 Accuracy 0.9085
Epoch 12 Batch 1400 Loss 0.3902 Accuracy 0.9085
Epoch 12 Batch 1450 Loss 0.3911 Accuracy 0.9083
Epoch 12 Batch 1500 Loss 0.3920 Accuracy 0.9082

wandb: WARNING Step must only increase in log calls.  Step 12 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3925873>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9080963>}.

Epoch 12 Loss 0.3926 Accuracy 0.9081
Time taken for 1 epoch: 35.82365584373474 secs

epoch lasted: 35.82822060585022
Epoch 13 Batch 0 Loss 0.3837 Accuracy 0.8987
Epoch 13 Batch 50 Loss 0.3557 Accuracy 0.9143
Epoch 13 Batch 100 Loss 0.3615 Accuracy 0.9140
Epoch 13 Batch 150 Loss 0.3640 Accuracy 0.9134
Epoch 13 Batch 200 Loss 0.3670 Accuracy 0.9127
Epoch 13 Batch 250 Loss 0.3671 Accuracy 0.9124
Epoch 13 Batch 300 Loss 0.3674 Accuracy 0.9125
Epoch 13 Batch 350 Loss 0.3689 Accuracy 0.9124
Epoch 13 Batch 400 Loss 0.3700 Accuracy 0.9121
Epoch 13 Batch 450 Loss 0.3715 Accuracy 0.9119
Epoch 13 Batch 500 Loss 0.3726 Accuracy 0.9118
Epoch 13 Batch 550 Loss 0.3736 Accuracy 0.9116
Epoch 13 Batch 600 Loss 0.3748 Accuracy 0.9114
Epoch 13 Batch 650 Loss 0.3756 Accuracy 0.9110
Epoch 13 Batch 700 Loss 0.3768 Accuracy 0.9108
Epoch 13 Batch 750 Loss 0.3779 Accuracy 0.9107
Epoch 13 Batch 800 Loss 0.3789 Accuracy 0.9105
Epoch 13 Batch 850 Loss 0.3799 Accuracy 0.9102
Epoch 13 Batch 900 Loss 0.3805 Accuracy 0.9100
Epoch 13 Batch 950 Loss 0.3814 Accuracy 0.9099
Epoch 13 Batch 1000 Loss 0.3824 Accuracy 0.9098
discarded batch 1031
Epoch 13 Batch 1050 Loss 0.3832 Accuracy 0.9097
Epoch 13 Batch 1100 Loss 0.3842 Accuracy 0.9095
Epoch 13 Batch 1150 Loss 0.3847 Accuracy 0.9095
Epoch 13 Batch 1200 Loss 0.3853 Accuracy 0.9094
Epoch 13 Batch 1250 Loss 0.3859 Accuracy 0.9093
Epoch 13 Batch 1300 Loss 0.3868 Accuracy 0.9092
Epoch 13 Batch 1350 Loss 0.3878 Accuracy 0.9090
Epoch 13 Batch 1400 Loss 0.3885 Accuracy 0.9089
Epoch 13 Batch 1450 Loss 0.3891 Accuracy 0.9088
Epoch 13 Batch 1500 Loss 0.3898 Accuracy 0.9087

wandb: WARNING Step must only increase in log calls.  Step 13 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3905071>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9085532>}.

Epoch 13 Loss 0.3905 Accuracy 0.9086
Time taken for 1 epoch: 35.769232988357544 secs

epoch lasted: 35.773669719696045
Epoch 14 Batch 0 Loss 0.3877 Accuracy 0.9003
Epoch 14 Batch 50 Loss 0.3660 Accuracy 0.9124
Epoch 14 Batch 100 Loss 0.3667 Accuracy 0.9128
Epoch 14 Batch 150 Loss 0.3645 Accuracy 0.9133
Epoch 14 Batch 200 Loss 0.3664 Accuracy 0.9129
Epoch 14 Batch 250 Loss 0.3668 Accuracy 0.9127
Epoch 14 Batch 300 Loss 0.3688 Accuracy 0.9123
Epoch 14 Batch 350 Loss 0.3696 Accuracy 0.9122
Epoch 14 Batch 400 Loss 0.3704 Accuracy 0.9119
Epoch 14 Batch 450 Loss 0.3700 Accuracy 0.9119
Epoch 14 Batch 500 Loss 0.3719 Accuracy 0.9118
Epoch 14 Batch 550 Loss 0.3726 Accuracy 0.9116
Epoch 14 Batch 600 Loss 0.3739 Accuracy 0.9113
Epoch 14 Batch 650 Loss 0.3746 Accuracy 0.9112
Epoch 14 Batch 700 Loss 0.3760 Accuracy 0.9110
Epoch 14 Batch 750 Loss 0.3773 Accuracy 0.9108
Epoch 14 Batch 800 Loss 0.3787 Accuracy 0.9106
Epoch 14 Batch 850 Loss 0.3794 Accuracy 0.9105
Epoch 14 Batch 900 Loss 0.3805 Accuracy 0.9103
Epoch 14 Batch 950 Loss 0.3816 Accuracy 0.9102
Epoch 14 Batch 1000 Loss 0.3826 Accuracy 0.9100
Epoch 14 Batch 1050 Loss 0.3838 Accuracy 0.9098
Epoch 14 Batch 1100 Loss 0.3843 Accuracy 0.9097
Epoch 14 Batch 1150 Loss 0.3847 Accuracy 0.9097
Epoch 14 Batch 1200 Loss 0.3853 Accuracy 0.9095
Epoch 14 Batch 1250 Loss 0.3861 Accuracy 0.9093
Epoch 14 Batch 1300 Loss 0.3868 Accuracy 0.9092
Epoch 14 Batch 1350 Loss 0.3873 Accuracy 0.9091
Epoch 14 Batch 1400 Loss 0.3881 Accuracy 0.9090
Epoch 14 Batch 1450 Loss 0.3890 Accuracy 0.9088
discarded batch 1493
Epoch 14 Batch 1500 Loss 0.3893 Accuracy 0.9088

wandb: WARNING Step must only increase in log calls.  Step 14 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38977906>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9087011>}.

Epoch 14 Loss 0.3898 Accuracy 0.9087
Time taken for 1 epoch: 35.789724349975586 secs

epoch lasted: 35.79501175880432
Epoch 15 Batch 0 Loss 0.3197 Accuracy 0.9153
Epoch 15 Batch 50 Loss 0.3662 Accuracy 0.9137
Epoch 15 Batch 100 Loss 0.3625 Accuracy 0.9131
Epoch 15 Batch 150 Loss 0.3609 Accuracy 0.9133
Epoch 15 Batch 200 Loss 0.3634 Accuracy 0.9129
Epoch 15 Batch 250 Loss 0.3635 Accuracy 0.9128
Epoch 15 Batch 300 Loss 0.3662 Accuracy 0.9122
Epoch 15 Batch 350 Loss 0.3662 Accuracy 0.9123
Epoch 15 Batch 400 Loss 0.3672 Accuracy 0.9121
Epoch 15 Batch 450 Loss 0.3679 Accuracy 0.9120
Epoch 15 Batch 500 Loss 0.3691 Accuracy 0.9120
Epoch 15 Batch 550 Loss 0.3708 Accuracy 0.9116
Epoch 15 Batch 600 Loss 0.3721 Accuracy 0.9115
Epoch 15 Batch 650 Loss 0.3734 Accuracy 0.9113
Epoch 15 Batch 700 Loss 0.3741 Accuracy 0.9112
Epoch 15 Batch 750 Loss 0.3751 Accuracy 0.9110
Epoch 15 Batch 800 Loss 0.3756 Accuracy 0.9110
Epoch 15 Batch 850 Loss 0.3767 Accuracy 0.9108
Epoch 15 Batch 900 Loss 0.3776 Accuracy 0.9106
Epoch 15 Batch 950 Loss 0.3786 Accuracy 0.9105
Epoch 15 Batch 1000 Loss 0.3798 Accuracy 0.9102
Epoch 15 Batch 1050 Loss 0.3809 Accuracy 0.9101
Epoch 15 Batch 1100 Loss 0.3820 Accuracy 0.9099
Epoch 15 Batch 1150 Loss 0.3829 Accuracy 0.9098
discarded batch 1152
Epoch 15 Batch 1200 Loss 0.3837 Accuracy 0.9096
Epoch 15 Batch 1250 Loss 0.3844 Accuracy 0.9095
Epoch 15 Batch 1300 Loss 0.3853 Accuracy 0.9094
Epoch 15 Batch 1350 Loss 0.3859 Accuracy 0.9094
Epoch 15 Batch 1400 Loss 0.3867 Accuracy 0.9093
Epoch 15 Batch 1450 Loss 0.3875 Accuracy 0.9092
Epoch 15 Batch 1500 Loss 0.3877 Accuracy 0.9092

wandb: WARNING Step must only increase in log calls.  Step 15 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3882657>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9090904>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-23
Epoch 15 Loss 0.3883 Accuracy 0.9091
Time taken for 1 epoch: 35.98012900352478 secs

epoch lasted: 35.98407864570618
Epoch 16 Batch 0 Loss 0.4472 Accuracy 0.8937
Epoch 16 Batch 50 Loss 0.3541 Accuracy 0.9137
Epoch 16 Batch 100 Loss 0.3558 Accuracy 0.9143
Epoch 16 Batch 150 Loss 0.3585 Accuracy 0.9142
Epoch 16 Batch 200 Loss 0.3605 Accuracy 0.9137
Epoch 16 Batch 250 Loss 0.3600 Accuracy 0.9138
Epoch 16 Batch 300 Loss 0.3636 Accuracy 0.9132
Epoch 16 Batch 350 Loss 0.3644 Accuracy 0.9129
Epoch 16 Batch 400 Loss 0.3651 Accuracy 0.9127
Epoch 16 Batch 450 Loss 0.3673 Accuracy 0.9123
Epoch 16 Batch 500 Loss 0.3677 Accuracy 0.9122
Epoch 16 Batch 550 Loss 0.3697 Accuracy 0.9119
Epoch 16 Batch 600 Loss 0.3705 Accuracy 0.9118
Epoch 16 Batch 650 Loss 0.3712 Accuracy 0.9117
Epoch 16 Batch 700 Loss 0.3727 Accuracy 0.9115
Epoch 16 Batch 750 Loss 0.3734 Accuracy 0.9114
Epoch 16 Batch 800 Loss 0.3743 Accuracy 0.9112
Epoch 16 Batch 850 Loss 0.3755 Accuracy 0.9110
Epoch 16 Batch 900 Loss 0.3764 Accuracy 0.9108
discarded batch 941
Epoch 16 Batch 950 Loss 0.3771 Accuracy 0.9107
Epoch 16 Batch 1000 Loss 0.3781 Accuracy 0.9105
Epoch 16 Batch 1050 Loss 0.3790 Accuracy 0.9103
Epoch 16 Batch 1100 Loss 0.3796 Accuracy 0.9102
Epoch 16 Batch 1150 Loss 0.3806 Accuracy 0.9101
Epoch 16 Batch 1200 Loss 0.3811 Accuracy 0.9100
Epoch 16 Batch 1250 Loss 0.3815 Accuracy 0.9098
Epoch 16 Batch 1300 Loss 0.3825 Accuracy 0.9096
Epoch 16 Batch 1350 Loss 0.3837 Accuracy 0.9094
Epoch 16 Batch 1400 Loss 0.3844 Accuracy 0.9093
Epoch 16 Batch 1450 Loss 0.3852 Accuracy 0.9092
Epoch 16 Batch 1500 Loss 0.3863 Accuracy 0.9090

wandb: WARNING Step must only increase in log calls.  Step 16 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38698536>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9089124>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 26; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8570917>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8637873>}.

Epoch 16 Loss 0.3870 Accuracy 0.9089
Time taken for 1 epoch: 35.720357179641724 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.8571 Accuracy 0.8638

epoch lasted: 35.87764644622803
Epoch 17 Batch 0 Loss 0.3734 Accuracy 0.9153
Epoch 17 Batch 50 Loss 0.3519 Accuracy 0.9137
Epoch 17 Batch 100 Loss 0.3549 Accuracy 0.9134
Epoch 17 Batch 150 Loss 0.3548 Accuracy 0.9137
Epoch 17 Batch 200 Loss 0.3567 Accuracy 0.9136
Epoch 17 Batch 250 Loss 0.3570 Accuracy 0.9135
Epoch 17 Batch 300 Loss 0.3594 Accuracy 0.9133
Epoch 17 Batch 350 Loss 0.3616 Accuracy 0.9129
Epoch 17 Batch 400 Loss 0.3628 Accuracy 0.9130
Epoch 17 Batch 450 Loss 0.3635 Accuracy 0.9127
Epoch 17 Batch 500 Loss 0.3649 Accuracy 0.9126
Epoch 17 Batch 550 Loss 0.3665 Accuracy 0.9124
discarded batch 598
Epoch 17 Batch 600 Loss 0.3682 Accuracy 0.9121
Epoch 17 Batch 650 Loss 0.3691 Accuracy 0.9119
Epoch 17 Batch 700 Loss 0.3707 Accuracy 0.9117
Epoch 17 Batch 750 Loss 0.3719 Accuracy 0.9115
Epoch 17 Batch 800 Loss 0.3730 Accuracy 0.9113
Epoch 17 Batch 850 Loss 0.3743 Accuracy 0.9110
Epoch 17 Batch 900 Loss 0.3747 Accuracy 0.9110
Epoch 17 Batch 950 Loss 0.3753 Accuracy 0.9109
Epoch 17 Batch 1000 Loss 0.3765 Accuracy 0.9108
Epoch 17 Batch 1050 Loss 0.3777 Accuracy 0.9106
Epoch 17 Batch 1100 Loss 0.3784 Accuracy 0.9104
Epoch 17 Batch 1150 Loss 0.3794 Accuracy 0.9103
Epoch 17 Batch 1200 Loss 0.3805 Accuracy 0.9101
Epoch 17 Batch 1250 Loss 0.3813 Accuracy 0.9100
Epoch 17 Batch 1300 Loss 0.3822 Accuracy 0.9099
Epoch 17 Batch 1350 Loss 0.3827 Accuracy 0.9098
Epoch 17 Batch 1400 Loss 0.3834 Accuracy 0.9097
Epoch 17 Batch 1450 Loss 0.3839 Accuracy 0.9096
Epoch 17 Batch 1500 Loss 0.3848 Accuracy 0.9095

wandb: WARNING Step must only increase in log calls.  Step 17 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38529402>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.90936494>}.

Epoch 17 Loss 0.3853 Accuracy 0.9094
Time taken for 1 epoch: 35.904048919677734 secs

epoch lasted: 35.90913939476013
Epoch 18 Batch 0 Loss 0.3521 Accuracy 0.9136
Epoch 18 Batch 50 Loss 0.3598 Accuracy 0.9138
Epoch 18 Batch 100 Loss 0.3565 Accuracy 0.9150
Epoch 18 Batch 150 Loss 0.3592 Accuracy 0.9141
Epoch 18 Batch 200 Loss 0.3606 Accuracy 0.9142
Epoch 18 Batch 250 Loss 0.3612 Accuracy 0.9139
Epoch 18 Batch 300 Loss 0.3613 Accuracy 0.9138
Epoch 18 Batch 350 Loss 0.3617 Accuracy 0.9135
Epoch 18 Batch 400 Loss 0.3640 Accuracy 0.9133
Epoch 18 Batch 450 Loss 0.3653 Accuracy 0.9129
Epoch 18 Batch 500 Loss 0.3665 Accuracy 0.9125
Epoch 18 Batch 550 Loss 0.3677 Accuracy 0.9122
Epoch 18 Batch 600 Loss 0.3682 Accuracy 0.9123
Epoch 18 Batch 650 Loss 0.3688 Accuracy 0.9122
Epoch 18 Batch 700 Loss 0.3699 Accuracy 0.9120
Epoch 18 Batch 750 Loss 0.3710 Accuracy 0.9119
Epoch 18 Batch 800 Loss 0.3718 Accuracy 0.9117
Epoch 18 Batch 850 Loss 0.3725 Accuracy 0.9116
Epoch 18 Batch 900 Loss 0.3737 Accuracy 0.9114
discarded batch 914
Epoch 18 Batch 950 Loss 0.3748 Accuracy 0.9112
Epoch 18 Batch 1000 Loss 0.3757 Accuracy 0.9111
Epoch 18 Batch 1050 Loss 0.3765 Accuracy 0.9109
Epoch 18 Batch 1100 Loss 0.3774 Accuracy 0.9107
Epoch 18 Batch 1150 Loss 0.3783 Accuracy 0.9106
Epoch 18 Batch 1200 Loss 0.3788 Accuracy 0.9105
Epoch 18 Batch 1250 Loss 0.3794 Accuracy 0.9104
Epoch 18 Batch 1300 Loss 0.3803 Accuracy 0.9103
Epoch 18 Batch 1350 Loss 0.3813 Accuracy 0.9101
Epoch 18 Batch 1400 Loss 0.3823 Accuracy 0.9100
Epoch 18 Batch 1450 Loss 0.3830 Accuracy 0.9098
Epoch 18 Batch 1500 Loss 0.3838 Accuracy 0.9097

wandb: WARNING Step must only increase in log calls.  Step 18 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38445926>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.909514>}.

Epoch 18 Loss 0.3845 Accuracy 0.9095
Time taken for 1 epoch: 35.8227219581604 secs

epoch lasted: 35.82678270339966
Epoch 19 Batch 0 Loss 0.3267 Accuracy 0.9169
discarded batch 45
Epoch 19 Batch 50 Loss 0.3572 Accuracy 0.9146
Epoch 19 Batch 100 Loss 0.3576 Accuracy 0.9139
Epoch 19 Batch 150 Loss 0.3599 Accuracy 0.9133
Epoch 19 Batch 200 Loss 0.3620 Accuracy 0.9130
Epoch 19 Batch 250 Loss 0.3628 Accuracy 0.9127
Epoch 19 Batch 300 Loss 0.3636 Accuracy 0.9126
Epoch 19 Batch 350 Loss 0.3645 Accuracy 0.9126
Epoch 19 Batch 400 Loss 0.3659 Accuracy 0.9125
Epoch 19 Batch 450 Loss 0.3672 Accuracy 0.9123
Epoch 19 Batch 500 Loss 0.3686 Accuracy 0.9121
Epoch 19 Batch 550 Loss 0.3691 Accuracy 0.9120
Epoch 19 Batch 600 Loss 0.3700 Accuracy 0.9118
Epoch 19 Batch 650 Loss 0.3707 Accuracy 0.9117
Epoch 19 Batch 700 Loss 0.3717 Accuracy 0.9115
Epoch 19 Batch 750 Loss 0.3724 Accuracy 0.9113
Epoch 19 Batch 800 Loss 0.3733 Accuracy 0.9111
Epoch 19 Batch 850 Loss 0.3744 Accuracy 0.9109
Epoch 19 Batch 900 Loss 0.3749 Accuracy 0.9109
Epoch 19 Batch 950 Loss 0.3759 Accuracy 0.9107
Epoch 19 Batch 1000 Loss 0.3768 Accuracy 0.9106
Epoch 19 Batch 1050 Loss 0.3775 Accuracy 0.9105
Epoch 19 Batch 1100 Loss 0.3784 Accuracy 0.9103
Epoch 19 Batch 1150 Loss 0.3787 Accuracy 0.9103
Epoch 19 Batch 1200 Loss 0.3793 Accuracy 0.9102
Epoch 19 Batch 1250 Loss 0.3803 Accuracy 0.9101
Epoch 19 Batch 1300 Loss 0.3809 Accuracy 0.9100
Epoch 19 Batch 1350 Loss 0.3818 Accuracy 0.9099
Epoch 19 Batch 1400 Loss 0.3826 Accuracy 0.9098
Epoch 19 Batch 1450 Loss 0.3835 Accuracy 0.9097
Epoch 19 Batch 1500 Loss 0.3840 Accuracy 0.9096

wandb: WARNING Step must only increase in log calls.  Step 19 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38463005>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9095333>}.

Epoch 19 Loss 0.3846 Accuracy 0.9095
Time taken for 1 epoch: 35.73302459716797 secs

epoch lasted: 35.7373583316803
Epoch 20 Batch 0 Loss 0.3169 Accuracy 0.9252
Epoch 20 Batch 50 Loss 0.3472 Accuracy 0.9166
Epoch 20 Batch 100 Loss 0.3518 Accuracy 0.9150
Epoch 20 Batch 150 Loss 0.3554 Accuracy 0.9147
Epoch 20 Batch 200 Loss 0.3551 Accuracy 0.9147
Epoch 20 Batch 250 Loss 0.3561 Accuracy 0.9144
Epoch 20 Batch 300 Loss 0.3586 Accuracy 0.9142
Epoch 20 Batch 350 Loss 0.3598 Accuracy 0.9137
Epoch 20 Batch 400 Loss 0.3609 Accuracy 0.9134
Epoch 20 Batch 450 Loss 0.3623 Accuracy 0.9131
Epoch 20 Batch 500 Loss 0.3633 Accuracy 0.9129
Epoch 20 Batch 550 Loss 0.3635 Accuracy 0.9128
Epoch 20 Batch 600 Loss 0.3648 Accuracy 0.9126
Epoch 20 Batch 650 Loss 0.3660 Accuracy 0.9123
discarded batch 672
Epoch 20 Batch 700 Loss 0.3674 Accuracy 0.9121
Epoch 20 Batch 750 Loss 0.3681 Accuracy 0.9119
Epoch 20 Batch 800 Loss 0.3696 Accuracy 0.9117
Epoch 20 Batch 850 Loss 0.3704 Accuracy 0.9115
Epoch 20 Batch 900 Loss 0.3712 Accuracy 0.9113
Epoch 20 Batch 950 Loss 0.3717 Accuracy 0.9112
Epoch 20 Batch 1000 Loss 0.3726 Accuracy 0.9110
Epoch 20 Batch 1050 Loss 0.3736 Accuracy 0.9108
Epoch 20 Batch 1100 Loss 0.3744 Accuracy 0.9107
Epoch 20 Batch 1150 Loss 0.3758 Accuracy 0.9105
Epoch 20 Batch 1200 Loss 0.3765 Accuracy 0.9105
Epoch 20 Batch 1250 Loss 0.3777 Accuracy 0.9103
Epoch 20 Batch 1300 Loss 0.3784 Accuracy 0.9102
Epoch 20 Batch 1350 Loss 0.3794 Accuracy 0.9100
Epoch 20 Batch 1400 Loss 0.3805 Accuracy 0.9099
Epoch 20 Batch 1450 Loss 0.3812 Accuracy 0.9098
Epoch 20 Batch 1500 Loss 0.3820 Accuracy 0.9097

wandb: WARNING Step must only increase in log calls.  Step 20 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38261065>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.909603>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-24
Epoch 20 Loss 0.3826 Accuracy 0.9096
Time taken for 1 epoch: 35.92417025566101 secs

epoch lasted: 35.92794632911682
Epoch 21 Batch 0 Loss 0.2954 Accuracy 0.9186
Epoch 21 Batch 50 Loss 0.3438 Accuracy 0.9152
Epoch 21 Batch 100 Loss 0.3475 Accuracy 0.9154
Epoch 21 Batch 150 Loss 0.3521 Accuracy 0.9151
Epoch 21 Batch 200 Loss 0.3546 Accuracy 0.9143
Epoch 21 Batch 250 Loss 0.3559 Accuracy 0.9140
Epoch 21 Batch 300 Loss 0.3569 Accuracy 0.9139
Epoch 21 Batch 350 Loss 0.3574 Accuracy 0.9137
Epoch 21 Batch 400 Loss 0.3586 Accuracy 0.9135
Epoch 21 Batch 450 Loss 0.3592 Accuracy 0.9132
Epoch 21 Batch 500 Loss 0.3604 Accuracy 0.9131
Epoch 21 Batch 550 Loss 0.3620 Accuracy 0.9129
Epoch 21 Batch 600 Loss 0.3632 Accuracy 0.9128
Epoch 21 Batch 650 Loss 0.3648 Accuracy 0.9125
Epoch 21 Batch 700 Loss 0.3659 Accuracy 0.9123
Epoch 21 Batch 750 Loss 0.3676 Accuracy 0.9120
Epoch 21 Batch 800 Loss 0.3687 Accuracy 0.9119
Epoch 21 Batch 850 Loss 0.3696 Accuracy 0.9118
Epoch 21 Batch 900 Loss 0.3704 Accuracy 0.9117
Epoch 21 Batch 950 Loss 0.3713 Accuracy 0.9115
Epoch 21 Batch 1000 Loss 0.3721 Accuracy 0.9114
Epoch 21 Batch 1050 Loss 0.3733 Accuracy 0.9111
Epoch 21 Batch 1100 Loss 0.3742 Accuracy 0.9110
Epoch 21 Batch 1150 Loss 0.3748 Accuracy 0.9109
Epoch 21 Batch 1200 Loss 0.3756 Accuracy 0.9108
Epoch 21 Batch 1250 Loss 0.3766 Accuracy 0.9107
Epoch 21 Batch 1300 Loss 0.3775 Accuracy 0.9106
Epoch 21 Batch 1350 Loss 0.3780 Accuracy 0.9105
Epoch 21 Batch 1400 Loss 0.3788 Accuracy 0.9104
Epoch 21 Batch 1450 Loss 0.3795 Accuracy 0.9103
discarded batch 1473
Epoch 21 Batch 1500 Loss 0.3801 Accuracy 0.9102

wandb: WARNING Step must only increase in log calls.  Step 21 < 26; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38058278>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91007704>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 26; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8573773>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86367667>}.

Epoch 21 Loss 0.3806 Accuracy 0.9101
Time taken for 1 epoch: 35.78825092315674 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.8574 Accuracy 0.8637

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 po|scia |che |l’ ar|co |più |che ’l |tuo |mor|to |gi|ro|
pe|rò |chi |sie|me |suo |per |voi |si |pa|gna|
ma |per|ché |più |pe|ra|to |più |di|si|ro|
                                                                                                                                                                   
 co|me ’l |dì |an|da|va |più |che ’l |mon|da|gna|
e |io |sen|ti’ |mo|strar |ciò |li |me|spi|ri|
 che |san|za |la|gri|man|to |tut|ti |di|vi|da|
e |io |te|ne|det|to |son |com|pa|ti|ca|
per |se|gui|te |fu |la |gen|te |di|vi|da|
                                                                                                                                                                   
 che |pian|ger |pro|po|ten|ta|men|te in |gi|ca|
per |ch’ io |ti |ce|si |sì |com’ |io |in|ten|da|
per |ch’ io |son |na|tu|ra |già |e|ran |li|ca|
ma |io |non |fui |e |giun|se a |quel|le |mie |quei |dis|se|
per |ch’ io |non |co|me a |tai |spi|ri|ti |por|te|
e |io |fui |con |le |gen|te |di|sco|se|
                                                                                                                                                                    
 e |io |la|gri|dan|do |la|scia|gu|sto|
 che |non |bi|li |fu |ché |da |lui |non |di|sce|
la |mia |sen|ti|sta |gen|te |che |non |tra|scor|se|
per |che ’l |sol |de|stra |ma|e|stro |mio |ce|so|
                                                                                                                                                                   
 e |qual |e|stro |mio |cor|ru|bi|le |por|se|
e |io |veg|gio |ben |sì |co|me |s’ in|ten|to|
e |qual |ten|der |può |di|man|da|men|se|se|
che |pria |che |per |lo |me|de|va |con |la |ve|nu|te|
io |at|ten|za |let|tor |che ’n |que|sta |fos|se|
io |fui |ten|za |de |la |gen|te |fo|re|te|
                                                                                                                                                                   
 per |ch’ io |ti |già |mai |per |li |pec|ca|to|sto|
e |io |fui |ché |tu |van|no |si |di|sde|gno|
ben |m’ ac|cor|so |non |vo’ |che |tu |se’ |que|sto|
 per |le |me|na|va |con |la |mia |che |so|let|to|
non |per|ché |pe|ran|za |fu |sì |con|for|te|
non |vo’ |che |più |a |la |mia |se|gna|giun|to|
                                                                                                                                                                   
 a |la |don|na |ch’ io |fui |e |co|sa |por|ti|
sì |co|me |die|tro a |lei |fa|mi|glia |por|to|
e |io |fu |co|me |del |mon|do |di|ste|so|
e |ma |per|ché |pe|na |che |tut|ti |di|scen|de|re|
e |io |le|var|ca |mio |per |ve|ra |se|gno|
e |io |ma|e|stro |mio |ché |non |ha |con|de|
                                                                                                                                                                   
 ma |or |con|vien |che |son |di|vi|na |die|ce|
per |ch’ io |ti |quin|ci e |quin|ci |son |men|te|tro|
e |se |tu |la|gri|do |per |l’ al|tra |cu|ce|
 e |io |ma|e|stro |mio |se|gui|tan|to |man|do|
con |que|sta |gen|te e |que|sta |mo|stra |ma|no|
con |lo|ce |fu |la|gri|mo|ve|te |man|do|
                                                                                                                                                                   
 ma |que|sta |cal|ca|ta |la |sua |ra|di|vo|
qual |è |la |sua |bon|tà |la|gri|da |pri|ma|
ben |ch’ a |la |sua |gui|da |tut|ta |mo|le|mo|
che |die|tro |di|man|da |tut|to ’l |mon|do |be|a|ce|
co|lui |che |per |lo |mio |fa |che |di|pin|za|
per |non |si |la|gri|man|da |mia |di|mo|ce|
                                                                                                                                                                   
 per |cui |vir|tù |né |val|le |pec|ca|stel|la|
e |poi |a |lui |par|te |ro|ma |mia |sce|ce|
e |quei |che |son |bea|tri|ce |tut|ta |que|ce|
in|nan|zi |che |son |ca|to in |me|stier |le |brac|cia|
di|
con|ce|men|te |fu |a |gui|da |la |pro|
con|ten|za |fu |e |io |son |giu|di|zio|
                                                                                                                                                                    
 ma |per|ché |pur |con |vo|ce |fu |rat|to|sta|
si |con|ce|mi |dis|se |que|ste |pa|ro|la|
e |io |veg|gio |ben |che |son |più |ra|gio|sta|
in|ten|de|bi|can|tan|do |fui |son |più |pro|ce|le|
co|me |gen|te |che |son |con |la |sua |por|ta|
e |io |fui |di|fe|ce a |la |sua |fe|ce|le|
                                                                                                                                                                   
 co|sì |ri|spuo|s’ io |ma|ra|vi|gliar |là |on|ta|
in|di |si |per |lo |tuo |par|la|ce|le|
in|con|vien |che |per |lor |me|nan|zi |si |sciol|ti|
e |io |fui |sto|rï|en|za |mia |che |si |di|ste|so|
ma |per |ve|gna|va |per |ma|dre |m’ ac|cor|so|
si |fe|ce |con |tut|to il |pet|to |m’ ac|ce|so|
                                                                                                                                                                   
 ma |io |a |l’ u|no e |l’ al|tro |fu |pre|gno|so|
pe|rò |mi |fe|ce |con |la |sua |ve|ni|ta|
e |s’ io |non |pur |per |ma|ne |la |sua |fe|sta|
ma |poi |che |la |mia |don|na e |con |in|ten|za |ve|gna|
co|me a |cui |gi|glia |con |più |si |le|va|
co|me |si |di|ste|sa |di |re|ti|ca |ve|ste|
                                                                                                                                                                   
 co|me |li|be|ne|det|to |si |le|va|ma|
né |per |ch’ io |vi|di |lu|lar |ma|ni|fe|ste|
e |io |veg|gen|do|ve|nir |sì |fat|go|ma|
 per |la |mia |sco|glio |con |tut|to ’l |ve|der |pro|fe|
non |pe|rò |non |pur |che |per|ché |più |a|ce|
non |vi |la|scia|ta |mia |me|de|stro |mon|do|
                                                                                                                                                                   
 né |mos|si |può |per |lo |du|ca |mio|
 e |io |a |ce|sco|per|ché |la |bel|la |ci|da|
por|ta |da |l’ ac|qua |e |io |ma|ra|ce|ra|
a |gui|sa |da |sé |stes|so |fu |ma|li|da|
                                                                                                                                                                   
 a |la |don|na |mia |che |sot|to |si |le|gra|
e |co|min|ciai |mo|ria |par|ve |si |le|zia|
ch’ i’ |cre|do |ver|so |che ’l |ciel |per |li |la|scia|
e |ma |per|ché |l’ u|ma|gi|ran |so|vra |sé |me|
con |que|sta |per|ché |non |cre|a|tu|na |gua|
con|vien |che |vo|ce |gui|da |sé |di|ver|mi|
                                                                                                                                                                    
 non |ve|ni|va |con |tan|to |sua |bon|ta|te|
sì |co|me |fu |e |poi |dis|se e |com|mi|
per |ch’ io |cre|den|do |ch’ a |nul|la |mia |ri|ta|te|

epoch lasted: 512.2986989021301
(1900, 128)
Epoch 1 Batch 0 Loss 0.3469 Accuracy 0.9236
Epoch 1 Batch 50 Loss 0.3476 Accuracy 0.9157
Epoch 1 Batch 100 Loss 0.3464 Accuracy 0.9160
Epoch 1 Batch 150 Loss 0.3489 Accuracy 0.9154
Epoch 1 Batch 200 Loss 0.3534 Accuracy 0.9146
Epoch 1 Batch 250 Loss 0.3542 Accuracy 0.9151
Epoch 1 Batch 300 Loss 0.3570 Accuracy 0.9147
Epoch 1 Batch 350 Loss 0.3569 Accuracy 0.9147
Epoch 1 Batch 400 Loss 0.3578 Accuracy 0.9146
discarded batch 413
Epoch 1 Batch 450 Loss 0.3597 Accuracy 0.9141
Epoch 1 Batch 500 Loss 0.3613 Accuracy 0.9139
Epoch 1 Batch 550 Loss 0.3628 Accuracy 0.9135
Epoch 1 Batch 600 Loss 0.3637 Accuracy 0.9132
Epoch 1 Batch 650 Loss 0.3652 Accuracy 0.9129
Epoch 1 Batch 700 Loss 0.3662 Accuracy 0.9127
Epoch 1 Batch 750 Loss 0.3673 Accuracy 0.9125
Epoch 1 Batch 800 Loss 0.3680 Accuracy 0.9124
Epoch 1 Batch 850 Loss 0.3692 Accuracy 0.9122
Epoch 1 Batch 900 Loss 0.3698 Accuracy 0.9121
Epoch 1 Batch 950 Loss 0.3709 Accuracy 0.9119
Epoch 1 Batch 1000 Loss 0.3718 Accuracy 0.9118
Epoch 1 Batch 1050 Loss 0.3727 Accuracy 0.9116
Epoch 1 Batch 1100 Loss 0.3736 Accuracy 0.9114
Epoch 1 Batch 1150 Loss 0.3744 Accuracy 0.9113
Epoch 1 Batch 1200 Loss 0.3751 Accuracy 0.9112
Epoch 1 Batch 1250 Loss 0.3758 Accuracy 0.9111
Epoch 1 Batch 1300 Loss 0.3765 Accuracy 0.9110
Epoch 1 Batch 1350 Loss 0.3772 Accuracy 0.9108
Epoch 1 Batch 1400 Loss 0.3778 Accuracy 0.9107
Epoch 1 Batch 1450 Loss 0.3787 Accuracy 0.9105
Epoch 1 Batch 1500 Loss 0.3793 Accuracy 0.9104

wandb: WARNING Step must only increase in log calls.  Step 1 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38008156>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9102711>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 27; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8547109>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8650055>}.

Epoch 1 Loss 0.3801 Accuracy 0.9103
Time taken for 1 epoch: 36.053555488586426 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.8547 Accuracy 0.8650

epoch lasted: 36.2103476524353
Epoch 2 Batch 0 Loss 0.3743 Accuracy 0.9037
Epoch 2 Batch 50 Loss 0.3438 Accuracy 0.9181
Epoch 2 Batch 100 Loss 0.3535 Accuracy 0.9163
Epoch 2 Batch 150 Loss 0.3521 Accuracy 0.9156
Epoch 2 Batch 200 Loss 0.3522 Accuracy 0.9153
Epoch 2 Batch 250 Loss 0.3528 Accuracy 0.9152
Epoch 2 Batch 300 Loss 0.3546 Accuracy 0.9150
Epoch 2 Batch 350 Loss 0.3553 Accuracy 0.9148
discarded batch 365
Epoch 2 Batch 400 Loss 0.3566 Accuracy 0.9148
Epoch 2 Batch 450 Loss 0.3587 Accuracy 0.9144
Epoch 2 Batch 500 Loss 0.3604 Accuracy 0.9140
Epoch 2 Batch 550 Loss 0.3616 Accuracy 0.9137
Epoch 2 Batch 600 Loss 0.3631 Accuracy 0.9134
Epoch 2 Batch 650 Loss 0.3637 Accuracy 0.9133
Epoch 2 Batch 700 Loss 0.3642 Accuracy 0.9132
Epoch 2 Batch 750 Loss 0.3651 Accuracy 0.9131
Epoch 2 Batch 800 Loss 0.3660 Accuracy 0.9130
Epoch 2 Batch 850 Loss 0.3673 Accuracy 0.9127
Epoch 2 Batch 900 Loss 0.3685 Accuracy 0.9125
Epoch 2 Batch 950 Loss 0.3690 Accuracy 0.9124
Epoch 2 Batch 1000 Loss 0.3700 Accuracy 0.9122
Epoch 2 Batch 1050 Loss 0.3712 Accuracy 0.9120
Epoch 2 Batch 1100 Loss 0.3716 Accuracy 0.9119
Epoch 2 Batch 1150 Loss 0.3724 Accuracy 0.9118
Epoch 2 Batch 1200 Loss 0.3730 Accuracy 0.9116
Epoch 2 Batch 1250 Loss 0.3741 Accuracy 0.9114
Epoch 2 Batch 1300 Loss 0.3747 Accuracy 0.9113
Epoch 2 Batch 1350 Loss 0.3756 Accuracy 0.9111
Epoch 2 Batch 1400 Loss 0.3761 Accuracy 0.9110
Epoch 2 Batch 1450 Loss 0.3769 Accuracy 0.9109
Epoch 2 Batch 1500 Loss 0.3777 Accuracy 0.9107

wandb: WARNING Step must only increase in log calls.  Step 2 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.37838227>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9105403>}.

Epoch 2 Loss 0.3784 Accuracy 0.9105
Time taken for 1 epoch: 35.98575711250305 secs

epoch lasted: 35.99035573005676
Epoch 3 Batch 0 Loss 0.3434 Accuracy 0.9053
Epoch 3 Batch 50 Loss 0.3520 Accuracy 0.9143
discarded batch 98
Epoch 3 Batch 100 Loss 0.3511 Accuracy 0.9147
Epoch 3 Batch 150 Loss 0.3521 Accuracy 0.9145
Epoch 3 Batch 200 Loss 0.3513 Accuracy 0.9149
Epoch 3 Batch 250 Loss 0.3529 Accuracy 0.9145
Epoch 3 Batch 300 Loss 0.3542 Accuracy 0.9142
Epoch 3 Batch 350 Loss 0.3556 Accuracy 0.9139
Epoch 3 Batch 400 Loss 0.3569 Accuracy 0.9137
Epoch 3 Batch 450 Loss 0.3575 Accuracy 0.9137
Epoch 3 Batch 500 Loss 0.3581 Accuracy 0.9137
Epoch 3 Batch 550 Loss 0.3596 Accuracy 0.9134
Epoch 3 Batch 600 Loss 0.3607 Accuracy 0.9132
Epoch 3 Batch 650 Loss 0.3621 Accuracy 0.9130
Epoch 3 Batch 700 Loss 0.3634 Accuracy 0.9129
Epoch 3 Batch 750 Loss 0.3643 Accuracy 0.9127
Epoch 3 Batch 800 Loss 0.3655 Accuracy 0.9126
Epoch 3 Batch 850 Loss 0.3664 Accuracy 0.9124
Epoch 3 Batch 900 Loss 0.3674 Accuracy 0.9122
Epoch 3 Batch 950 Loss 0.3682 Accuracy 0.9120
Epoch 3 Batch 1000 Loss 0.3691 Accuracy 0.9119
Epoch 3 Batch 1050 Loss 0.3701 Accuracy 0.9118
Epoch 3 Batch 1100 Loss 0.3711 Accuracy 0.9116
Epoch 3 Batch 1150 Loss 0.3718 Accuracy 0.9115
Epoch 3 Batch 1200 Loss 0.3724 Accuracy 0.9114
Epoch 3 Batch 1250 Loss 0.3733 Accuracy 0.9112
Epoch 3 Batch 1300 Loss 0.3738 Accuracy 0.9112
Epoch 3 Batch 1350 Loss 0.3746 Accuracy 0.9110
Epoch 3 Batch 1400 Loss 0.3753 Accuracy 0.9109
Epoch 3 Batch 1450 Loss 0.3764 Accuracy 0.9107
Epoch 3 Batch 1500 Loss 0.3773 Accuracy 0.9105

wandb: WARNING Step must only increase in log calls.  Step 3 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3779561>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9104352>}.

Epoch 3 Loss 0.3780 Accuracy 0.9104
Time taken for 1 epoch: 35.64720177650452 secs

epoch lasted: 35.659828186035156
Epoch 4 Batch 0 Loss 0.3305 Accuracy 0.9252
Epoch 4 Batch 50 Loss 0.3519 Accuracy 0.9154
Epoch 4 Batch 100 Loss 0.3493 Accuracy 0.9161
Epoch 4 Batch 150 Loss 0.3489 Accuracy 0.9157
Epoch 4 Batch 200 Loss 0.3509 Accuracy 0.9153
Epoch 4 Batch 250 Loss 0.3526 Accuracy 0.9151
Epoch 4 Batch 300 Loss 0.3528 Accuracy 0.9151
Epoch 4 Batch 350 Loss 0.3548 Accuracy 0.9145
Epoch 4 Batch 400 Loss 0.3554 Accuracy 0.9144
Epoch 4 Batch 450 Loss 0.3566 Accuracy 0.9142
Epoch 4 Batch 500 Loss 0.3585 Accuracy 0.9138
Epoch 4 Batch 550 Loss 0.3599 Accuracy 0.9135
Epoch 4 Batch 600 Loss 0.3611 Accuracy 0.9132
Epoch 4 Batch 650 Loss 0.3623 Accuracy 0.9130
Epoch 4 Batch 700 Loss 0.3634 Accuracy 0.9128
Epoch 4 Batch 750 Loss 0.3651 Accuracy 0.9125
Epoch 4 Batch 800 Loss 0.3661 Accuracy 0.9124
Epoch 4 Batch 850 Loss 0.3669 Accuracy 0.9124
discarded batch 863
Epoch 4 Batch 900 Loss 0.3679 Accuracy 0.9122
Epoch 4 Batch 950 Loss 0.3688 Accuracy 0.9120
Epoch 4 Batch 1000 Loss 0.3695 Accuracy 0.9119
Epoch 4 Batch 1050 Loss 0.3703 Accuracy 0.9117
Epoch 4 Batch 1100 Loss 0.3709 Accuracy 0.9116
Epoch 4 Batch 1150 Loss 0.3714 Accuracy 0.9115
Epoch 4 Batch 1200 Loss 0.3720 Accuracy 0.9115
Epoch 4 Batch 1250 Loss 0.3727 Accuracy 0.9113
Epoch 4 Batch 1300 Loss 0.3734 Accuracy 0.9112
Epoch 4 Batch 1350 Loss 0.3743 Accuracy 0.9110
Epoch 4 Batch 1400 Loss 0.3752 Accuracy 0.9108
Epoch 4 Batch 1450 Loss 0.3757 Accuracy 0.9108
Epoch 4 Batch 1500 Loss 0.3765 Accuracy 0.9106

wandb: WARNING Step must only increase in log calls.  Step 4 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.37718737>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9105403>}.

Epoch 4 Loss 0.3772 Accuracy 0.9105
Time taken for 1 epoch: 35.86132192611694 secs

epoch lasted: 35.86717867851257
Epoch 5 Batch 0 Loss 0.3332 Accuracy 0.9252
Epoch 5 Batch 50 Loss 0.3437 Accuracy 0.9169
Epoch 5 Batch 100 Loss 0.3449 Accuracy 0.9160
Epoch 5 Batch 150 Loss 0.3469 Accuracy 0.9162
Epoch 5 Batch 200 Loss 0.3479 Accuracy 0.9162
Epoch 5 Batch 250 Loss 0.3501 Accuracy 0.9156
Epoch 5 Batch 300 Loss 0.3523 Accuracy 0.9150
Epoch 5 Batch 350 Loss 0.3545 Accuracy 0.9146
Epoch 5 Batch 400 Loss 0.3563 Accuracy 0.9144
Epoch 5 Batch 450 Loss 0.3578 Accuracy 0.9140
Epoch 5 Batch 500 Loss 0.3592 Accuracy 0.9139
discarded batch 506
Epoch 5 Batch 550 Loss 0.3596 Accuracy 0.9137
Epoch 5 Batch 600 Loss 0.3605 Accuracy 0.9136
Epoch 5 Batch 650 Loss 0.3612 Accuracy 0.9134
Epoch 5 Batch 700 Loss 0.3627 Accuracy 0.9131
Epoch 5 Batch 750 Loss 0.3636 Accuracy 0.9130
Epoch 5 Batch 800 Loss 0.3644 Accuracy 0.9129
Epoch 5 Batch 850 Loss 0.3656 Accuracy 0.9127
Epoch 5 Batch 900 Loss 0.3664 Accuracy 0.9125
Epoch 5 Batch 950 Loss 0.3673 Accuracy 0.9124
Epoch 5 Batch 1000 Loss 0.3681 Accuracy 0.9123
Epoch 5 Batch 1050 Loss 0.3690 Accuracy 0.9121
Epoch 5 Batch 1100 Loss 0.3698 Accuracy 0.9119
Epoch 5 Batch 1150 Loss 0.3710 Accuracy 0.9118
Epoch 5 Batch 1200 Loss 0.3715 Accuracy 0.9116
Epoch 5 Batch 1250 Loss 0.3726 Accuracy 0.9114
Epoch 5 Batch 1300 Loss 0.3733 Accuracy 0.9114
Epoch 5 Batch 1350 Loss 0.3741 Accuracy 0.9112
Epoch 5 Batch 1400 Loss 0.3749 Accuracy 0.9111
Epoch 5 Batch 1450 Loss 0.3758 Accuracy 0.9110
Epoch 5 Batch 1500 Loss 0.3763 Accuracy 0.9109

wandb: WARNING Step must only increase in log calls.  Step 5 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.37708157>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9107837>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-25
Epoch 5 Loss 0.3771 Accuracy 0.9108
Time taken for 1 epoch: 35.96409559249878 secs

epoch lasted: 35.96823859214783
Epoch 6 Batch 0 Loss 0.3892 Accuracy 0.9136
Epoch 6 Batch 50 Loss 0.3413 Accuracy 0.9173
Epoch 6 Batch 100 Loss 0.3430 Accuracy 0.9168
Epoch 6 Batch 150 Loss 0.3437 Accuracy 0.9163
Epoch 6 Batch 200 Loss 0.3470 Accuracy 0.9159
Epoch 6 Batch 250 Loss 0.3504 Accuracy 0.9152
Epoch 6 Batch 300 Loss 0.3524 Accuracy 0.9148
Epoch 6 Batch 350 Loss 0.3534 Accuracy 0.9148
Epoch 6 Batch 400 Loss 0.3547 Accuracy 0.9143
Epoch 6 Batch 450 Loss 0.3565 Accuracy 0.9140
Epoch 6 Batch 500 Loss 0.3580 Accuracy 0.9137
Epoch 6 Batch 550 Loss 0.3593 Accuracy 0.9135
Epoch 6 Batch 600 Loss 0.3599 Accuracy 0.9133
Epoch 6 Batch 650 Loss 0.3606 Accuracy 0.9132
Epoch 6 Batch 700 Loss 0.3613 Accuracy 0.9131
Epoch 6 Batch 750 Loss 0.3626 Accuracy 0.9130
Epoch 6 Batch 800 Loss 0.3638 Accuracy 0.9127
Epoch 6 Batch 850 Loss 0.3650 Accuracy 0.9125
Epoch 6 Batch 900 Loss 0.3664 Accuracy 0.9122
Epoch 6 Batch 950 Loss 0.3673 Accuracy 0.9121
Epoch 6 Batch 1000 Loss 0.3676 Accuracy 0.9120
Epoch 6 Batch 1050 Loss 0.3682 Accuracy 0.9120
Epoch 6 Batch 1100 Loss 0.3687 Accuracy 0.9119
Epoch 6 Batch 1150 Loss 0.3692 Accuracy 0.9118
Epoch 6 Batch 1200 Loss 0.3702 Accuracy 0.9117
Epoch 6 Batch 1250 Loss 0.3711 Accuracy 0.9115
discarded batch 1269
Epoch 6 Batch 1300 Loss 0.3718 Accuracy 0.9114
Epoch 6 Batch 1350 Loss 0.3728 Accuracy 0.9113
Epoch 6 Batch 1400 Loss 0.3735 Accuracy 0.9113
Epoch 6 Batch 1450 Loss 0.3741 Accuracy 0.9112
Epoch 6 Batch 1500 Loss 0.3748 Accuracy 0.9111

wandb: WARNING Step must only increase in log calls.  Step 6 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3754532>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9109092>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 27; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8642484>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8634551>}.

Epoch 6 Loss 0.3755 Accuracy 0.9109
Time taken for 1 epoch: 35.708436012268066 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.8642 Accuracy 0.8635

epoch lasted: 35.86247158050537
Epoch 7 Batch 0 Loss 0.3650 Accuracy 0.9037
Epoch 7 Batch 50 Loss 0.3389 Accuracy 0.9164
Epoch 7 Batch 100 Loss 0.3439 Accuracy 0.9156
Epoch 7 Batch 150 Loss 0.3453 Accuracy 0.9151
Epoch 7 Batch 200 Loss 0.3481 Accuracy 0.9145
Epoch 7 Batch 250 Loss 0.3501 Accuracy 0.9142
Epoch 7 Batch 300 Loss 0.3524 Accuracy 0.9139
Epoch 7 Batch 350 Loss 0.3543 Accuracy 0.9137
Epoch 7 Batch 400 Loss 0.3551 Accuracy 0.9137
Epoch 7 Batch 450 Loss 0.3556 Accuracy 0.9136
Epoch 7 Batch 500 Loss 0.3576 Accuracy 0.9133
Epoch 7 Batch 550 Loss 0.3590 Accuracy 0.9131
Epoch 7 Batch 600 Loss 0.3602 Accuracy 0.9130
Epoch 7 Batch 650 Loss 0.3615 Accuracy 0.9128
Epoch 7 Batch 700 Loss 0.3626 Accuracy 0.9127
Epoch 7 Batch 750 Loss 0.3636 Accuracy 0.9126
Epoch 7 Batch 800 Loss 0.3647 Accuracy 0.9125
Epoch 7 Batch 850 Loss 0.3653 Accuracy 0.9124
Epoch 7 Batch 900 Loss 0.3660 Accuracy 0.9123
Epoch 7 Batch 950 Loss 0.3665 Accuracy 0.9122
Epoch 7 Batch 1000 Loss 0.3669 Accuracy 0.9122
Epoch 7 Batch 1050 Loss 0.3679 Accuracy 0.9120
Epoch 7 Batch 1100 Loss 0.3687 Accuracy 0.9119
Epoch 7 Batch 1150 Loss 0.3695 Accuracy 0.9118
discarded batch 1181
Epoch 7 Batch 1200 Loss 0.3702 Accuracy 0.9117
Epoch 7 Batch 1250 Loss 0.3711 Accuracy 0.9115
Epoch 7 Batch 1300 Loss 0.3718 Accuracy 0.9114
Epoch 7 Batch 1350 Loss 0.3727 Accuracy 0.9114
Epoch 7 Batch 1400 Loss 0.3734 Accuracy 0.9113
Epoch 7 Batch 1450 Loss 0.3740 Accuracy 0.9112
Epoch 7 Batch 1500 Loss 0.3750 Accuracy 0.9110

wandb: WARNING Step must only increase in log calls.  Step 7 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.37554285>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9109682>}.

Epoch 7 Loss 0.3755 Accuracy 0.9110
Time taken for 1 epoch: 35.739983797073364 secs

epoch lasted: 35.743996143341064
Epoch 8 Batch 0 Loss 0.3506 Accuracy 0.9103
Epoch 8 Batch 50 Loss 0.3391 Accuracy 0.9176
Epoch 8 Batch 100 Loss 0.3403 Accuracy 0.9177
Epoch 8 Batch 150 Loss 0.3439 Accuracy 0.9165
Epoch 8 Batch 200 Loss 0.3469 Accuracy 0.9156
Epoch 8 Batch 250 Loss 0.3508 Accuracy 0.9150
Epoch 8 Batch 300 Loss 0.3527 Accuracy 0.9146
Epoch 8 Batch 350 Loss 0.3551 Accuracy 0.9142
Epoch 8 Batch 400 Loss 0.3557 Accuracy 0.9140
Epoch 8 Batch 450 Loss 0.3571 Accuracy 0.9138
Epoch 8 Batch 500 Loss 0.3583 Accuracy 0.9137
Epoch 8 Batch 550 Loss 0.3595 Accuracy 0.9136
Epoch 8 Batch 600 Loss 0.3606 Accuracy 0.9134
Epoch 8 Batch 650 Loss 0.3613 Accuracy 0.9133
Epoch 8 Batch 700 Loss 0.3620 Accuracy 0.9131
Epoch 8 Batch 750 Loss 0.3629 Accuracy 0.9130
Epoch 8 Batch 800 Loss 0.3635 Accuracy 0.9128
Epoch 8 Batch 850 Loss 0.3642 Accuracy 0.9126
Epoch 8 Batch 900 Loss 0.3651 Accuracy 0.9125
Epoch 8 Batch 950 Loss 0.3659 Accuracy 0.9123
Epoch 8 Batch 1000 Loss 0.3664 Accuracy 0.9122
Epoch 8 Batch 1050 Loss 0.3673 Accuracy 0.9120
Epoch 8 Batch 1100 Loss 0.3680 Accuracy 0.9119
Epoch 8 Batch 1150 Loss 0.3684 Accuracy 0.9119
Epoch 8 Batch 1200 Loss 0.3695 Accuracy 0.9117
Epoch 8 Batch 1250 Loss 0.3705 Accuracy 0.9115
Epoch 8 Batch 1300 Loss 0.3706 Accuracy 0.9115
Epoch 8 Batch 1350 Loss 0.3716 Accuracy 0.9113
discarded batch 1356
Epoch 8 Batch 1400 Loss 0.3720 Accuracy 0.9113
Epoch 8 Batch 1450 Loss 0.3728 Accuracy 0.9111
Epoch 8 Batch 1500 Loss 0.3731 Accuracy 0.9111

wandb: WARNING Step must only increase in log calls.  Step 8 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3736879>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9110314>}.

Epoch 8 Loss 0.3737 Accuracy 0.9110
Time taken for 1 epoch: 35.81355047225952 secs

epoch lasted: 35.817782163619995
Epoch 9 Batch 0 Loss 0.3976 Accuracy 0.9037
Epoch 9 Batch 50 Loss 0.3509 Accuracy 0.9166
Epoch 9 Batch 100 Loss 0.3474 Accuracy 0.9153
Epoch 9 Batch 150 Loss 0.3497 Accuracy 0.9154
Epoch 9 Batch 200 Loss 0.3504 Accuracy 0.9151
Epoch 9 Batch 250 Loss 0.3512 Accuracy 0.9149
Epoch 9 Batch 300 Loss 0.3520 Accuracy 0.9148
Epoch 9 Batch 350 Loss 0.3525 Accuracy 0.9147
Epoch 9 Batch 400 Loss 0.3526 Accuracy 0.9146
discarded batch 406
Epoch 9 Batch 450 Loss 0.3537 Accuracy 0.9144
Epoch 9 Batch 500 Loss 0.3546 Accuracy 0.9143
Epoch 9 Batch 550 Loss 0.3556 Accuracy 0.9141
Epoch 9 Batch 600 Loss 0.3560 Accuracy 0.9141
Epoch 9 Batch 650 Loss 0.3576 Accuracy 0.9139
Epoch 9 Batch 700 Loss 0.3584 Accuracy 0.9138
Epoch 9 Batch 750 Loss 0.3594 Accuracy 0.9136
Epoch 9 Batch 800 Loss 0.3601 Accuracy 0.9134
Epoch 9 Batch 850 Loss 0.3614 Accuracy 0.9133
Epoch 9 Batch 900 Loss 0.3616 Accuracy 0.9132
Epoch 9 Batch 950 Loss 0.3620 Accuracy 0.9132
Epoch 9 Batch 1000 Loss 0.3632 Accuracy 0.9130
Epoch 9 Batch 1050 Loss 0.3639 Accuracy 0.9129
Epoch 9 Batch 1100 Loss 0.3647 Accuracy 0.9127
Epoch 9 Batch 1150 Loss 0.3654 Accuracy 0.9126
Epoch 9 Batch 1200 Loss 0.3659 Accuracy 0.9125
Epoch 9 Batch 1250 Loss 0.3668 Accuracy 0.9124
Epoch 9 Batch 1300 Loss 0.3677 Accuracy 0.9123
Epoch 9 Batch 1350 Loss 0.3687 Accuracy 0.9121
Epoch 9 Batch 1400 Loss 0.3695 Accuracy 0.9120
Epoch 9 Batch 1450 Loss 0.3702 Accuracy 0.9119
Epoch 9 Batch 1500 Loss 0.3709 Accuracy 0.9118

wandb: WARNING Step must only increase in log calls.  Step 9 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3716449>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91160625>}.

Epoch 9 Loss 0.3716 Accuracy 0.9116
Time taken for 1 epoch: 35.85240697860718 secs

epoch lasted: 35.85677361488342
Epoch 10 Batch 0 Loss 0.2814 Accuracy 0.9352
Epoch 10 Batch 50 Loss 0.3396 Accuracy 0.9178
Epoch 10 Batch 100 Loss 0.3390 Accuracy 0.9178
Epoch 10 Batch 150 Loss 0.3414 Accuracy 0.9170
Epoch 10 Batch 200 Loss 0.3425 Accuracy 0.9166
Epoch 10 Batch 250 Loss 0.3442 Accuracy 0.9164
discarded batch 254
Epoch 10 Batch 300 Loss 0.3464 Accuracy 0.9161
Epoch 10 Batch 350 Loss 0.3481 Accuracy 0.9159
Epoch 10 Batch 400 Loss 0.3494 Accuracy 0.9155
Epoch 10 Batch 450 Loss 0.3508 Accuracy 0.9152
Epoch 10 Batch 500 Loss 0.3521 Accuracy 0.9151
Epoch 10 Batch 550 Loss 0.3533 Accuracy 0.9149
Epoch 10 Batch 600 Loss 0.3542 Accuracy 0.9146
Epoch 10 Batch 650 Loss 0.3557 Accuracy 0.9143
Epoch 10 Batch 700 Loss 0.3562 Accuracy 0.9142
Epoch 10 Batch 750 Loss 0.3571 Accuracy 0.9141
Epoch 10 Batch 800 Loss 0.3584 Accuracy 0.9139
Epoch 10 Batch 850 Loss 0.3595 Accuracy 0.9136
Epoch 10 Batch 900 Loss 0.3601 Accuracy 0.9135
Epoch 10 Batch 950 Loss 0.3615 Accuracy 0.9133
Epoch 10 Batch 1000 Loss 0.3623 Accuracy 0.9132
Epoch 10 Batch 1050 Loss 0.3634 Accuracy 0.9130
Epoch 10 Batch 1100 Loss 0.3644 Accuracy 0.9128
Epoch 10 Batch 1150 Loss 0.3653 Accuracy 0.9126
Epoch 10 Batch 1200 Loss 0.3664 Accuracy 0.9124
Epoch 10 Batch 1250 Loss 0.3669 Accuracy 0.9124
Epoch 10 Batch 1300 Loss 0.3676 Accuracy 0.9123
Epoch 10 Batch 1350 Loss 0.3685 Accuracy 0.9122
Epoch 10 Batch 1400 Loss 0.3694 Accuracy 0.9120
Epoch 10 Batch 1450 Loss 0.3701 Accuracy 0.9119
Epoch 10 Batch 1500 Loss 0.3707 Accuracy 0.9118

wandb: WARNING Step must only increase in log calls.  Step 10 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.37134874>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91173494>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-26
Epoch 10 Loss 0.3713 Accuracy 0.9117
Time taken for 1 epoch: 36.125372648239136 secs

epoch lasted: 36.12933945655823
Epoch 11 Batch 0 Loss 0.3252 Accuracy 0.9186
Epoch 11 Batch 50 Loss 0.3336 Accuracy 0.9190
Epoch 11 Batch 100 Loss 0.3338 Accuracy 0.9184
Epoch 11 Batch 150 Loss 0.3376 Accuracy 0.9174
Epoch 11 Batch 200 Loss 0.3404 Accuracy 0.9170
Epoch 11 Batch 250 Loss 0.3424 Accuracy 0.9166
Epoch 11 Batch 300 Loss 0.3449 Accuracy 0.9163
Epoch 11 Batch 350 Loss 0.3474 Accuracy 0.9157
Epoch 11 Batch 400 Loss 0.3487 Accuracy 0.9155
Epoch 11 Batch 450 Loss 0.3500 Accuracy 0.9153
Epoch 11 Batch 500 Loss 0.3510 Accuracy 0.9151
Epoch 11 Batch 550 Loss 0.3533 Accuracy 0.9146
discarded batch 564
Epoch 11 Batch 600 Loss 0.3548 Accuracy 0.9143
Epoch 11 Batch 650 Loss 0.3558 Accuracy 0.9142
Epoch 11 Batch 700 Loss 0.3568 Accuracy 0.9141
Epoch 11 Batch 750 Loss 0.3577 Accuracy 0.9140
Epoch 11 Batch 800 Loss 0.3587 Accuracy 0.9138
Epoch 11 Batch 850 Loss 0.3595 Accuracy 0.9136
Epoch 11 Batch 900 Loss 0.3602 Accuracy 0.9136
Epoch 11 Batch 950 Loss 0.3613 Accuracy 0.9135
Epoch 11 Batch 1000 Loss 0.3618 Accuracy 0.9133
Epoch 11 Batch 1050 Loss 0.3626 Accuracy 0.9132
Epoch 11 Batch 1100 Loss 0.3629 Accuracy 0.9131
Epoch 11 Batch 1150 Loss 0.3635 Accuracy 0.9130
Epoch 11 Batch 1200 Loss 0.3642 Accuracy 0.9129
Epoch 11 Batch 1250 Loss 0.3647 Accuracy 0.9127
Epoch 11 Batch 1300 Loss 0.3658 Accuracy 0.9126
Epoch 11 Batch 1350 Loss 0.3667 Accuracy 0.9125
Epoch 11 Batch 1400 Loss 0.3674 Accuracy 0.9124
Epoch 11 Batch 1450 Loss 0.3682 Accuracy 0.9122
Epoch 11 Batch 1500 Loss 0.3687 Accuracy 0.9122

wandb: WARNING Step must only increase in log calls.  Step 11 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36948392>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91202986>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 27; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8639553>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86478406>}.

Epoch 11 Loss 0.3695 Accuracy 0.9120
Time taken for 1 epoch: 35.83887219429016 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.8640 Accuracy 0.8648

epoch lasted: 35.99525475502014
Epoch 12 Batch 0 Loss 0.2983 Accuracy 0.9252
Epoch 12 Batch 50 Loss 0.3367 Accuracy 0.9172
Epoch 12 Batch 100 Loss 0.3369 Accuracy 0.9171
Epoch 12 Batch 150 Loss 0.3379 Accuracy 0.9170
Epoch 12 Batch 200 Loss 0.3424 Accuracy 0.9162
Epoch 12 Batch 250 Loss 0.3444 Accuracy 0.9159
Epoch 12 Batch 300 Loss 0.3456 Accuracy 0.9156
Epoch 12 Batch 350 Loss 0.3463 Accuracy 0.9156
Epoch 12 Batch 400 Loss 0.3483 Accuracy 0.9153
Epoch 12 Batch 450 Loss 0.3497 Accuracy 0.9149
Epoch 12 Batch 500 Loss 0.3508 Accuracy 0.9148
Epoch 12 Batch 550 Loss 0.3516 Accuracy 0.9147
Epoch 12 Batch 600 Loss 0.3526 Accuracy 0.9146
Epoch 12 Batch 650 Loss 0.3535 Accuracy 0.9145
Epoch 12 Batch 700 Loss 0.3551 Accuracy 0.9143
Epoch 12 Batch 750 Loss 0.3563 Accuracy 0.9140
Epoch 12 Batch 800 Loss 0.3572 Accuracy 0.9139
Epoch 12 Batch 850 Loss 0.3583 Accuracy 0.9137
Epoch 12 Batch 900 Loss 0.3587 Accuracy 0.9136
Epoch 12 Batch 950 Loss 0.3601 Accuracy 0.9134
Epoch 12 Batch 1000 Loss 0.3606 Accuracy 0.9132
Epoch 12 Batch 1050 Loss 0.3616 Accuracy 0.9131
Epoch 12 Batch 1100 Loss 0.3624 Accuracy 0.9130
Epoch 12 Batch 1150 Loss 0.3638 Accuracy 0.9128
Epoch 12 Batch 1200 Loss 0.3646 Accuracy 0.9126
Epoch 12 Batch 1250 Loss 0.3652 Accuracy 0.9124
Epoch 12 Batch 1300 Loss 0.3660 Accuracy 0.9124
Epoch 12 Batch 1350 Loss 0.3668 Accuracy 0.9122
Epoch 12 Batch 1400 Loss 0.3673 Accuracy 0.9121
Epoch 12 Batch 1450 Loss 0.3679 Accuracy 0.9120
Epoch 12 Batch 1500 Loss 0.3687 Accuracy 0.9118

wandb: WARNING Step must only increase in log calls.  Step 12 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36954662>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.911706>}.

discarded batch 1549
Epoch 12 Loss 0.3695 Accuracy 0.9117
Time taken for 1 epoch: 35.821693658828735 secs

epoch lasted: 35.82556939125061
Epoch 13 Batch 0 Loss 0.3264 Accuracy 0.9203
Epoch 13 Batch 50 Loss 0.3326 Accuracy 0.9201
Epoch 13 Batch 100 Loss 0.3376 Accuracy 0.9183
Epoch 13 Batch 150 Loss 0.3370 Accuracy 0.9184
Epoch 13 Batch 200 Loss 0.3409 Accuracy 0.9178
Epoch 13 Batch 250 Loss 0.3429 Accuracy 0.9175
Epoch 13 Batch 300 Loss 0.3439 Accuracy 0.9170
Epoch 13 Batch 350 Loss 0.3451 Accuracy 0.9167
Epoch 13 Batch 400 Loss 0.3459 Accuracy 0.9163
Epoch 13 Batch 450 Loss 0.3468 Accuracy 0.9159
Epoch 13 Batch 500 Loss 0.3488 Accuracy 0.9157
Epoch 13 Batch 550 Loss 0.3496 Accuracy 0.9156
Epoch 13 Batch 600 Loss 0.3511 Accuracy 0.9153
Epoch 13 Batch 650 Loss 0.3523 Accuracy 0.9151
Epoch 13 Batch 700 Loss 0.3532 Accuracy 0.9151
Epoch 13 Batch 750 Loss 0.3547 Accuracy 0.9148
Epoch 13 Batch 800 Loss 0.3557 Accuracy 0.9147
Epoch 13 Batch 850 Loss 0.3571 Accuracy 0.9145
Epoch 13 Batch 900 Loss 0.3577 Accuracy 0.9143
discarded batch 950
Epoch 13 Batch 1000 Loss 0.3592 Accuracy 0.9139
Epoch 13 Batch 1050 Loss 0.3604 Accuracy 0.9137
Epoch 13 Batch 1100 Loss 0.3619 Accuracy 0.9135
Epoch 13 Batch 1150 Loss 0.3633 Accuracy 0.9133
Epoch 13 Batch 1200 Loss 0.3640 Accuracy 0.9132
Epoch 13 Batch 1250 Loss 0.3651 Accuracy 0.9129
Epoch 13 Batch 1300 Loss 0.3657 Accuracy 0.9128
Epoch 13 Batch 1350 Loss 0.3663 Accuracy 0.9127
Epoch 13 Batch 1400 Loss 0.3672 Accuracy 0.9127
Epoch 13 Batch 1450 Loss 0.3678 Accuracy 0.9126
Epoch 13 Batch 1500 Loss 0.3686 Accuracy 0.9124

wandb: WARNING Step must only increase in log calls.  Step 13 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36958158>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91220355>}.

Epoch 13 Loss 0.3696 Accuracy 0.9122
Time taken for 1 epoch: 35.79579973220825 secs

epoch lasted: 35.80315971374512
Epoch 14 Batch 0 Loss 0.3333 Accuracy 0.9120
Epoch 14 Batch 50 Loss 0.3322 Accuracy 0.9186
Epoch 14 Batch 100 Loss 0.3315 Accuracy 0.9183
Epoch 14 Batch 150 Loss 0.3362 Accuracy 0.9175
Epoch 14 Batch 200 Loss 0.3397 Accuracy 0.9170
Epoch 14 Batch 250 Loss 0.3404 Accuracy 0.9167
Epoch 14 Batch 300 Loss 0.3424 Accuracy 0.9166
Epoch 14 Batch 350 Loss 0.3441 Accuracy 0.9163
Epoch 14 Batch 400 Loss 0.3458 Accuracy 0.9158
Epoch 14 Batch 450 Loss 0.3486 Accuracy 0.9155
Epoch 14 Batch 500 Loss 0.3501 Accuracy 0.9153
Epoch 14 Batch 550 Loss 0.3507 Accuracy 0.9152
Epoch 14 Batch 600 Loss 0.3519 Accuracy 0.9149
Epoch 14 Batch 650 Loss 0.3530 Accuracy 0.9146
Epoch 14 Batch 700 Loss 0.3544 Accuracy 0.9143
Epoch 14 Batch 750 Loss 0.3552 Accuracy 0.9142
Epoch 14 Batch 800 Loss 0.3561 Accuracy 0.9141
Epoch 14 Batch 850 Loss 0.3570 Accuracy 0.9140
Epoch 14 Batch 900 Loss 0.3580 Accuracy 0.9138
Epoch 14 Batch 950 Loss 0.3590 Accuracy 0.9136
Epoch 14 Batch 1000 Loss 0.3600 Accuracy 0.9134
Epoch 14 Batch 1050 Loss 0.3608 Accuracy 0.9132
Epoch 14 Batch 1100 Loss 0.3616 Accuracy 0.9130
Epoch 14 Batch 1150 Loss 0.3624 Accuracy 0.9129
Epoch 14 Batch 1200 Loss 0.3632 Accuracy 0.9128
Epoch 14 Batch 1250 Loss 0.3640 Accuracy 0.9126
discarded batch 1288
Epoch 14 Batch 1300 Loss 0.3650 Accuracy 0.9124
Epoch 14 Batch 1350 Loss 0.3658 Accuracy 0.9124
Epoch 14 Batch 1400 Loss 0.3663 Accuracy 0.9124
Epoch 14 Batch 1450 Loss 0.3669 Accuracy 0.9122
Epoch 14 Batch 1500 Loss 0.3678 Accuracy 0.9121

wandb: WARNING Step must only increase in log calls.  Step 14 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3682422>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9120234>}.

Epoch 14 Loss 0.3682 Accuracy 0.9120
Time taken for 1 epoch: 35.80221605300903 secs

epoch lasted: 35.80751872062683
Epoch 15 Batch 0 Loss 0.2813 Accuracy 0.9352
Epoch 15 Batch 50 Loss 0.3355 Accuracy 0.9190
Epoch 15 Batch 100 Loss 0.3386 Accuracy 0.9175
Epoch 15 Batch 150 Loss 0.3407 Accuracy 0.9166
Epoch 15 Batch 200 Loss 0.3420 Accuracy 0.9162
Epoch 15 Batch 250 Loss 0.3431 Accuracy 0.9161
Epoch 15 Batch 300 Loss 0.3437 Accuracy 0.9160
Epoch 15 Batch 350 Loss 0.3456 Accuracy 0.9157
Epoch 15 Batch 400 Loss 0.3480 Accuracy 0.9155
Epoch 15 Batch 450 Loss 0.3487 Accuracy 0.9152
Epoch 15 Batch 500 Loss 0.3499 Accuracy 0.9149
Epoch 15 Batch 550 Loss 0.3512 Accuracy 0.9147
Epoch 15 Batch 600 Loss 0.3516 Accuracy 0.9145
discarded batch 648
Epoch 15 Batch 650 Loss 0.3528 Accuracy 0.9145
Epoch 15 Batch 700 Loss 0.3538 Accuracy 0.9143
Epoch 15 Batch 750 Loss 0.3545 Accuracy 0.9141
Epoch 15 Batch 800 Loss 0.3556 Accuracy 0.9139
Epoch 15 Batch 850 Loss 0.3562 Accuracy 0.9138
Epoch 15 Batch 900 Loss 0.3572 Accuracy 0.9137
Epoch 15 Batch 950 Loss 0.3582 Accuracy 0.9135
Epoch 15 Batch 1000 Loss 0.3588 Accuracy 0.9133
Epoch 15 Batch 1050 Loss 0.3589 Accuracy 0.9133
Epoch 15 Batch 1100 Loss 0.3597 Accuracy 0.9131
Epoch 15 Batch 1150 Loss 0.3603 Accuracy 0.9130
Epoch 15 Batch 1200 Loss 0.3609 Accuracy 0.9130
Epoch 15 Batch 1250 Loss 0.3618 Accuracy 0.9129
Epoch 15 Batch 1300 Loss 0.3629 Accuracy 0.9127
Epoch 15 Batch 1350 Loss 0.3637 Accuracy 0.9127
Epoch 15 Batch 1400 Loss 0.3645 Accuracy 0.9125
Epoch 15 Batch 1450 Loss 0.3650 Accuracy 0.9125
Epoch 15 Batch 1500 Loss 0.3658 Accuracy 0.9124

wandb: WARNING Step must only increase in log calls.  Step 15 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36626986>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91233975>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-27
Epoch 15 Loss 0.3663 Accuracy 0.9123
Time taken for 1 epoch: 36.19892168045044 secs

epoch lasted: 36.202924728393555
Epoch 16 Batch 0 Loss 0.2918 Accuracy 0.9219
Epoch 16 Batch 50 Loss 0.3405 Accuracy 0.9173
Epoch 16 Batch 100 Loss 0.3402 Accuracy 0.9175
Epoch 16 Batch 150 Loss 0.3409 Accuracy 0.9175
Epoch 16 Batch 200 Loss 0.3410 Accuracy 0.9172
Epoch 16 Batch 250 Loss 0.3414 Accuracy 0.9167
Epoch 16 Batch 300 Loss 0.3434 Accuracy 0.9164
Epoch 16 Batch 350 Loss 0.3451 Accuracy 0.9164
Epoch 16 Batch 400 Loss 0.3460 Accuracy 0.9163
Epoch 16 Batch 450 Loss 0.3470 Accuracy 0.9160
Epoch 16 Batch 500 Loss 0.3475 Accuracy 0.9159
Epoch 16 Batch 550 Loss 0.3484 Accuracy 0.9155
Epoch 16 Batch 600 Loss 0.3490 Accuracy 0.9154
Epoch 16 Batch 650 Loss 0.3499 Accuracy 0.9152
Epoch 16 Batch 700 Loss 0.3508 Accuracy 0.9149
Epoch 16 Batch 750 Loss 0.3523 Accuracy 0.9147
Epoch 16 Batch 800 Loss 0.3534 Accuracy 0.9145
Epoch 16 Batch 850 Loss 0.3543 Accuracy 0.9144
Epoch 16 Batch 900 Loss 0.3553 Accuracy 0.9142
Epoch 16 Batch 950 Loss 0.3561 Accuracy 0.9141
Epoch 16 Batch 1000 Loss 0.3572 Accuracy 0.9139
Epoch 16 Batch 1050 Loss 0.3581 Accuracy 0.9137
Epoch 16 Batch 1100 Loss 0.3587 Accuracy 0.9136
Epoch 16 Batch 1150 Loss 0.3595 Accuracy 0.9135
Epoch 16 Batch 1200 Loss 0.3603 Accuracy 0.9134
Epoch 16 Batch 1250 Loss 0.3610 Accuracy 0.9133
Epoch 16 Batch 1300 Loss 0.3619 Accuracy 0.9131
Epoch 16 Batch 1350 Loss 0.3627 Accuracy 0.9130
Epoch 16 Batch 1400 Loss 0.3634 Accuracy 0.9128
discarded batch 1409
Epoch 16 Batch 1450 Loss 0.3639 Accuracy 0.9127
Epoch 16 Batch 1500 Loss 0.3645 Accuracy 0.9126

wandb: WARNING Step must only increase in log calls.  Step 16 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3653886>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9124127>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 27; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8780481>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8636766>}.

Epoch 16 Loss 0.3654 Accuracy 0.9124
Time taken for 1 epoch: 35.85685706138611 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.8780 Accuracy 0.8637

epoch lasted: 36.01462268829346
Epoch 17 Batch 0 Loss 0.2992 Accuracy 0.9286
Epoch 17 Batch 50 Loss 0.3328 Accuracy 0.9175
Epoch 17 Batch 100 Loss 0.3326 Accuracy 0.9179
Epoch 17 Batch 150 Loss 0.3364 Accuracy 0.9173
Epoch 17 Batch 200 Loss 0.3379 Accuracy 0.9171
Epoch 17 Batch 250 Loss 0.3398 Accuracy 0.9168
Epoch 17 Batch 300 Loss 0.3393 Accuracy 0.9171
discarded batch 338
Epoch 17 Batch 350 Loss 0.3410 Accuracy 0.9168
Epoch 17 Batch 400 Loss 0.3425 Accuracy 0.9165
Epoch 17 Batch 450 Loss 0.3438 Accuracy 0.9163
Epoch 17 Batch 500 Loss 0.3456 Accuracy 0.9158
Epoch 17 Batch 550 Loss 0.3466 Accuracy 0.9156
Epoch 17 Batch 600 Loss 0.3476 Accuracy 0.9155
Epoch 17 Batch 650 Loss 0.3485 Accuracy 0.9153
Epoch 17 Batch 700 Loss 0.3496 Accuracy 0.9151
Epoch 17 Batch 750 Loss 0.3508 Accuracy 0.9149
Epoch 17 Batch 800 Loss 0.3522 Accuracy 0.9145
Epoch 17 Batch 850 Loss 0.3530 Accuracy 0.9144
Epoch 17 Batch 900 Loss 0.3541 Accuracy 0.9142
Epoch 17 Batch 950 Loss 0.3550 Accuracy 0.9140
Epoch 17 Batch 1000 Loss 0.3559 Accuracy 0.9139
Epoch 17 Batch 1050 Loss 0.3566 Accuracy 0.9138
Epoch 17 Batch 1100 Loss 0.3574 Accuracy 0.9137
Epoch 17 Batch 1150 Loss 0.3582 Accuracy 0.9135
Epoch 17 Batch 1200 Loss 0.3590 Accuracy 0.9135
Epoch 17 Batch 1250 Loss 0.3599 Accuracy 0.9134
Epoch 17 Batch 1300 Loss 0.3608 Accuracy 0.9132
Epoch 17 Batch 1350 Loss 0.3616 Accuracy 0.9131
Epoch 17 Batch 1400 Loss 0.3621 Accuracy 0.9129
Epoch 17 Batch 1450 Loss 0.3630 Accuracy 0.9128
Epoch 17 Batch 1500 Loss 0.3634 Accuracy 0.9128

wandb: WARNING Step must only increase in log calls.  Step 17 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36418054>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9125907>}.

Epoch 17 Loss 0.3642 Accuracy 0.9126
Time taken for 1 epoch: 35.73928356170654 secs

epoch lasted: 35.752790689468384
Epoch 18 Batch 0 Loss 0.3574 Accuracy 0.9103
Epoch 18 Batch 50 Loss 0.3333 Accuracy 0.9177
Epoch 18 Batch 100 Loss 0.3355 Accuracy 0.9176
Epoch 18 Batch 150 Loss 0.3414 Accuracy 0.9167
Epoch 18 Batch 200 Loss 0.3389 Accuracy 0.9172
Epoch 18 Batch 250 Loss 0.3400 Accuracy 0.9171
Epoch 18 Batch 300 Loss 0.3419 Accuracy 0.9168
Epoch 18 Batch 350 Loss 0.3424 Accuracy 0.9169
Epoch 18 Batch 400 Loss 0.3437 Accuracy 0.9166
Epoch 18 Batch 450 Loss 0.3449 Accuracy 0.9165
Epoch 18 Batch 500 Loss 0.3469 Accuracy 0.9161
Epoch 18 Batch 550 Loss 0.3477 Accuracy 0.9159
Epoch 18 Batch 600 Loss 0.3484 Accuracy 0.9157
Epoch 18 Batch 650 Loss 0.3491 Accuracy 0.9155
Epoch 18 Batch 700 Loss 0.3505 Accuracy 0.9151
Epoch 18 Batch 750 Loss 0.3517 Accuracy 0.9151
Epoch 18 Batch 800 Loss 0.3523 Accuracy 0.9150
Epoch 18 Batch 850 Loss 0.3532 Accuracy 0.9149
Epoch 18 Batch 900 Loss 0.3538 Accuracy 0.9147
Epoch 18 Batch 950 Loss 0.3544 Accuracy 0.9145
Epoch 18 Batch 1000 Loss 0.3556 Accuracy 0.9143
Epoch 18 Batch 1050 Loss 0.3565 Accuracy 0.9142
Epoch 18 Batch 1100 Loss 0.3572 Accuracy 0.9141
Epoch 18 Batch 1150 Loss 0.3582 Accuracy 0.9140
Epoch 18 Batch 1200 Loss 0.3588 Accuracy 0.9139
Epoch 18 Batch 1250 Loss 0.3595 Accuracy 0.9138
Epoch 18 Batch 1300 Loss 0.3600 Accuracy 0.9137
Epoch 18 Batch 1350 Loss 0.3605 Accuracy 0.9136
Epoch 18 Batch 1400 Loss 0.3612 Accuracy 0.9135
discarded batch 1414
Epoch 18 Batch 1450 Loss 0.3619 Accuracy 0.9133
Epoch 18 Batch 1500 Loss 0.3629 Accuracy 0.9131

wandb: WARNING Step must only increase in log calls.  Step 18 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36358315>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91299605>}.

Epoch 18 Loss 0.3636 Accuracy 0.9130
Time taken for 1 epoch: 35.968467712402344 secs

epoch lasted: 35.972742319107056
Epoch 19 Batch 0 Loss 0.3065 Accuracy 0.9219
Epoch 19 Batch 50 Loss 0.3380 Accuracy 0.9180
Epoch 19 Batch 100 Loss 0.3405 Accuracy 0.9175
Epoch 19 Batch 150 Loss 0.3400 Accuracy 0.9169
Epoch 19 Batch 200 Loss 0.3418 Accuracy 0.9166
Epoch 19 Batch 250 Loss 0.3415 Accuracy 0.9167
Epoch 19 Batch 300 Loss 0.3425 Accuracy 0.9162
Epoch 19 Batch 350 Loss 0.3439 Accuracy 0.9159
Epoch 19 Batch 400 Loss 0.3441 Accuracy 0.9158
Epoch 19 Batch 450 Loss 0.3450 Accuracy 0.9158
Epoch 19 Batch 500 Loss 0.3458 Accuracy 0.9156
Epoch 19 Batch 550 Loss 0.3461 Accuracy 0.9155
Epoch 19 Batch 600 Loss 0.3473 Accuracy 0.9153
Epoch 19 Batch 650 Loss 0.3488 Accuracy 0.9152
Epoch 19 Batch 700 Loss 0.3497 Accuracy 0.9150
Epoch 19 Batch 750 Loss 0.3506 Accuracy 0.9149
Epoch 19 Batch 800 Loss 0.3515 Accuracy 0.9148
Epoch 19 Batch 850 Loss 0.3525 Accuracy 0.9146
discarded batch 864
Epoch 19 Batch 900 Loss 0.3533 Accuracy 0.9145
Epoch 19 Batch 950 Loss 0.3540 Accuracy 0.9145
Epoch 19 Batch 1000 Loss 0.3547 Accuracy 0.9144
Epoch 19 Batch 1050 Loss 0.3557 Accuracy 0.9141
Epoch 19 Batch 1100 Loss 0.3561 Accuracy 0.9140
Epoch 19 Batch 1150 Loss 0.3571 Accuracy 0.9139
Epoch 19 Batch 1200 Loss 0.3578 Accuracy 0.9137
Epoch 19 Batch 1250 Loss 0.3585 Accuracy 0.9136
Epoch 19 Batch 1300 Loss 0.3590 Accuracy 0.9134
Epoch 19 Batch 1350 Loss 0.3595 Accuracy 0.9134
Epoch 19 Batch 1400 Loss 0.3601 Accuracy 0.9133
Epoch 19 Batch 1450 Loss 0.3610 Accuracy 0.9132
Epoch 19 Batch 1500 Loss 0.3616 Accuracy 0.9131

wandb: WARNING Step must only increase in log calls.  Step 19 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36241052>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9130025>}.

Epoch 19 Loss 0.3624 Accuracy 0.9130
Time taken for 1 epoch: 35.75659990310669 secs

epoch lasted: 35.76093149185181
Epoch 20 Batch 0 Loss 0.3423 Accuracy 0.9153
Epoch 20 Batch 50 Loss 0.3229 Accuracy 0.9194
Epoch 20 Batch 100 Loss 0.3297 Accuracy 0.9190
Epoch 20 Batch 150 Loss 0.3328 Accuracy 0.9181
Epoch 20 Batch 200 Loss 0.3339 Accuracy 0.9177
Epoch 20 Batch 250 Loss 0.3365 Accuracy 0.9169
Epoch 20 Batch 300 Loss 0.3396 Accuracy 0.9163
Epoch 20 Batch 350 Loss 0.3404 Accuracy 0.9165
Epoch 20 Batch 400 Loss 0.3423 Accuracy 0.9162
Epoch 20 Batch 450 Loss 0.3435 Accuracy 0.9160
Epoch 20 Batch 500 Loss 0.3446 Accuracy 0.9158
Epoch 20 Batch 550 Loss 0.3454 Accuracy 0.9157
Epoch 20 Batch 600 Loss 0.3461 Accuracy 0.9155
Epoch 20 Batch 650 Loss 0.3465 Accuracy 0.9155
Epoch 20 Batch 700 Loss 0.3474 Accuracy 0.9154
discarded batch 705
Epoch 20 Batch 750 Loss 0.3479 Accuracy 0.9154
Epoch 20 Batch 800 Loss 0.3491 Accuracy 0.9152
Epoch 20 Batch 850 Loss 0.3499 Accuracy 0.9150
Epoch 20 Batch 900 Loss 0.3512 Accuracy 0.9148
Epoch 20 Batch 950 Loss 0.3521 Accuracy 0.9145
Epoch 20 Batch 1000 Loss 0.3530 Accuracy 0.9144
Epoch 20 Batch 1050 Loss 0.3540 Accuracy 0.9143
Epoch 20 Batch 1100 Loss 0.3549 Accuracy 0.9142
Epoch 20 Batch 1150 Loss 0.3556 Accuracy 0.9140
Epoch 20 Batch 1200 Loss 0.3564 Accuracy 0.9139
Epoch 20 Batch 1250 Loss 0.3573 Accuracy 0.9138
Epoch 20 Batch 1300 Loss 0.3580 Accuracy 0.9136
Epoch 20 Batch 1350 Loss 0.3590 Accuracy 0.9134
Epoch 20 Batch 1400 Loss 0.3594 Accuracy 0.9134
Epoch 20 Batch 1450 Loss 0.3599 Accuracy 0.9133
Epoch 20 Batch 1500 Loss 0.3608 Accuracy 0.9132

wandb: WARNING Step must only increase in log calls.  Step 20 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3614504>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91308933>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-28
Epoch 20 Loss 0.3615 Accuracy 0.9131
Time taken for 1 epoch: 36.286251068115234 secs

epoch lasted: 36.290523529052734
Epoch 21 Batch 0 Loss 0.3190 Accuracy 0.9203
Epoch 21 Batch 50 Loss 0.3237 Accuracy 0.9207
Epoch 21 Batch 100 Loss 0.3286 Accuracy 0.9191
Epoch 21 Batch 150 Loss 0.3305 Accuracy 0.9181
Epoch 21 Batch 200 Loss 0.3339 Accuracy 0.9175
discarded batch 250
Epoch 21 Batch 300 Loss 0.3379 Accuracy 0.9171
Epoch 21 Batch 350 Loss 0.3386 Accuracy 0.9167
Epoch 21 Batch 400 Loss 0.3401 Accuracy 0.9166
Epoch 21 Batch 450 Loss 0.3414 Accuracy 0.9164
Epoch 21 Batch 500 Loss 0.3416 Accuracy 0.9163
Epoch 21 Batch 550 Loss 0.3433 Accuracy 0.9160
Epoch 21 Batch 600 Loss 0.3447 Accuracy 0.9157
Epoch 21 Batch 650 Loss 0.3454 Accuracy 0.9155
Epoch 21 Batch 700 Loss 0.3465 Accuracy 0.9155
Epoch 21 Batch 750 Loss 0.3478 Accuracy 0.9153
Epoch 21 Batch 800 Loss 0.3483 Accuracy 0.9152
Epoch 21 Batch 850 Loss 0.3492 Accuracy 0.9151
Epoch 21 Batch 900 Loss 0.3504 Accuracy 0.9148
Epoch 21 Batch 950 Loss 0.3511 Accuracy 0.9149
Epoch 21 Batch 1000 Loss 0.3521 Accuracy 0.9147
Epoch 21 Batch 1050 Loss 0.3526 Accuracy 0.9147
Epoch 21 Batch 1100 Loss 0.3536 Accuracy 0.9145
Epoch 21 Batch 1150 Loss 0.3541 Accuracy 0.9144
Epoch 21 Batch 1200 Loss 0.3550 Accuracy 0.9143
Epoch 21 Batch 1250 Loss 0.3559 Accuracy 0.9141
Epoch 21 Batch 1300 Loss 0.3566 Accuracy 0.9140
Epoch 21 Batch 1350 Loss 0.3572 Accuracy 0.9139
Epoch 21 Batch 1400 Loss 0.3583 Accuracy 0.9137
Epoch 21 Batch 1450 Loss 0.3593 Accuracy 0.9135
Epoch 21 Batch 1500 Loss 0.3600 Accuracy 0.9135

wandb: WARNING Step must only increase in log calls.  Step 21 < 27; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3603238>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9134625>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 27; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8781623>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86445177>}.

Epoch 21 Loss 0.3603 Accuracy 0.9135
Time taken for 1 epoch: 36.28609037399292 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.8782 Accuracy 0.8645

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 on|d’ io |co|lui |ve|der |ch’ i’ |ti |ri|cor|po|co|
quan|do |son |an|cor |tor|nar |co|tai |vi|so|
ben |ti |ma|la|men|te |più |che |mi |mo|co|
                                                                                                                                                                   
 e ’l |ca|gio|va|mo e |tu |vuo’ |sa|reb|be |fi|so|
qual |tu |se’ |tu |sai |che |mi |di|mo|te|
e |quel |che ’l |ce|de|reb|be |li |mor|ti|so|
con |es|si |fa |la |don|na |con |le |sue |me|mo|to|
con |tan|to |mon|do |per |cui |buo|na |me|
e |per|ché |pur |co|lui |chi |nel |se|con|do|
                                                                                                                                                                    
 per |ma|e|stro |mio |ma|le|ti|ca |me|mo|
per |che |que|sta |lu|ce |cre|det|to |mo|re|
e |s’ io |a |co|stui |fu |cre|do |giù |mi|mo|
 ma |per|ché |la |mia |don|na |mia |si|mi|su|so|
ma |dim|co|me ’l |sol |per |la |mia |con|du|ra|
non |que|sto |fon|do|man|da |que|sta |le|mo|
                                                                                                                                                                   
 ma |per|cos|sen|te |tut|ta |que|sta |lu|ca|
che |s’ io |po|co a |po|co |do|lor |più |le|mo|
on|d’ el|li a |me |fa |ché |tut|ti |si |var|ca|
e |se |le |par|ti|ca|re |po|scia |per |le |ce|po|
cre|det|ti |son |cre|det|to |ma|no a |que|sta|
non |fos|se |già |mai |non |fos|se |be|ne|po|
                                                                                                                                                                   
 ma |per|ché |la |par|la|gri|da|re |sciol|se|
né |vi|sï|a |lui |che |son |so|la |ce|sa|
ma |cre|do |che |san|za |più |ol|tre |lu|me|
e |se |già |per |ma|gi|mai |non |vuol |cui |si |do|
so|
per |lo |mon|do |per |chi |mar|gi|ra|
co|me ’l |dì |e |io |ca|gion |del |suo |so|gna|
                                                                                                                                                                    
 e |se |pos|sen|ten|de|re in |ca|ro |spi|ra|
per |ch’ io |cor|so |cor|po |che |son |que|sta |gen|te|
so|pra |lo|ro e |san|za |sua |fe|sta|to|
e |que|sta |gen|te |mia |na|tu|ra |me|co |pro|fon|
con |que|sta |par|te |mia |me|mo|stra |sca|la|
e |co|me |con|ve|lo|co |che |ti |mon|chi|
                                                                                                                                                                   
 non |pur |co|me |ten|za |mia |fos|ser |ton|do|
co|me |lu|ce |tut|to |son |be|a|to|sto|
e |io |son |fat|to |là |do|ve ’l |sol |do|mo|
 per |le |mie |suo|na|sce|re |che |si |di|scer|na|
non |vi |ben |far |ma |per |a|to |di|let|to|
ma |per|ché |la |mia |don|na |ch’ è |più |leg|ge|
                                                                                                                                                                   
 per |ch’ io |mi |ce|le|bran|di|scer|no |rat|to|
sì |che |mi |le|rò |mal |può |dir |li |spe|si|
che |tut|ti |fa |di |dio |e |io |ap|pres|so|
 e |la |te|sta |ca|gion |che |cia|scu|na |vo|le|
in|co|me |d’ e|sto |tut|to |fu |me|mo|re|
co|sì |l’ al|tra |vol|to |tut|to |so|spe|so|
                                                                                                                                                                   
 e |io |a |la |par|la|gri|ma |sua |pro|re|
co|me |fa |don|na |sen |va |fiam|ma |so|
e |io |fui |fu |co|nob|bi |tut|ta |co|ro|ne|
e |cia|scu|na |ve|nim|mo e |io |in|ten|der |cer|ti|
con |le |gen|do|ve |co|stui |con|su|per|so|
che |mi |vol|se |quei |che |per |la |di|ser|mo|
                                                                                                                                                                   
 per |ch’ io |dis|si |può |dir |com’ |io |in|veg|gia|
e |io |vi|d’ io |par|lar |tut|to |be|ni|mo|
e |io |a|ves|si |quan|to |per |lo |stre|mo|
 cre|det|te|si |le|va |per |lor |che |si |puo|te|
cre|det|to |di |tut|ti |di |me |va|net|ta|
che |so|ma |sap|pi |ch’ i’ |non |son |so|gna|
                                                                                                                                                                    
 mo|stra|va |co|me |ma|li|be|ri |lu|ce|
per |ch’ io |vo |per |me |tut|to |pos|sie|cen|no|
e |per|ché |non |cre|det|ti |mol|ti |lu|ce|
 là |do|ve |per|so|pra |ru|gia |fu |sì |rat|to|
fu |tut|to |d’ e|sto |d’ e|sto |le|da |ma|no|
che |due |so|pra |del |tuo |vel|la |di|man|to|
                                                                                                                                                                   
 non |si |la|det|to |fu |tut|te |fu |ma|no|
e |io |cre|det|to |mi |fia |com|bat|te|ste|
che |da |me |fa|ma |per|ché |mi |con|fa|mo|
 e |non |son |na|scon|ce |che |so|pra |de|spet|to|
or |tu |vuo’ |sa|ran |so|vra |quel|la |ri|ma|
ma |dim|mi |chi |se’ |sì |ch’ io |t’ in|ten|de|gna|
                                                                                                                                                                   
 co|me |la |te|sta |gen|te |fos|se in |i|ma|
per |ch’ io |ma|ra|vi|sco|glio |qui |si |tro|
e |quin|di |te |già |mai |pren|den|tro |vo |su|ma|
e |qual |è |co|lui |con |es|ser |tut|to |con |que|sta?|
con |que|sta |par|la|men|te |mal |vo|ce |chio|
e |co|sì |mal |che |ve|nìa |sì |pro|que|sto|
                                                                                                                                                                   
 non |pur |a |lui |che |la |mi|li|ce |scu|no|
e |tu |ve|drai |lu|ce |lu|ce |lu|cen|no|
son |di|nan|zi a |me |con|tra|co|me |mi|no|
 per |ma|gna|la |mia |con |pe|cre|det|te a|mo|va|
per |ch’ io |pos|se|gnor |mio |ma|e|stro |mon|ti|
con |el|gna|va|
per |tut|to |so|a|va|
                                                                                                                                                                   
 che |già |le|va|re a |cor|po |di|sco|cen|ti|
per |ch’ io |pos|si|mi |fe|c’ io |per |ma|ria|
e |io |a |dir |se |che |tut|te |fa|vel|li|
in|co|me ’l |sol |non |cre|den|tro a |sua |di|sde|mo|
tra|
vo|lon|ta|cer |se |ch’ i’ |o|gne |par|te|
mo|ve |bea|tri|ce |tut|ti |que|sto |mo|mo|
                                                                                                                                                                   
 mo|stra|va |per |man|dar |per |tan|to |ca|me|
mo|strar|si |co|min|ciò |el|la |si |mo|stra|
e |poi |co|me |la |fu |ma|gi|ne |mo|me|
e |non |è |se |que|sta |ma|la |ve|de|stra |val|ce|
ma|te|sta |vi|ta |che |son |na|scon|cia |non |
ma |se |non |dis|s’ io |non |per |al|cun |pria |so|
                                                                                                                                                                   
 ma |per|ch’ io |for|ma |per |la |fa|cea |spe|ra|
tu |se’ |que|sto |cie|co |per |più |to|sto |fon|do|
e |io |per |man|co |per |ve|der |cu|ra|

epoch lasted: 520.4750182628632
(1900, 128)
Epoch 1 Batch 0 Loss 0.3848 Accuracy 0.9120
discarded batch 16
Epoch 1 Batch 50 Loss 0.3255 Accuracy 0.9194
Epoch 1 Batch 100 Loss 0.3306 Accuracy 0.9186
Epoch 1 Batch 150 Loss 0.3343 Accuracy 0.9182
Epoch 1 Batch 200 Loss 0.3318 Accuracy 0.9186
Epoch 1 Batch 250 Loss 0.3349 Accuracy 0.9182
Epoch 1 Batch 300 Loss 0.3372 Accuracy 0.9178
Epoch 1 Batch 350 Loss 0.3375 Accuracy 0.9177
Epoch 1 Batch 400 Loss 0.3389 Accuracy 0.9174
Epoch 1 Batch 450 Loss 0.3410 Accuracy 0.9168
Epoch 1 Batch 500 Loss 0.3429 Accuracy 0.9166
Epoch 1 Batch 550 Loss 0.3443 Accuracy 0.9164
Epoch 1 Batch 600 Loss 0.3452 Accuracy 0.9161
Epoch 1 Batch 650 Loss 0.3462 Accuracy 0.9158
Epoch 1 Batch 700 Loss 0.3473 Accuracy 0.9156
Epoch 1 Batch 750 Loss 0.3485 Accuracy 0.9154
Epoch 1 Batch 800 Loss 0.3491 Accuracy 0.9153
Epoch 1 Batch 850 Loss 0.3503 Accuracy 0.9151
Epoch 1 Batch 900 Loss 0.3508 Accuracy 0.9150
Epoch 1 Batch 950 Loss 0.3515 Accuracy 0.9149
Epoch 1 Batch 1000 Loss 0.3523 Accuracy 0.9148
Epoch 1 Batch 1050 Loss 0.3531 Accuracy 0.9146
Epoch 1 Batch 1100 Loss 0.3538 Accuracy 0.9145
Epoch 1 Batch 1150 Loss 0.3544 Accuracy 0.9144
Epoch 1 Batch 1200 Loss 0.3551 Accuracy 0.9142
Epoch 1 Batch 1250 Loss 0.3562 Accuracy 0.9141
Epoch 1 Batch 1300 Loss 0.3569 Accuracy 0.9139
Epoch 1 Batch 1350 Loss 0.3577 Accuracy 0.9138
Epoch 1 Batch 1400 Loss 0.3585 Accuracy 0.9136
Epoch 1 Batch 1450 Loss 0.3592 Accuracy 0.9135
Epoch 1 Batch 1500 Loss 0.3598 Accuracy 0.9134

wandb: WARNING Step must only increase in log calls.  Step 1 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.36062992>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9133296>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 28; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8779804>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8637875>}.

Epoch 1 Loss 0.3606 Accuracy 0.9133
Time taken for 1 epoch: 35.98994278907776 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.8780 Accuracy 0.8638

epoch lasted: 36.147985219955444
Epoch 2 Batch 0 Loss 0.2986 Accuracy 0.9286
Epoch 2 Batch 50 Loss 0.3326 Accuracy 0.9179
Epoch 2 Batch 100 Loss 0.3281 Accuracy 0.9190
Epoch 2 Batch 150 Loss 0.3284 Accuracy 0.9187
Epoch 2 Batch 200 Loss 0.3321 Accuracy 0.9183
Epoch 2 Batch 250 Loss 0.3346 Accuracy 0.9178
Epoch 2 Batch 300 Loss 0.3366 Accuracy 0.9176
discarded batch 324
Epoch 2 Batch 350 Loss 0.3365 Accuracy 0.9174
Epoch 2 Batch 400 Loss 0.3360 Accuracy 0.9175
Epoch 2 Batch 450 Loss 0.3376 Accuracy 0.9171
Epoch 2 Batch 500 Loss 0.3392 Accuracy 0.9168
Epoch 2 Batch 550 Loss 0.3406 Accuracy 0.9167
Epoch 2 Batch 600 Loss 0.3413 Accuracy 0.9165
Epoch 2 Batch 650 Loss 0.3429 Accuracy 0.9164
Epoch 2 Batch 700 Loss 0.3441 Accuracy 0.9161
Epoch 2 Batch 750 Loss 0.3453 Accuracy 0.9160
Epoch 2 Batch 800 Loss 0.3458 Accuracy 0.9159
Epoch 2 Batch 850 Loss 0.3472 Accuracy 0.9157
Epoch 2 Batch 900 Loss 0.3477 Accuracy 0.9157
Epoch 2 Batch 950 Loss 0.3487 Accuracy 0.9155
Epoch 2 Batch 1000 Loss 0.3496 Accuracy 0.9153
Epoch 2 Batch 1050 Loss 0.3500 Accuracy 0.9153
Epoch 2 Batch 1100 Loss 0.3514 Accuracy 0.9150
Epoch 2 Batch 1150 Loss 0.3527 Accuracy 0.9148
Epoch 2 Batch 1200 Loss 0.3534 Accuracy 0.9147
Epoch 2 Batch 1250 Loss 0.3542 Accuracy 0.9146
Epoch 2 Batch 1300 Loss 0.3547 Accuracy 0.9145
Epoch 2 Batch 1350 Loss 0.3557 Accuracy 0.9144
Epoch 2 Batch 1400 Loss 0.3565 Accuracy 0.9142
Epoch 2 Batch 1450 Loss 0.3574 Accuracy 0.9140
Epoch 2 Batch 1500 Loss 0.3582 Accuracy 0.9139

wandb: WARNING Step must only increase in log calls.  Step 2 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35896602>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.913766>}.

Epoch 2 Loss 0.3590 Accuracy 0.9138
Time taken for 1 epoch: 35.90229368209839 secs

epoch lasted: 35.90669870376587
Epoch 3 Batch 0 Loss 0.3162 Accuracy 0.9153
Epoch 3 Batch 50 Loss 0.3332 Accuracy 0.9177
Epoch 3 Batch 100 Loss 0.3294 Accuracy 0.9183
Epoch 3 Batch 150 Loss 0.3318 Accuracy 0.9181
Epoch 3 Batch 200 Loss 0.3336 Accuracy 0.9176
Epoch 3 Batch 250 Loss 0.3336 Accuracy 0.9176
Epoch 3 Batch 300 Loss 0.3347 Accuracy 0.9173
Epoch 3 Batch 350 Loss 0.3352 Accuracy 0.9173
Epoch 3 Batch 400 Loss 0.3365 Accuracy 0.9173
Epoch 3 Batch 450 Loss 0.3374 Accuracy 0.9172
Epoch 3 Batch 500 Loss 0.3387 Accuracy 0.9169
Epoch 3 Batch 550 Loss 0.3401 Accuracy 0.9166
Epoch 3 Batch 600 Loss 0.3410 Accuracy 0.9164
Epoch 3 Batch 650 Loss 0.3421 Accuracy 0.9163
Epoch 3 Batch 700 Loss 0.3435 Accuracy 0.9160
Epoch 3 Batch 750 Loss 0.3452 Accuracy 0.9157
Epoch 3 Batch 800 Loss 0.3460 Accuracy 0.9156
Epoch 3 Batch 850 Loss 0.3471 Accuracy 0.9154
Epoch 3 Batch 900 Loss 0.3477 Accuracy 0.9153
Epoch 3 Batch 950 Loss 0.3486 Accuracy 0.9151
Epoch 3 Batch 1000 Loss 0.3495 Accuracy 0.9149
Epoch 3 Batch 1050 Loss 0.3506 Accuracy 0.9148
Epoch 3 Batch 1100 Loss 0.3515 Accuracy 0.9146
Epoch 3 Batch 1150 Loss 0.3524 Accuracy 0.9145
Epoch 3 Batch 1200 Loss 0.3533 Accuracy 0.9144
Epoch 3 Batch 1250 Loss 0.3541 Accuracy 0.9143
Epoch 3 Batch 1300 Loss 0.3547 Accuracy 0.9142
discarded batch 1341
Epoch 3 Batch 1350 Loss 0.3555 Accuracy 0.9140
Epoch 3 Batch 1400 Loss 0.3564 Accuracy 0.9139
Epoch 3 Batch 1450 Loss 0.3574 Accuracy 0.9137
Epoch 3 Batch 1500 Loss 0.3581 Accuracy 0.9137

wandb: WARNING Step must only increase in log calls.  Step 3 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.358782>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91352475>}.

Epoch 3 Loss 0.3588 Accuracy 0.9135
Time taken for 1 epoch: 35.7362060546875 secs

epoch lasted: 35.740915298461914
Epoch 4 Batch 0 Loss 0.3422 Accuracy 0.9153
Epoch 4 Batch 50 Loss 0.3248 Accuracy 0.9200
Epoch 4 Batch 100 Loss 0.3267 Accuracy 0.9190
Epoch 4 Batch 150 Loss 0.3312 Accuracy 0.9185
Epoch 4 Batch 200 Loss 0.3321 Accuracy 0.9189
Epoch 4 Batch 250 Loss 0.3325 Accuracy 0.9188
Epoch 4 Batch 300 Loss 0.3335 Accuracy 0.9185
Epoch 4 Batch 350 Loss 0.3340 Accuracy 0.9184
Epoch 4 Batch 400 Loss 0.3366 Accuracy 0.9178
Epoch 4 Batch 450 Loss 0.3376 Accuracy 0.9175
Epoch 4 Batch 500 Loss 0.3379 Accuracy 0.9175
Epoch 4 Batch 550 Loss 0.3399 Accuracy 0.9171
Epoch 4 Batch 600 Loss 0.3405 Accuracy 0.9170
discarded batch 650
Epoch 4 Batch 700 Loss 0.3430 Accuracy 0.9166
Epoch 4 Batch 750 Loss 0.3441 Accuracy 0.9164
Epoch 4 Batch 800 Loss 0.3453 Accuracy 0.9162
Epoch 4 Batch 850 Loss 0.3460 Accuracy 0.9161
Epoch 4 Batch 900 Loss 0.3468 Accuracy 0.9161
Epoch 4 Batch 950 Loss 0.3480 Accuracy 0.9159
Epoch 4 Batch 1000 Loss 0.3490 Accuracy 0.9157
Epoch 4 Batch 1050 Loss 0.3503 Accuracy 0.9155
Epoch 4 Batch 1100 Loss 0.3515 Accuracy 0.9153
Epoch 4 Batch 1150 Loss 0.3521 Accuracy 0.9150
Epoch 4 Batch 1200 Loss 0.3528 Accuracy 0.9149
Epoch 4 Batch 1250 Loss 0.3539 Accuracy 0.9147
Epoch 4 Batch 1300 Loss 0.3547 Accuracy 0.9145
Epoch 4 Batch 1350 Loss 0.3553 Accuracy 0.9144
Epoch 4 Batch 1400 Loss 0.3557 Accuracy 0.9143
Epoch 4 Batch 1450 Loss 0.3568 Accuracy 0.9141
Epoch 4 Batch 1500 Loss 0.3575 Accuracy 0.9140

wandb: WARNING Step must only increase in log calls.  Step 4 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3582962>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9139387>}.

Epoch 4 Loss 0.3583 Accuracy 0.9139
Time taken for 1 epoch: 35.96480679512024 secs

epoch lasted: 35.970885276794434
Epoch 5 Batch 0 Loss 0.2960 Accuracy 0.9419
Epoch 5 Batch 50 Loss 0.3242 Accuracy 0.9212
Epoch 5 Batch 100 Loss 0.3255 Accuracy 0.9208
Epoch 5 Batch 150 Loss 0.3290 Accuracy 0.9200
Epoch 5 Batch 200 Loss 0.3289 Accuracy 0.9199
Epoch 5 Batch 250 Loss 0.3319 Accuracy 0.9192
Epoch 5 Batch 300 Loss 0.3332 Accuracy 0.9189
Epoch 5 Batch 350 Loss 0.3336 Accuracy 0.9186
Epoch 5 Batch 400 Loss 0.3356 Accuracy 0.9182
Epoch 5 Batch 450 Loss 0.3371 Accuracy 0.9179
Epoch 5 Batch 500 Loss 0.3380 Accuracy 0.9177
Epoch 5 Batch 550 Loss 0.3396 Accuracy 0.9173
Epoch 5 Batch 600 Loss 0.3406 Accuracy 0.9171
Epoch 5 Batch 650 Loss 0.3417 Accuracy 0.9169
Epoch 5 Batch 700 Loss 0.3427 Accuracy 0.9169
Epoch 5 Batch 750 Loss 0.3443 Accuracy 0.9165
Epoch 5 Batch 800 Loss 0.3453 Accuracy 0.9164
Epoch 5 Batch 850 Loss 0.3463 Accuracy 0.9163
Epoch 5 Batch 900 Loss 0.3469 Accuracy 0.9162
Epoch 5 Batch 950 Loss 0.3473 Accuracy 0.9160
Epoch 5 Batch 1000 Loss 0.3484 Accuracy 0.9158
Epoch 5 Batch 1050 Loss 0.3494 Accuracy 0.9157
Epoch 5 Batch 1100 Loss 0.3507 Accuracy 0.9154
Epoch 5 Batch 1150 Loss 0.3515 Accuracy 0.9152
Epoch 5 Batch 1200 Loss 0.3522 Accuracy 0.9151
Epoch 5 Batch 1250 Loss 0.3529 Accuracy 0.9149
Epoch 5 Batch 1300 Loss 0.3539 Accuracy 0.9148
discarded batch 1309
Epoch 5 Batch 1350 Loss 0.3548 Accuracy 0.9146
Epoch 5 Batch 1400 Loss 0.3553 Accuracy 0.9146
Epoch 5 Batch 1450 Loss 0.3561 Accuracy 0.9144
Epoch 5 Batch 1500 Loss 0.3568 Accuracy 0.9143

wandb: WARNING Step must only increase in log calls.  Step 5 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35735214>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9142143>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-29
Epoch 5 Loss 0.3574 Accuracy 0.9142
Time taken for 1 epoch: 35.94341015815735 secs

epoch lasted: 35.94788193702698
Epoch 6 Batch 0 Loss 0.2994 Accuracy 0.9269
Epoch 6 Batch 50 Loss 0.3236 Accuracy 0.9225
Epoch 6 Batch 100 Loss 0.3332 Accuracy 0.9191
Epoch 6 Batch 150 Loss 0.3317 Accuracy 0.9190
Epoch 6 Batch 200 Loss 0.3319 Accuracy 0.9186
Epoch 6 Batch 250 Loss 0.3331 Accuracy 0.9185
Epoch 6 Batch 300 Loss 0.3354 Accuracy 0.9181
Epoch 6 Batch 350 Loss 0.3358 Accuracy 0.9179
Epoch 6 Batch 400 Loss 0.3360 Accuracy 0.9178
Epoch 6 Batch 450 Loss 0.3370 Accuracy 0.9175
Epoch 6 Batch 500 Loss 0.3382 Accuracy 0.9173
Epoch 6 Batch 550 Loss 0.3396 Accuracy 0.9172
Epoch 6 Batch 600 Loss 0.3405 Accuracy 0.9170
Epoch 6 Batch 650 Loss 0.3423 Accuracy 0.9167
Epoch 6 Batch 700 Loss 0.3438 Accuracy 0.9164
Epoch 6 Batch 750 Loss 0.3446 Accuracy 0.9161
Epoch 6 Batch 800 Loss 0.3452 Accuracy 0.9160
Epoch 6 Batch 850 Loss 0.3464 Accuracy 0.9158
Epoch 6 Batch 900 Loss 0.3473 Accuracy 0.9157
Epoch 6 Batch 950 Loss 0.3485 Accuracy 0.9154
Epoch 6 Batch 1000 Loss 0.3490 Accuracy 0.9154
Epoch 6 Batch 1050 Loss 0.3496 Accuracy 0.9153
Epoch 6 Batch 1100 Loss 0.3504 Accuracy 0.9152
Epoch 6 Batch 1150 Loss 0.3514 Accuracy 0.9150
Epoch 6 Batch 1200 Loss 0.3521 Accuracy 0.9148
discarded batch 1244
Epoch 6 Batch 1250 Loss 0.3527 Accuracy 0.9147
Epoch 6 Batch 1300 Loss 0.3532 Accuracy 0.9147
Epoch 6 Batch 1350 Loss 0.3539 Accuracy 0.9146
Epoch 6 Batch 1400 Loss 0.3543 Accuracy 0.9145
Epoch 6 Batch 1450 Loss 0.3549 Accuracy 0.9144
Epoch 6 Batch 1500 Loss 0.3556 Accuracy 0.9142

wandb: WARNING Step must only increase in log calls.  Step 6 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35624483>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.914121>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 28; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8790008>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8650055>}.

Epoch 6 Loss 0.3562 Accuracy 0.9141
Time taken for 1 epoch: 35.80878233909607 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.8790 Accuracy 0.8650

epoch lasted: 35.964860677719116
Epoch 7 Batch 0 Loss 0.2992 Accuracy 0.9153
Epoch 7 Batch 50 Loss 0.3260 Accuracy 0.9188
Epoch 7 Batch 100 Loss 0.3263 Accuracy 0.9187
Epoch 7 Batch 150 Loss 0.3291 Accuracy 0.9185
Epoch 7 Batch 200 Loss 0.3290 Accuracy 0.9186
Epoch 7 Batch 250 Loss 0.3313 Accuracy 0.9181
Epoch 7 Batch 300 Loss 0.3337 Accuracy 0.9178
Epoch 7 Batch 350 Loss 0.3346 Accuracy 0.9177
Epoch 7 Batch 400 Loss 0.3356 Accuracy 0.9176
Epoch 7 Batch 450 Loss 0.3371 Accuracy 0.9172
Epoch 7 Batch 500 Loss 0.3381 Accuracy 0.9169
Epoch 7 Batch 550 Loss 0.3388 Accuracy 0.9169
Epoch 7 Batch 600 Loss 0.3404 Accuracy 0.9166
Epoch 7 Batch 650 Loss 0.3416 Accuracy 0.9164
Epoch 7 Batch 700 Loss 0.3426 Accuracy 0.9162
Epoch 7 Batch 750 Loss 0.3437 Accuracy 0.9161
Epoch 7 Batch 800 Loss 0.3440 Accuracy 0.9161
Epoch 7 Batch 850 Loss 0.3447 Accuracy 0.9160
Epoch 7 Batch 900 Loss 0.3455 Accuracy 0.9159
Epoch 7 Batch 950 Loss 0.3466 Accuracy 0.9157
Epoch 7 Batch 1000 Loss 0.3475 Accuracy 0.9155
discarded batch 1048
Epoch 7 Batch 1050 Loss 0.3483 Accuracy 0.9154
Epoch 7 Batch 1100 Loss 0.3490 Accuracy 0.9152
Epoch 7 Batch 1150 Loss 0.3496 Accuracy 0.9151
Epoch 7 Batch 1200 Loss 0.3503 Accuracy 0.9150
Epoch 7 Batch 1250 Loss 0.3510 Accuracy 0.9148
Epoch 7 Batch 1300 Loss 0.3520 Accuracy 0.9147
Epoch 7 Batch 1350 Loss 0.3526 Accuracy 0.9145
Epoch 7 Batch 1400 Loss 0.3533 Accuracy 0.9144
Epoch 7 Batch 1450 Loss 0.3541 Accuracy 0.9144
Epoch 7 Batch 1500 Loss 0.3550 Accuracy 0.9142

wandb: WARNING Step must only increase in log calls.  Step 7 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3553285>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9141564>}.

Epoch 7 Loss 0.3553 Accuracy 0.9142
Time taken for 1 epoch: 35.76402997970581 secs

epoch lasted: 35.768096685409546
Epoch 8 Batch 0 Loss 0.2972 Accuracy 0.9236
Epoch 8 Batch 50 Loss 0.3309 Accuracy 0.9193
Epoch 8 Batch 100 Loss 0.3266 Accuracy 0.9205
Epoch 8 Batch 150 Loss 0.3271 Accuracy 0.9200
Epoch 8 Batch 200 Loss 0.3286 Accuracy 0.9192
Epoch 8 Batch 250 Loss 0.3293 Accuracy 0.9191
Epoch 8 Batch 300 Loss 0.3304 Accuracy 0.9187
Epoch 8 Batch 350 Loss 0.3320 Accuracy 0.9183
Epoch 8 Batch 400 Loss 0.3330 Accuracy 0.9183
Epoch 8 Batch 450 Loss 0.3335 Accuracy 0.9182
Epoch 8 Batch 500 Loss 0.3345 Accuracy 0.9180
Epoch 8 Batch 550 Loss 0.3354 Accuracy 0.9179
Epoch 8 Batch 600 Loss 0.3367 Accuracy 0.9177
Epoch 8 Batch 650 Loss 0.3373 Accuracy 0.9175
Epoch 8 Batch 700 Loss 0.3385 Accuracy 0.9172
Epoch 8 Batch 750 Loss 0.3392 Accuracy 0.9172
Epoch 8 Batch 800 Loss 0.3401 Accuracy 0.9170
Epoch 8 Batch 850 Loss 0.3413 Accuracy 0.9168
Epoch 8 Batch 900 Loss 0.3424 Accuracy 0.9165
Epoch 8 Batch 950 Loss 0.3436 Accuracy 0.9163
Epoch 8 Batch 1000 Loss 0.3449 Accuracy 0.9162
Epoch 8 Batch 1050 Loss 0.3457 Accuracy 0.9161
Epoch 8 Batch 1100 Loss 0.3469 Accuracy 0.9158
Epoch 8 Batch 1150 Loss 0.3480 Accuracy 0.9156
Epoch 8 Batch 1200 Loss 0.3482 Accuracy 0.9156
Epoch 8 Batch 1250 Loss 0.3490 Accuracy 0.9155
Epoch 8 Batch 1300 Loss 0.3499 Accuracy 0.9153
Epoch 8 Batch 1350 Loss 0.3508 Accuracy 0.9152
Epoch 8 Batch 1400 Loss 0.3514 Accuracy 0.9151
discarded batch 1417
Epoch 8 Batch 1450 Loss 0.3520 Accuracy 0.9150
Epoch 8 Batch 1500 Loss 0.3531 Accuracy 0.9148

wandb: WARNING Step must only increase in log calls.  Step 8 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35381228>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9146808>}.

Epoch 8 Loss 0.3538 Accuracy 0.9147
Time taken for 1 epoch: 35.84205508232117 secs

epoch lasted: 35.846293449401855
Epoch 9 Batch 0 Loss 0.3126 Accuracy 0.9169
Epoch 9 Batch 50 Loss 0.3172 Accuracy 0.9210
Epoch 9 Batch 100 Loss 0.3254 Accuracy 0.9187
Epoch 9 Batch 150 Loss 0.3279 Accuracy 0.9185
Epoch 9 Batch 200 Loss 0.3291 Accuracy 0.9181
Epoch 9 Batch 250 Loss 0.3302 Accuracy 0.9179
Epoch 9 Batch 300 Loss 0.3304 Accuracy 0.9181
Epoch 9 Batch 350 Loss 0.3319 Accuracy 0.9179
Epoch 9 Batch 400 Loss 0.3342 Accuracy 0.9176
Epoch 9 Batch 450 Loss 0.3350 Accuracy 0.9176
Epoch 9 Batch 500 Loss 0.3360 Accuracy 0.9174
Epoch 9 Batch 550 Loss 0.3375 Accuracy 0.9171
Epoch 9 Batch 600 Loss 0.3383 Accuracy 0.9170
Epoch 9 Batch 650 Loss 0.3398 Accuracy 0.9168
Epoch 9 Batch 700 Loss 0.3406 Accuracy 0.9167
Epoch 9 Batch 750 Loss 0.3414 Accuracy 0.9166
Epoch 9 Batch 800 Loss 0.3423 Accuracy 0.9164
Epoch 9 Batch 850 Loss 0.3436 Accuracy 0.9162
discarded batch 888
Epoch 9 Batch 900 Loss 0.3442 Accuracy 0.9160
Epoch 9 Batch 950 Loss 0.3447 Accuracy 0.9159
Epoch 9 Batch 1000 Loss 0.3456 Accuracy 0.9157
Epoch 9 Batch 1050 Loss 0.3465 Accuracy 0.9155
Epoch 9 Batch 1100 Loss 0.3473 Accuracy 0.9155
Epoch 9 Batch 1150 Loss 0.3480 Accuracy 0.9153
Epoch 9 Batch 1200 Loss 0.3487 Accuracy 0.9152
Epoch 9 Batch 1250 Loss 0.3495 Accuracy 0.9151
Epoch 9 Batch 1300 Loss 0.3506 Accuracy 0.9150
Epoch 9 Batch 1350 Loss 0.3514 Accuracy 0.9148
Epoch 9 Batch 1400 Loss 0.3521 Accuracy 0.9147
Epoch 9 Batch 1450 Loss 0.3526 Accuracy 0.9147
Epoch 9 Batch 1500 Loss 0.3534 Accuracy 0.9145

wandb: WARNING Step must only increase in log calls.  Step 9 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35419646>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9143773>}.

Epoch 9 Loss 0.3542 Accuracy 0.9144
Time taken for 1 epoch: 35.830509424209595 secs

epoch lasted: 35.83472681045532
Epoch 10 Batch 0 Loss 0.3136 Accuracy 0.9169
Epoch 10 Batch 50 Loss 0.3199 Accuracy 0.9186
Epoch 10 Batch 100 Loss 0.3218 Accuracy 0.9185
discarded batch 106
Epoch 10 Batch 150 Loss 0.3227 Accuracy 0.9191
Epoch 10 Batch 200 Loss 0.3269 Accuracy 0.9186
Epoch 10 Batch 250 Loss 0.3287 Accuracy 0.9183
Epoch 10 Batch 300 Loss 0.3291 Accuracy 0.9185
Epoch 10 Batch 350 Loss 0.3300 Accuracy 0.9184
Epoch 10 Batch 400 Loss 0.3315 Accuracy 0.9182
Epoch 10 Batch 450 Loss 0.3334 Accuracy 0.9180
Epoch 10 Batch 500 Loss 0.3341 Accuracy 0.9179
Epoch 10 Batch 550 Loss 0.3342 Accuracy 0.9177
Epoch 10 Batch 600 Loss 0.3354 Accuracy 0.9174
Epoch 10 Batch 650 Loss 0.3369 Accuracy 0.9173
Epoch 10 Batch 700 Loss 0.3383 Accuracy 0.9171
Epoch 10 Batch 750 Loss 0.3388 Accuracy 0.9170
Epoch 10 Batch 800 Loss 0.3400 Accuracy 0.9169
Epoch 10 Batch 850 Loss 0.3407 Accuracy 0.9167
Epoch 10 Batch 900 Loss 0.3416 Accuracy 0.9166
Epoch 10 Batch 950 Loss 0.3423 Accuracy 0.9164
Epoch 10 Batch 1000 Loss 0.3430 Accuracy 0.9162
Epoch 10 Batch 1050 Loss 0.3436 Accuracy 0.9160
Epoch 10 Batch 1100 Loss 0.3448 Accuracy 0.9159
Epoch 10 Batch 1150 Loss 0.3457 Accuracy 0.9158
Epoch 10 Batch 1200 Loss 0.3465 Accuracy 0.9156
Epoch 10 Batch 1250 Loss 0.3474 Accuracy 0.9155
Epoch 10 Batch 1300 Loss 0.3480 Accuracy 0.9154
Epoch 10 Batch 1350 Loss 0.3486 Accuracy 0.9154
Epoch 10 Batch 1400 Loss 0.3495 Accuracy 0.9152
Epoch 10 Batch 1450 Loss 0.3501 Accuracy 0.9151
Epoch 10 Batch 1500 Loss 0.3510 Accuracy 0.9150

wandb: WARNING Step must only increase in log calls.  Step 10 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35152003>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9148899>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-30
Epoch 10 Loss 0.3515 Accuracy 0.9149
Time taken for 1 epoch: 36.0784809589386 secs

epoch lasted: 36.082563161849976
Epoch 11 Batch 0 Loss 0.2921 Accuracy 0.9269
discarded batch 39
Epoch 11 Batch 50 Loss 0.3218 Accuracy 0.9202
Epoch 11 Batch 100 Loss 0.3229 Accuracy 0.9202
Epoch 11 Batch 150 Loss 0.3225 Accuracy 0.9200
Epoch 11 Batch 200 Loss 0.3252 Accuracy 0.9195
Epoch 11 Batch 250 Loss 0.3278 Accuracy 0.9188
Epoch 11 Batch 300 Loss 0.3290 Accuracy 0.9188
Epoch 11 Batch 350 Loss 0.3301 Accuracy 0.9187
Epoch 11 Batch 400 Loss 0.3317 Accuracy 0.9183
Epoch 11 Batch 450 Loss 0.3330 Accuracy 0.9182
Epoch 11 Batch 500 Loss 0.3337 Accuracy 0.9181
Epoch 11 Batch 550 Loss 0.3347 Accuracy 0.9179
Epoch 11 Batch 600 Loss 0.3355 Accuracy 0.9177
Epoch 11 Batch 650 Loss 0.3371 Accuracy 0.9175
Epoch 11 Batch 700 Loss 0.3391 Accuracy 0.9172
Epoch 11 Batch 750 Loss 0.3402 Accuracy 0.9169
Epoch 11 Batch 800 Loss 0.3412 Accuracy 0.9167
Epoch 11 Batch 850 Loss 0.3417 Accuracy 0.9166
Epoch 11 Batch 900 Loss 0.3423 Accuracy 0.9165
Epoch 11 Batch 950 Loss 0.3430 Accuracy 0.9164
Epoch 11 Batch 1000 Loss 0.3439 Accuracy 0.9162
Epoch 11 Batch 1050 Loss 0.3448 Accuracy 0.9161
Epoch 11 Batch 1100 Loss 0.3457 Accuracy 0.9159
Epoch 11 Batch 1150 Loss 0.3464 Accuracy 0.9158
Epoch 11 Batch 1200 Loss 0.3471 Accuracy 0.9157
Epoch 11 Batch 1250 Loss 0.3478 Accuracy 0.9155
Epoch 11 Batch 1300 Loss 0.3486 Accuracy 0.9154
Epoch 11 Batch 1350 Loss 0.3492 Accuracy 0.9154
Epoch 11 Batch 1400 Loss 0.3499 Accuracy 0.9152
Epoch 11 Batch 1450 Loss 0.3505 Accuracy 0.9151
Epoch 11 Batch 1500 Loss 0.3516 Accuracy 0.9149

wandb: WARNING Step must only increase in log calls.  Step 11 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3525097>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9147569>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 28; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.88797003>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86268014>}.

Epoch 11 Loss 0.3525 Accuracy 0.9148
Time taken for 1 epoch: 35.834962606430054 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.8880 Accuracy 0.8627

epoch lasted: 35.99071025848389
Epoch 12 Batch 0 Loss 0.3074 Accuracy 0.9236
Epoch 12 Batch 50 Loss 0.3176 Accuracy 0.9185
discarded batch 94
Epoch 12 Batch 100 Loss 0.3177 Accuracy 0.9195
Epoch 12 Batch 150 Loss 0.3200 Accuracy 0.9187
Epoch 12 Batch 200 Loss 0.3218 Accuracy 0.9189
Epoch 12 Batch 250 Loss 0.3225 Accuracy 0.9190
Epoch 12 Batch 300 Loss 0.3237 Accuracy 0.9191
Epoch 12 Batch 350 Loss 0.3260 Accuracy 0.9184
Epoch 12 Batch 400 Loss 0.3282 Accuracy 0.9182
Epoch 12 Batch 450 Loss 0.3305 Accuracy 0.9179
Epoch 12 Batch 500 Loss 0.3318 Accuracy 0.9177
Epoch 12 Batch 550 Loss 0.3332 Accuracy 0.9176
Epoch 12 Batch 600 Loss 0.3342 Accuracy 0.9174
Epoch 12 Batch 650 Loss 0.3352 Accuracy 0.9173
Epoch 12 Batch 700 Loss 0.3359 Accuracy 0.9173
Epoch 12 Batch 750 Loss 0.3376 Accuracy 0.9170
Epoch 12 Batch 800 Loss 0.3390 Accuracy 0.9168
Epoch 12 Batch 850 Loss 0.3399 Accuracy 0.9167
Epoch 12 Batch 900 Loss 0.3403 Accuracy 0.9168
Epoch 12 Batch 950 Loss 0.3419 Accuracy 0.9165
Epoch 12 Batch 1000 Loss 0.3429 Accuracy 0.9164
Epoch 12 Batch 1050 Loss 0.3437 Accuracy 0.9162
Epoch 12 Batch 1100 Loss 0.3447 Accuracy 0.9161
Epoch 12 Batch 1150 Loss 0.3454 Accuracy 0.9160
Epoch 12 Batch 1200 Loss 0.3464 Accuracy 0.9158
Epoch 12 Batch 1250 Loss 0.3472 Accuracy 0.9157
Epoch 12 Batch 1300 Loss 0.3484 Accuracy 0.9156
Epoch 12 Batch 1350 Loss 0.3491 Accuracy 0.9155
Epoch 12 Batch 1400 Loss 0.3500 Accuracy 0.9153
Epoch 12 Batch 1450 Loss 0.3506 Accuracy 0.9152
Epoch 12 Batch 1500 Loss 0.3516 Accuracy 0.9150

wandb: WARNING Step must only increase in log calls.  Step 12 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35254934>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91485345>}.

Epoch 12 Loss 0.3525 Accuracy 0.9149
Time taken for 1 epoch: 36.34899353981018 secs

epoch lasted: 36.353230476379395
Epoch 13 Batch 0 Loss 0.3350 Accuracy 0.9053
Epoch 13 Batch 50 Loss 0.3101 Accuracy 0.9226
Epoch 13 Batch 100 Loss 0.3143 Accuracy 0.9215
Epoch 13 Batch 150 Loss 0.3177 Accuracy 0.9207
Epoch 13 Batch 200 Loss 0.3188 Accuracy 0.9209
Epoch 13 Batch 250 Loss 0.3217 Accuracy 0.9200
Epoch 13 Batch 300 Loss 0.3230 Accuracy 0.9197
Epoch 13 Batch 350 Loss 0.3245 Accuracy 0.9195
Epoch 13 Batch 400 Loss 0.3252 Accuracy 0.9194
Epoch 13 Batch 450 Loss 0.3261 Accuracy 0.9192
Epoch 13 Batch 500 Loss 0.3286 Accuracy 0.9188
Epoch 13 Batch 550 Loss 0.3309 Accuracy 0.9185
Epoch 13 Batch 600 Loss 0.3326 Accuracy 0.9184
Epoch 13 Batch 650 Loss 0.3338 Accuracy 0.9181
Epoch 13 Batch 700 Loss 0.3353 Accuracy 0.9179
Epoch 13 Batch 750 Loss 0.3366 Accuracy 0.9176
Epoch 13 Batch 800 Loss 0.3379 Accuracy 0.9172
Epoch 13 Batch 850 Loss 0.3389 Accuracy 0.9170
Epoch 13 Batch 900 Loss 0.3400 Accuracy 0.9168
Epoch 13 Batch 950 Loss 0.3408 Accuracy 0.9167
Epoch 13 Batch 1000 Loss 0.3418 Accuracy 0.9166
Epoch 13 Batch 1050 Loss 0.3428 Accuracy 0.9163
Epoch 13 Batch 1100 Loss 0.3440 Accuracy 0.9161
Epoch 13 Batch 1150 Loss 0.3448 Accuracy 0.9160
Epoch 13 Batch 1200 Loss 0.3455 Accuracy 0.9159
Epoch 13 Batch 1250 Loss 0.3465 Accuracy 0.9157
Epoch 13 Batch 1300 Loss 0.3472 Accuracy 0.9156
Epoch 13 Batch 1350 Loss 0.3477 Accuracy 0.9155
Epoch 13 Batch 1400 Loss 0.3486 Accuracy 0.9154
Epoch 13 Batch 1450 Loss 0.3495 Accuracy 0.9153
Epoch 13 Batch 1500 Loss 0.3505 Accuracy 0.9151
discarded batch 1521

wandb: WARNING Step must only increase in log calls.  Step 13 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35112596>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9149607>}.

Epoch 13 Loss 0.3511 Accuracy 0.9150
Time taken for 1 epoch: 36.67253518104553 secs

epoch lasted: 36.67702317237854
Epoch 14 Batch 0 Loss 0.3824 Accuracy 0.8970
Epoch 14 Batch 50 Loss 0.3122 Accuracy 0.9216
Epoch 14 Batch 100 Loss 0.3144 Accuracy 0.9215
Epoch 14 Batch 150 Loss 0.3167 Accuracy 0.9216
Epoch 14 Batch 200 Loss 0.3187 Accuracy 0.9208
Epoch 14 Batch 250 Loss 0.3210 Accuracy 0.9206
Epoch 14 Batch 300 Loss 0.3240 Accuracy 0.9200
Epoch 14 Batch 350 Loss 0.3263 Accuracy 0.9194
discarded batch 366
Epoch 14 Batch 400 Loss 0.3284 Accuracy 0.9192
Epoch 14 Batch 450 Loss 0.3291 Accuracy 0.9190
Epoch 14 Batch 500 Loss 0.3312 Accuracy 0.9186
Epoch 14 Batch 550 Loss 0.3326 Accuracy 0.9184
Epoch 14 Batch 600 Loss 0.3332 Accuracy 0.9182
Epoch 14 Batch 650 Loss 0.3341 Accuracy 0.9179
Epoch 14 Batch 700 Loss 0.3348 Accuracy 0.9178
Epoch 14 Batch 750 Loss 0.3358 Accuracy 0.9176
Epoch 14 Batch 800 Loss 0.3373 Accuracy 0.9174
Epoch 14 Batch 850 Loss 0.3389 Accuracy 0.9171
Epoch 14 Batch 900 Loss 0.3399 Accuracy 0.9169
Epoch 14 Batch 950 Loss 0.3408 Accuracy 0.9167
Epoch 14 Batch 1000 Loss 0.3417 Accuracy 0.9165
Epoch 14 Batch 1050 Loss 0.3424 Accuracy 0.9164
Epoch 14 Batch 1100 Loss 0.3432 Accuracy 0.9163
Epoch 14 Batch 1150 Loss 0.3442 Accuracy 0.9160
Epoch 14 Batch 1200 Loss 0.3447 Accuracy 0.9159
Epoch 14 Batch 1250 Loss 0.3456 Accuracy 0.9158
Epoch 14 Batch 1300 Loss 0.3463 Accuracy 0.9157
Epoch 14 Batch 1350 Loss 0.3471 Accuracy 0.9156
Epoch 14 Batch 1400 Loss 0.3482 Accuracy 0.9154
Epoch 14 Batch 1450 Loss 0.3488 Accuracy 0.9154
Epoch 14 Batch 1500 Loss 0.3494 Accuracy 0.9153

wandb: WARNING Step must only increase in log calls.  Step 14 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.35012037>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91513014>}.

Epoch 14 Loss 0.3501 Accuracy 0.9151
Time taken for 1 epoch: 35.942054271698 secs

epoch lasted: 35.946611404418945
Epoch 15 Batch 0 Loss 0.2996 Accuracy 0.9236
Epoch 15 Batch 50 Loss 0.3150 Accuracy 0.9220
discarded batch 52
Epoch 15 Batch 100 Loss 0.3185 Accuracy 0.9207
Epoch 15 Batch 150 Loss 0.3200 Accuracy 0.9201
Epoch 15 Batch 200 Loss 0.3224 Accuracy 0.9193
Epoch 15 Batch 250 Loss 0.3230 Accuracy 0.9193
Epoch 15 Batch 300 Loss 0.3238 Accuracy 0.9195
Epoch 15 Batch 350 Loss 0.3260 Accuracy 0.9192
Epoch 15 Batch 400 Loss 0.3269 Accuracy 0.9191
Epoch 15 Batch 450 Loss 0.3276 Accuracy 0.9189
Epoch 15 Batch 500 Loss 0.3284 Accuracy 0.9189
Epoch 15 Batch 550 Loss 0.3305 Accuracy 0.9185
Epoch 15 Batch 600 Loss 0.3318 Accuracy 0.9183
Epoch 15 Batch 650 Loss 0.3332 Accuracy 0.9181
Epoch 15 Batch 700 Loss 0.3349 Accuracy 0.9177
Epoch 15 Batch 750 Loss 0.3362 Accuracy 0.9175
Epoch 15 Batch 800 Loss 0.3374 Accuracy 0.9173
Epoch 15 Batch 850 Loss 0.3384 Accuracy 0.9170
Epoch 15 Batch 900 Loss 0.3394 Accuracy 0.9168
Epoch 15 Batch 950 Loss 0.3398 Accuracy 0.9167
Epoch 15 Batch 1000 Loss 0.3410 Accuracy 0.9165
Epoch 15 Batch 1050 Loss 0.3420 Accuracy 0.9163
Epoch 15 Batch 1100 Loss 0.3428 Accuracy 0.9162
Epoch 15 Batch 1150 Loss 0.3439 Accuracy 0.9160
Epoch 15 Batch 1200 Loss 0.3447 Accuracy 0.9159
Epoch 15 Batch 1250 Loss 0.3454 Accuracy 0.9158
Epoch 15 Batch 1300 Loss 0.3461 Accuracy 0.9157
Epoch 15 Batch 1350 Loss 0.3469 Accuracy 0.9155
Epoch 15 Batch 1400 Loss 0.3475 Accuracy 0.9154
Epoch 15 Batch 1450 Loss 0.3481 Accuracy 0.9153
Epoch 15 Batch 1500 Loss 0.3487 Accuracy 0.9153

wandb: WARNING Step must only increase in log calls.  Step 15 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34941906>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9151655>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-31
Epoch 15 Loss 0.3494 Accuracy 0.9152
Time taken for 1 epoch: 36.1329083442688 secs

epoch lasted: 36.137033462524414
Epoch 16 Batch 0 Loss 0.2876 Accuracy 0.9286
Epoch 16 Batch 50 Loss 0.3010 Accuracy 0.9245
Epoch 16 Batch 100 Loss 0.3110 Accuracy 0.9224
Epoch 16 Batch 150 Loss 0.3158 Accuracy 0.9215
Epoch 16 Batch 200 Loss 0.3181 Accuracy 0.9211
Epoch 16 Batch 250 Loss 0.3211 Accuracy 0.9203
Epoch 16 Batch 300 Loss 0.3243 Accuracy 0.9199
Epoch 16 Batch 350 Loss 0.3267 Accuracy 0.9191
Epoch 16 Batch 400 Loss 0.3290 Accuracy 0.9188
Epoch 16 Batch 450 Loss 0.3300 Accuracy 0.9187
Epoch 16 Batch 500 Loss 0.3312 Accuracy 0.9185
Epoch 16 Batch 550 Loss 0.3314 Accuracy 0.9184
Epoch 16 Batch 600 Loss 0.3316 Accuracy 0.9183
Epoch 16 Batch 650 Loss 0.3328 Accuracy 0.9181
Epoch 16 Batch 700 Loss 0.3330 Accuracy 0.9180
Epoch 16 Batch 750 Loss 0.3342 Accuracy 0.9178
discarded batch 759
Epoch 16 Batch 800 Loss 0.3350 Accuracy 0.9177
Epoch 16 Batch 850 Loss 0.3364 Accuracy 0.9174
Epoch 16 Batch 900 Loss 0.3377 Accuracy 0.9172
Epoch 16 Batch 950 Loss 0.3387 Accuracy 0.9171
Epoch 16 Batch 1000 Loss 0.3404 Accuracy 0.9167
Epoch 16 Batch 1050 Loss 0.3414 Accuracy 0.9166
Epoch 16 Batch 1100 Loss 0.3419 Accuracy 0.9165
Epoch 16 Batch 1150 Loss 0.3428 Accuracy 0.9164
Epoch 16 Batch 1200 Loss 0.3438 Accuracy 0.9162
Epoch 16 Batch 1250 Loss 0.3442 Accuracy 0.9161
Epoch 16 Batch 1300 Loss 0.3448 Accuracy 0.9160
Epoch 16 Batch 1350 Loss 0.3457 Accuracy 0.9159
Epoch 16 Batch 1400 Loss 0.3463 Accuracy 0.9158
Epoch 16 Batch 1450 Loss 0.3470 Accuracy 0.9157
Epoch 16 Batch 1500 Loss 0.3480 Accuracy 0.9156

wandb: WARNING Step must only increase in log calls.  Step 16 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3488591>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9153843>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 28; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.891366>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86445177>}.

Epoch 16 Loss 0.3489 Accuracy 0.9154
Time taken for 1 epoch: 35.86701679229736 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.8914 Accuracy 0.8645

epoch lasted: 36.02448916435242
Epoch 17 Batch 0 Loss 0.3176 Accuracy 0.9236
Epoch 17 Batch 50 Loss 0.3124 Accuracy 0.9225
Epoch 17 Batch 100 Loss 0.3151 Accuracy 0.9222
Epoch 17 Batch 150 Loss 0.3176 Accuracy 0.9215
Epoch 17 Batch 200 Loss 0.3207 Accuracy 0.9208
Epoch 17 Batch 250 Loss 0.3221 Accuracy 0.9205
Epoch 17 Batch 300 Loss 0.3234 Accuracy 0.9203
Epoch 17 Batch 350 Loss 0.3248 Accuracy 0.9201
Epoch 17 Batch 400 Loss 0.3263 Accuracy 0.9196
Epoch 17 Batch 450 Loss 0.3269 Accuracy 0.9193
Epoch 17 Batch 500 Loss 0.3287 Accuracy 0.9189
Epoch 17 Batch 550 Loss 0.3300 Accuracy 0.9187
Epoch 17 Batch 600 Loss 0.3316 Accuracy 0.9184
Epoch 17 Batch 650 Loss 0.3327 Accuracy 0.9182
Epoch 17 Batch 700 Loss 0.3339 Accuracy 0.9180
Epoch 17 Batch 750 Loss 0.3346 Accuracy 0.9179
Epoch 17 Batch 800 Loss 0.3360 Accuracy 0.9176
discarded batch 809
Epoch 17 Batch 850 Loss 0.3368 Accuracy 0.9174
Epoch 17 Batch 900 Loss 0.3379 Accuracy 0.9174
Epoch 17 Batch 950 Loss 0.3385 Accuracy 0.9172
Epoch 17 Batch 1000 Loss 0.3393 Accuracy 0.9171
Epoch 17 Batch 1050 Loss 0.3405 Accuracy 0.9168
Epoch 17 Batch 1100 Loss 0.3415 Accuracy 0.9167
Epoch 17 Batch 1150 Loss 0.3423 Accuracy 0.9166
Epoch 17 Batch 1200 Loss 0.3428 Accuracy 0.9164
Epoch 17 Batch 1250 Loss 0.3436 Accuracy 0.9164
Epoch 17 Batch 1300 Loss 0.3444 Accuracy 0.9162
Epoch 17 Batch 1350 Loss 0.3449 Accuracy 0.9161
Epoch 17 Batch 1400 Loss 0.3457 Accuracy 0.9159
Epoch 17 Batch 1450 Loss 0.3463 Accuracy 0.9159
Epoch 17 Batch 1500 Loss 0.3471 Accuracy 0.9157

wandb: WARNING Step must only increase in log calls.  Step 17 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34786502>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9156352>}.

Epoch 17 Loss 0.3479 Accuracy 0.9156
Time taken for 1 epoch: 36.26858329772949 secs

epoch lasted: 36.272908449172974
Epoch 18 Batch 0 Loss 0.3895 Accuracy 0.9120
Epoch 18 Batch 50 Loss 0.3235 Accuracy 0.9180
Epoch 18 Batch 100 Loss 0.3197 Accuracy 0.9199
Epoch 18 Batch 150 Loss 0.3165 Accuracy 0.9203
Epoch 18 Batch 200 Loss 0.3187 Accuracy 0.9198
Epoch 18 Batch 250 Loss 0.3200 Accuracy 0.9196
Epoch 18 Batch 300 Loss 0.3219 Accuracy 0.9195
Epoch 18 Batch 350 Loss 0.3229 Accuracy 0.9196
Epoch 18 Batch 400 Loss 0.3248 Accuracy 0.9193
Epoch 18 Batch 450 Loss 0.3257 Accuracy 0.9193
Epoch 18 Batch 500 Loss 0.3267 Accuracy 0.9191
Epoch 18 Batch 550 Loss 0.3285 Accuracy 0.9188
Epoch 18 Batch 600 Loss 0.3287 Accuracy 0.9187
Epoch 18 Batch 650 Loss 0.3303 Accuracy 0.9186
Epoch 18 Batch 700 Loss 0.3314 Accuracy 0.9184
Epoch 18 Batch 750 Loss 0.3328 Accuracy 0.9181
Epoch 18 Batch 800 Loss 0.3339 Accuracy 0.9179
Epoch 18 Batch 850 Loss 0.3350 Accuracy 0.9177
Epoch 18 Batch 900 Loss 0.3363 Accuracy 0.9174
Epoch 18 Batch 950 Loss 0.3371 Accuracy 0.9173
discarded batch 953
Epoch 18 Batch 1000 Loss 0.3377 Accuracy 0.9173
Epoch 18 Batch 1050 Loss 0.3385 Accuracy 0.9172
Epoch 18 Batch 1100 Loss 0.3396 Accuracy 0.9170
Epoch 18 Batch 1150 Loss 0.3404 Accuracy 0.9169
Epoch 18 Batch 1200 Loss 0.3415 Accuracy 0.9167
Epoch 18 Batch 1250 Loss 0.3422 Accuracy 0.9166
Epoch 18 Batch 1300 Loss 0.3432 Accuracy 0.9165
Epoch 18 Batch 1350 Loss 0.3439 Accuracy 0.9164
Epoch 18 Batch 1400 Loss 0.3446 Accuracy 0.9162
Epoch 18 Batch 1450 Loss 0.3454 Accuracy 0.9161
Epoch 18 Batch 1500 Loss 0.3462 Accuracy 0.9159

wandb: WARNING Step must only increase in log calls.  Step 18 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3470102>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91584>}.

Epoch 18 Loss 0.3470 Accuracy 0.9158
Time taken for 1 epoch: 36.16544246673584 secs

epoch lasted: 36.16980695724487
Epoch 19 Batch 0 Loss 0.3236 Accuracy 0.9236
Epoch 19 Batch 50 Loss 0.3095 Accuracy 0.9227
Epoch 19 Batch 100 Loss 0.3114 Accuracy 0.9216
Epoch 19 Batch 150 Loss 0.3139 Accuracy 0.9213
Epoch 19 Batch 200 Loss 0.3176 Accuracy 0.9210
Epoch 19 Batch 250 Loss 0.3189 Accuracy 0.9206
Epoch 19 Batch 300 Loss 0.3220 Accuracy 0.9201
Epoch 19 Batch 350 Loss 0.3233 Accuracy 0.9200
Epoch 19 Batch 400 Loss 0.3242 Accuracy 0.9198
Epoch 19 Batch 450 Loss 0.3262 Accuracy 0.9193
Epoch 19 Batch 500 Loss 0.3274 Accuracy 0.9192
Epoch 19 Batch 550 Loss 0.3277 Accuracy 0.9190
Epoch 19 Batch 600 Loss 0.3289 Accuracy 0.9188
Epoch 19 Batch 650 Loss 0.3305 Accuracy 0.9186
Epoch 19 Batch 700 Loss 0.3313 Accuracy 0.9184
Epoch 19 Batch 750 Loss 0.3325 Accuracy 0.9182
Epoch 19 Batch 800 Loss 0.3338 Accuracy 0.9181
Epoch 19 Batch 850 Loss 0.3350 Accuracy 0.9178
Epoch 19 Batch 900 Loss 0.3359 Accuracy 0.9177
Epoch 19 Batch 950 Loss 0.3370 Accuracy 0.9175
Epoch 19 Batch 1000 Loss 0.3384 Accuracy 0.9172
Epoch 19 Batch 1050 Loss 0.3394 Accuracy 0.9170
Epoch 19 Batch 1100 Loss 0.3401 Accuracy 0.9169
Epoch 19 Batch 1150 Loss 0.3408 Accuracy 0.9168
Epoch 19 Batch 1200 Loss 0.3416 Accuracy 0.9166
Epoch 19 Batch 1250 Loss 0.3424 Accuracy 0.9165
Epoch 19 Batch 1300 Loss 0.3433 Accuracy 0.9163
Epoch 19 Batch 1350 Loss 0.3442 Accuracy 0.9162
discarded batch 1384
Epoch 19 Batch 1400 Loss 0.3450 Accuracy 0.9161
Epoch 19 Batch 1450 Loss 0.3459 Accuracy 0.9159
Epoch 19 Batch 1500 Loss 0.3470 Accuracy 0.9158

wandb: WARNING Step must only increase in log calls.  Step 19 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3476332>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9155966>}.

Epoch 19 Loss 0.3476 Accuracy 0.9156
Time taken for 1 epoch: 35.961052656173706 secs

epoch lasted: 35.97473859786987
Epoch 20 Batch 0 Loss 0.3153 Accuracy 0.9236
Epoch 20 Batch 50 Loss 0.3173 Accuracy 0.9223
Epoch 20 Batch 100 Loss 0.3132 Accuracy 0.9229
Epoch 20 Batch 150 Loss 0.3154 Accuracy 0.9220
Epoch 20 Batch 200 Loss 0.3182 Accuracy 0.9214
Epoch 20 Batch 250 Loss 0.3200 Accuracy 0.9211
Epoch 20 Batch 300 Loss 0.3216 Accuracy 0.9208
Epoch 20 Batch 350 Loss 0.3227 Accuracy 0.9204
discarded batch 374
Epoch 20 Batch 400 Loss 0.3237 Accuracy 0.9202
Epoch 20 Batch 450 Loss 0.3248 Accuracy 0.9198
Epoch 20 Batch 500 Loss 0.3256 Accuracy 0.9197
Epoch 20 Batch 550 Loss 0.3274 Accuracy 0.9193
Epoch 20 Batch 600 Loss 0.3288 Accuracy 0.9191
Epoch 20 Batch 650 Loss 0.3295 Accuracy 0.9189
Epoch 20 Batch 700 Loss 0.3308 Accuracy 0.9188
Epoch 20 Batch 750 Loss 0.3322 Accuracy 0.9185
Epoch 20 Batch 800 Loss 0.3337 Accuracy 0.9182
Epoch 20 Batch 850 Loss 0.3344 Accuracy 0.9180
Epoch 20 Batch 900 Loss 0.3354 Accuracy 0.9178
Epoch 20 Batch 950 Loss 0.3365 Accuracy 0.9176
Epoch 20 Batch 1000 Loss 0.3376 Accuracy 0.9174
Epoch 20 Batch 1050 Loss 0.3382 Accuracy 0.9172
Epoch 20 Batch 1100 Loss 0.3388 Accuracy 0.9171
Epoch 20 Batch 1150 Loss 0.3395 Accuracy 0.9170
Epoch 20 Batch 1200 Loss 0.3404 Accuracy 0.9168
Epoch 20 Batch 1250 Loss 0.3411 Accuracy 0.9167
Epoch 20 Batch 1300 Loss 0.3421 Accuracy 0.9165
Epoch 20 Batch 1350 Loss 0.3431 Accuracy 0.9164
Epoch 20 Batch 1400 Loss 0.3439 Accuracy 0.9162
Epoch 20 Batch 1450 Loss 0.3443 Accuracy 0.9162
Epoch 20 Batch 1500 Loss 0.3449 Accuracy 0.9161

wandb: WARNING Step must only increase in log calls.  Step 20 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34573776>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9158851>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-32
Epoch 20 Loss 0.3457 Accuracy 0.9159
Time taken for 1 epoch: 36.60167169570923 secs

epoch lasted: 36.60575985908508
Epoch 21 Batch 0 Loss 0.3107 Accuracy 0.9153
Epoch 21 Batch 50 Loss 0.3115 Accuracy 0.9219
Epoch 21 Batch 100 Loss 0.3137 Accuracy 0.9217
Epoch 21 Batch 150 Loss 0.3172 Accuracy 0.9207
Epoch 21 Batch 200 Loss 0.3188 Accuracy 0.9201
Epoch 21 Batch 250 Loss 0.3172 Accuracy 0.9205
Epoch 21 Batch 300 Loss 0.3198 Accuracy 0.9201
Epoch 21 Batch 350 Loss 0.3206 Accuracy 0.9200
Epoch 21 Batch 400 Loss 0.3210 Accuracy 0.9199
Epoch 21 Batch 450 Loss 0.3227 Accuracy 0.9198
Epoch 21 Batch 500 Loss 0.3239 Accuracy 0.9196
Epoch 21 Batch 550 Loss 0.3250 Accuracy 0.9195
Epoch 21 Batch 600 Loss 0.3262 Accuracy 0.9193
Epoch 21 Batch 650 Loss 0.3273 Accuracy 0.9191
Epoch 21 Batch 700 Loss 0.3286 Accuracy 0.9188
Epoch 21 Batch 750 Loss 0.3302 Accuracy 0.9185
Epoch 21 Batch 800 Loss 0.3314 Accuracy 0.9182
Epoch 21 Batch 850 Loss 0.3329 Accuracy 0.9179
Epoch 21 Batch 900 Loss 0.3340 Accuracy 0.9178
Epoch 21 Batch 950 Loss 0.3350 Accuracy 0.9176
Epoch 21 Batch 1000 Loss 0.3360 Accuracy 0.9174
Epoch 21 Batch 1050 Loss 0.3370 Accuracy 0.9173
Epoch 21 Batch 1100 Loss 0.3379 Accuracy 0.9172
Epoch 21 Batch 1150 Loss 0.3389 Accuracy 0.9170
Epoch 21 Batch 1200 Loss 0.3398 Accuracy 0.9168
Epoch 21 Batch 1250 Loss 0.3403 Accuracy 0.9167
Epoch 21 Batch 1300 Loss 0.3414 Accuracy 0.9166
Epoch 21 Batch 1350 Loss 0.3420 Accuracy 0.9165
Epoch 21 Batch 1400 Loss 0.3428 Accuracy 0.9164
Epoch 21 Batch 1450 Loss 0.3433 Accuracy 0.9163
discarded batch 1483
Epoch 21 Batch 1500 Loss 0.3440 Accuracy 0.9162

wandb: WARNING Step must only increase in log calls.  Step 21 < 28; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34466124>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91607916>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 28; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.88951194>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8644518>}.

Epoch 21 Loss 0.3447 Accuracy 0.9161
Time taken for 1 epoch: 36.0530481338501 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.8895 Accuracy 0.8645

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
  e |quan|do |sa|li|co |tem|po |ca|i|ra|
e |quan|do |noi |fum|mo |per |a|to |gi|re|
e ’l |buon |vo|stro |fum|mo |non |po|e|vel|la|
                                                                                                                                                                   
 che |si |le|var|ca |già |si |di|ver|mi|no|
in|ver’ |lo |me|co |me|co |più |a |no|ma|
la |ter|ra |già |da |qua |giù |si |ri|gi|no|
e |co|sì |con |es|si |fa |con |la |de|stra |cor|te|
per |lei |con |un |pun|to in |cui |tan|to |de|gno|
in|fi|gu|ra in |su |la |val|le |man |cor|te|
                                                                                                                                                                   
 e |io |a |cui |non |pos|sen|tì |la |man |de|
e ’l |buon |pos|so |di |par|te |non |si |cor|te|
e |quan|to |di |là |giù |per |lo |stre|ma |so|
e |io |a |cui |a |lui |a |sé |per|ché |tu |ve|de|
con |la |mi|su|so il |mi|se|ro a |par|ti|va|
e |co|min|ciò |el|la |cir|cun|fe|de|re|
                                                                                                                                                                   
 co|me |le|va |con |tut|te |fu |det|ta |vi|
per |te |sen |va |con |la |fiam|ma |cor|ni|re|
per |ch’ io |veg|gen|te |del |cor|po |di|ste|so|
e |là |giù |per |lo |fon|de |la |gen|te |ne |sca|sca|
non |ti |la|scia|no |qui|vi |fa|cea |o|scu|na |che |già |veg|gia|va |sù |vin|ce |più |ca|sca|
                                                                                                                                                                   
 a |lei |ve|ren|te |già |mai |non |si |veg|gio|
e |o|ve |l’ ac|qua |la |mia |don|na |val|sca|
mo|strar|ti e |vi|d’ io |ma|gi|ran|no |stan|no|
 e |l’ al|tre |ch’ io |sap|pi |ch’ i’ |fu’ |io |man|do|
quin|
con|giun|si e |ren|der |li |mal |di|let|to|
con |quel|le |pian|te |dis|s’ io |ma|men|ti|
                                                                                                                                                                    
 ed |el|li a |me |qual |co|me |con |ma|su |stret|to|
che |l’ ac|qua |e |di |cui |tan|te |pian|ti|
e |quin|ci |co|me |che |tu |mi |di|stret|to|
la|scia|
se |le |man |mo|do|man|da |la |val|le|
non |per|ché |pe|rò |mal |vo|stra |qua |sù |pia|
io |vi|di |qua |giù |del |cor|po |sì |tol|le|
                                                                                                                                                                   
 e ’l |buon |ma|li|so |lor |co|sì |ca|fa|vil|
qual |è |che |me|ro |son |con |lei |ar|des|se|
io |fui |qua|lun|que |co|me |l’ uom |cui |fa|mi|
 per |le |gen|te |sen |van|no |più |che |s’ a|mo|stra|
pe|rò |o|ve |a |cui |sì |di|mo|stra|ro|
ne |la |sua |cor|re|na |tut|to ’l |mon|do|ve|
                                                                                                                                                                   
 que|sto |tut|to ’l |cor|po |che ’l |mon|do |ca|ro|
a |po|scia |re|ve|ren|der |fa |l’ uom |cui |que|
on|d’ el|li |cer|to |li |fa|cea |si |la|ro|
cia|scun |che |per|so|pra |la |ve|ren|der |la |por|ta|
mi |fe|de|stra |per |que|sto |mon|te |die|tro|
a |le |ve|der |d’ un |gri|dò |per|ché |pur |a |
                                                                                                                                                                   
 per |la |qual |fo|ra |per|ché |per |con|giun|tro|
mi |fe|ce |più |lun|go |ch’ a |la |fa|cea |ma|
non |e|ra |già |mai |non |co|me |l’ uom |fon|do|
 ma |per|so|vra |tut|te |le |me|mo|glia |ca|sca|
con |le |me|de|stra |qua |giù |per |le |sca|gna|
e |co|se |tu |se’ |sì |al|to |dal |ca|sca|
                                                                                                                                                                   
 che |non |fos|se |qual |co|me |stu|dio |so|gna|
or |ti |fia |lo|ro |fui |a |cui |no|vel|li|
 ché |so|vra |noi |ce|ra|dor |di |lor |sof|fer|se|
se |li oc|chi |guar|dar |chi |per |la |più |bel|la|
per |pa|rean |di |là |giù |non |pa|rea |cam|mi|
                                                                                                                                                                   
 e |quin|di |pian|gen|do |per |un |de|ste|la|
non |cor|so |di |ben |ch’ a |dio |so|ste|ria|
ché |non |mo|ve|der |drit|ti |li |fa|cea |ste|
 que|sto |che |que|sta |ca|de|stra |qua |giù |ca|ro|
que|sta |dol|ce |pa|u|na |val|le|o|ne|
non |è |cor|po |per |lo |tuo |par|la|men|to|
                                                                                                                                                                   
 per|ché |mi |la|men|tr’ io |li |che |ve|ra|ne|
a |cui |tu |la|sciar |do|lo|ro|te |die|tro|
e |quin|di |si |fa|cea |la |mia |mag|gior |ca|
 e |quan|t’ io |car|ca|ro |si |con|vien |con |u|ca|
si |con|si|glio |co|me a |cui |tan|ta |mor|ti|
e |quin|ci |mo|stra |ca|re e |a |cui |no|cui |no|
                                                                                                                                                                  
 per |la |mia |don|na |che |tut|ta |si |cor|ti|
la |sua |cit|tà |la |co|sì |sen |gi|na|ce|
on|de |la |sua |glo|rï|o|san|za |por|ti|
e |bel|la |mia |don|na in |ca|gion |ch’ io |mi |par|la|
e |io |co|me |let|tor |con |un |prin|ci|pio |lo|
e |io |veg|gio |co|me |ma|la|bo|ma|
                                                                                                                                                                    
 a |no|stro |ser|vo |che ’l |tuo |di|vo|lu|lo|
e |quin|ci |si |fa|cea |e |co|lor |to|sto|
e |io |veg|gio |ben |ma |io |veg|gio |du|lo|
 sì |ch’ a |la |mia |don|na |ch’ i’ |non |si |con|for|se|
ma |per |le |ve|men|te |che |più |si |tol|se|
ma |io |fui |a |lui |la|scia|te |por|ta|le|
                                                                                                                                                                   
 per |li |me|ro |più |a|ves|se |ta|men|ze|
per |lo |sol |mo|re e |per|ché |per |la |por|te|
e |l’ al|tro |se|gna|te |qua |giù |di|ven|ze|
 co|sì |ri|tor|no |do|ve |tor|nan|zi a |la |be|
in|co|me a |nes|se |tut|ta |ri|cor|se|gno|
in|fi|no a |la |don|na |che |so|vra |gran |be|
                                                                                                                                                                   
 co|me |quei |fu |a |piè |del |mon|te |cor|gno|
in|con|tro a |la |sua |oc|ca|sa |fu |a |be|
e |la |sua |spe|da |tut|ta |val|le|var|ca|
e |là |do|ve |se|gna|va |non |si |fa |di |fo|co|
e |te |par|te |sì |che |tut|to ’l |mon|te|
a |me |con |li oc|chi |se’ |tu |la|gri|dan|no|
                                                                                                                                                                    
 là |do|ve |si|cu|pi|lo|co |fon|de|re|
co|min|ciò |el|li |ve|nir |per |me |cen|no|
o|ve |per |que|sto |cie|lo e |mol|te |ve|de|

epoch lasted: 518.8274168968201
(1900, 128)
Epoch 1 Batch 0 Loss 0.3250 Accuracy 0.9203
Epoch 1 Batch 50 Loss 0.3121 Accuracy 0.9232
Epoch 1 Batch 100 Loss 0.3111 Accuracy 0.9225
Epoch 1 Batch 150 Loss 0.3147 Accuracy 0.9218
Epoch 1 Batch 200 Loss 0.3177 Accuracy 0.9216
Epoch 1 Batch 250 Loss 0.3163 Accuracy 0.9221
Epoch 1 Batch 300 Loss 0.3187 Accuracy 0.9212
Epoch 1 Batch 350 Loss 0.3203 Accuracy 0.9208
Epoch 1 Batch 400 Loss 0.3217 Accuracy 0.9205
Epoch 1 Batch 450 Loss 0.3232 Accuracy 0.9203
Epoch 1 Batch 500 Loss 0.3240 Accuracy 0.9202
Epoch 1 Batch 550 Loss 0.3249 Accuracy 0.9200
Epoch 1 Batch 600 Loss 0.3260 Accuracy 0.9198
Epoch 1 Batch 650 Loss 0.3275 Accuracy 0.9196
Epoch 1 Batch 700 Loss 0.3287 Accuracy 0.9193
Epoch 1 Batch 750 Loss 0.3295 Accuracy 0.9191
Epoch 1 Batch 800 Loss 0.3308 Accuracy 0.9189
Epoch 1 Batch 850 Loss 0.3317 Accuracy 0.9188
discarded batch 876
Epoch 1 Batch 900 Loss 0.3326 Accuracy 0.9187
Epoch 1 Batch 950 Loss 0.3337 Accuracy 0.9185
Epoch 1 Batch 1000 Loss 0.3346 Accuracy 0.9183
Epoch 1 Batch 1050 Loss 0.3362 Accuracy 0.9180
Epoch 1 Batch 1100 Loss 0.3370 Accuracy 0.9179
Epoch 1 Batch 1150 Loss 0.3381 Accuracy 0.9176
Epoch 1 Batch 1200 Loss 0.3391 Accuracy 0.9174
Epoch 1 Batch 1250 Loss 0.3402 Accuracy 0.9172
Epoch 1 Batch 1300 Loss 0.3410 Accuracy 0.9170
Epoch 1 Batch 1350 Loss 0.3414 Accuracy 0.9169
Epoch 1 Batch 1400 Loss 0.3422 Accuracy 0.9167
Epoch 1 Batch 1450 Loss 0.3427 Accuracy 0.9166
Epoch 1 Batch 1500 Loss 0.3432 Accuracy 0.9165

wandb: WARNING Step must only increase in log calls.  Step 1 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3441109>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91635907>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 29; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.89220876>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.865227>}.

Epoch 1 Loss 0.3441 Accuracy 0.9164
Time taken for 1 epoch: 36.35529708862305 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.8922 Accuracy 0.8652

epoch lasted: 36.510496377944946
Epoch 2 Batch 0 Loss 0.2740 Accuracy 0.9169
Epoch 2 Batch 50 Loss 0.3150 Accuracy 0.9216
Epoch 2 Batch 100 Loss 0.3172 Accuracy 0.9208
Epoch 2 Batch 150 Loss 0.3182 Accuracy 0.9208
Epoch 2 Batch 200 Loss 0.3179 Accuracy 0.9212
Epoch 2 Batch 250 Loss 0.3190 Accuracy 0.9208
Epoch 2 Batch 300 Loss 0.3213 Accuracy 0.9203
Epoch 2 Batch 350 Loss 0.3230 Accuracy 0.9199
Epoch 2 Batch 400 Loss 0.3235 Accuracy 0.9198
Epoch 2 Batch 450 Loss 0.3245 Accuracy 0.9197
Epoch 2 Batch 500 Loss 0.3263 Accuracy 0.9194
Epoch 2 Batch 550 Loss 0.3269 Accuracy 0.9194
Epoch 2 Batch 600 Loss 0.3281 Accuracy 0.9191
discarded batch 642
Epoch 2 Batch 650 Loss 0.3293 Accuracy 0.9189
Epoch 2 Batch 700 Loss 0.3306 Accuracy 0.9187
Epoch 2 Batch 750 Loss 0.3323 Accuracy 0.9184
Epoch 2 Batch 800 Loss 0.3328 Accuracy 0.9182
Epoch 2 Batch 850 Loss 0.3337 Accuracy 0.9181
Epoch 2 Batch 900 Loss 0.3346 Accuracy 0.9179
Epoch 2 Batch 950 Loss 0.3360 Accuracy 0.9176
Epoch 2 Batch 1000 Loss 0.3369 Accuracy 0.9175
Epoch 2 Batch 1050 Loss 0.3375 Accuracy 0.9174
Epoch 2 Batch 1100 Loss 0.3381 Accuracy 0.9174
Epoch 2 Batch 1150 Loss 0.3388 Accuracy 0.9173
Epoch 2 Batch 1200 Loss 0.3394 Accuracy 0.9171
Epoch 2 Batch 1250 Loss 0.3400 Accuracy 0.9171
Epoch 2 Batch 1300 Loss 0.3408 Accuracy 0.9169
Epoch 2 Batch 1350 Loss 0.3416 Accuracy 0.9168
Epoch 2 Batch 1400 Loss 0.3419 Accuracy 0.9167
Epoch 2 Batch 1450 Loss 0.3425 Accuracy 0.9166
Epoch 2 Batch 1500 Loss 0.3434 Accuracy 0.9165

wandb: WARNING Step must only increase in log calls.  Step 2 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34402865>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9163451>}.

Epoch 2 Loss 0.3440 Accuracy 0.9163
Time taken for 1 epoch: 35.77559041976929 secs

epoch lasted: 35.77931070327759
Epoch 3 Batch 0 Loss 0.3363 Accuracy 0.9053
Epoch 3 Batch 50 Loss 0.3066 Accuracy 0.9220
Epoch 3 Batch 100 Loss 0.3131 Accuracy 0.9212
Epoch 3 Batch 150 Loss 0.3139 Accuracy 0.9212
Epoch 3 Batch 200 Loss 0.3165 Accuracy 0.9210
Epoch 3 Batch 250 Loss 0.3178 Accuracy 0.9205
Epoch 3 Batch 300 Loss 0.3196 Accuracy 0.9202
Epoch 3 Batch 350 Loss 0.3217 Accuracy 0.9198
Epoch 3 Batch 400 Loss 0.3221 Accuracy 0.9197
Epoch 3 Batch 450 Loss 0.3230 Accuracy 0.9195
Epoch 3 Batch 500 Loss 0.3247 Accuracy 0.9190
Epoch 3 Batch 550 Loss 0.3259 Accuracy 0.9189
Epoch 3 Batch 600 Loss 0.3266 Accuracy 0.9188
Epoch 3 Batch 650 Loss 0.3274 Accuracy 0.9187
Epoch 3 Batch 700 Loss 0.3287 Accuracy 0.9185
Epoch 3 Batch 750 Loss 0.3294 Accuracy 0.9183
Epoch 3 Batch 800 Loss 0.3301 Accuracy 0.9182
Epoch 3 Batch 850 Loss 0.3310 Accuracy 0.9180
Epoch 3 Batch 900 Loss 0.3322 Accuracy 0.9178
discarded batch 947
Epoch 3 Batch 950 Loss 0.3334 Accuracy 0.9176
Epoch 3 Batch 1000 Loss 0.3346 Accuracy 0.9174
Epoch 3 Batch 1050 Loss 0.3355 Accuracy 0.9173
Epoch 3 Batch 1100 Loss 0.3363 Accuracy 0.9171
Epoch 3 Batch 1150 Loss 0.3368 Accuracy 0.9170
Epoch 3 Batch 1200 Loss 0.3374 Accuracy 0.9170
Epoch 3 Batch 1250 Loss 0.3387 Accuracy 0.9168
Epoch 3 Batch 1300 Loss 0.3397 Accuracy 0.9166
Epoch 3 Batch 1350 Loss 0.3405 Accuracy 0.9164
Epoch 3 Batch 1400 Loss 0.3416 Accuracy 0.9163
Epoch 3 Batch 1450 Loss 0.3424 Accuracy 0.9161
Epoch 3 Batch 1500 Loss 0.3431 Accuracy 0.9160

wandb: WARNING Step must only increase in log calls.  Step 3 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34372833>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91594404>}.

Epoch 3 Loss 0.3437 Accuracy 0.9159
Time taken for 1 epoch: 35.84934329986572 secs

epoch lasted: 35.85383605957031
Epoch 4 Batch 0 Loss 0.3037 Accuracy 0.9203
Epoch 4 Batch 50 Loss 0.3040 Accuracy 0.9236
Epoch 4 Batch 100 Loss 0.3130 Accuracy 0.9217
Epoch 4 Batch 150 Loss 0.3150 Accuracy 0.9215
Epoch 4 Batch 200 Loss 0.3161 Accuracy 0.9214
Epoch 4 Batch 250 Loss 0.3163 Accuracy 0.9213
Epoch 4 Batch 300 Loss 0.3181 Accuracy 0.9206
Epoch 4 Batch 350 Loss 0.3198 Accuracy 0.9203
Epoch 4 Batch 400 Loss 0.3207 Accuracy 0.9202
Epoch 4 Batch 450 Loss 0.3216 Accuracy 0.9201
Epoch 4 Batch 500 Loss 0.3222 Accuracy 0.9200
Epoch 4 Batch 550 Loss 0.3233 Accuracy 0.9199
Epoch 4 Batch 600 Loss 0.3244 Accuracy 0.9196
Epoch 4 Batch 650 Loss 0.3251 Accuracy 0.9195
Epoch 4 Batch 700 Loss 0.3256 Accuracy 0.9195
Epoch 4 Batch 750 Loss 0.3266 Accuracy 0.9193
Epoch 4 Batch 800 Loss 0.3276 Accuracy 0.9190
Epoch 4 Batch 850 Loss 0.3282 Accuracy 0.9189
Epoch 4 Batch 900 Loss 0.3294 Accuracy 0.9187
discarded batch 918
Epoch 4 Batch 950 Loss 0.3302 Accuracy 0.9186
Epoch 4 Batch 1000 Loss 0.3309 Accuracy 0.9185
Epoch 4 Batch 1050 Loss 0.3318 Accuracy 0.9183
Epoch 4 Batch 1100 Loss 0.3327 Accuracy 0.9181
Epoch 4 Batch 1150 Loss 0.3339 Accuracy 0.9178
Epoch 4 Batch 1200 Loss 0.3349 Accuracy 0.9177
Epoch 4 Batch 1250 Loss 0.3360 Accuracy 0.9175
Epoch 4 Batch 1300 Loss 0.3369 Accuracy 0.9173
Epoch 4 Batch 1350 Loss 0.3378 Accuracy 0.9172
Epoch 4 Batch 1400 Loss 0.3387 Accuracy 0.9170
Epoch 4 Batch 1450 Loss 0.3396 Accuracy 0.9168
Epoch 4 Batch 1500 Loss 0.3403 Accuracy 0.9167

wandb: WARNING Step must only increase in log calls.  Step 4 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34135154>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91656494>}.

Epoch 4 Loss 0.3414 Accuracy 0.9166
Time taken for 1 epoch: 35.88643670082092 secs

epoch lasted: 35.8919563293457
Epoch 5 Batch 0 Loss 0.3242 Accuracy 0.9252
Epoch 5 Batch 50 Loss 0.3090 Accuracy 0.9222
Epoch 5 Batch 100 Loss 0.3114 Accuracy 0.9221
Epoch 5 Batch 150 Loss 0.3132 Accuracy 0.9216
Epoch 5 Batch 200 Loss 0.3146 Accuracy 0.9213
Epoch 5 Batch 250 Loss 0.3161 Accuracy 0.9213
Epoch 5 Batch 300 Loss 0.3173 Accuracy 0.9209
Epoch 5 Batch 350 Loss 0.3188 Accuracy 0.9208
Epoch 5 Batch 400 Loss 0.3199 Accuracy 0.9203
Epoch 5 Batch 450 Loss 0.3211 Accuracy 0.9201
Epoch 5 Batch 500 Loss 0.3219 Accuracy 0.9200
Epoch 5 Batch 550 Loss 0.3233 Accuracy 0.9198
Epoch 5 Batch 600 Loss 0.3243 Accuracy 0.9197
Epoch 5 Batch 650 Loss 0.3256 Accuracy 0.9194
Epoch 5 Batch 700 Loss 0.3266 Accuracy 0.9191
Epoch 5 Batch 750 Loss 0.3277 Accuracy 0.9189
Epoch 5 Batch 800 Loss 0.3282 Accuracy 0.9188
Epoch 5 Batch 850 Loss 0.3288 Accuracy 0.9187
Epoch 5 Batch 900 Loss 0.3300 Accuracy 0.9185
Epoch 5 Batch 950 Loss 0.3310 Accuracy 0.9183
Epoch 5 Batch 1000 Loss 0.3314 Accuracy 0.9182
Epoch 5 Batch 1050 Loss 0.3324 Accuracy 0.9180
Epoch 5 Batch 1100 Loss 0.3335 Accuracy 0.9178
Epoch 5 Batch 1150 Loss 0.3346 Accuracy 0.9177
Epoch 5 Batch 1200 Loss 0.3356 Accuracy 0.9175
Epoch 5 Batch 1250 Loss 0.3363 Accuracy 0.9174
Epoch 5 Batch 1300 Loss 0.3374 Accuracy 0.9173
Epoch 5 Batch 1350 Loss 0.3382 Accuracy 0.9171
Epoch 5 Batch 1400 Loss 0.3391 Accuracy 0.9170
Epoch 5 Batch 1450 Loss 0.3398 Accuracy 0.9169
Epoch 5 Batch 1500 Loss 0.3407 Accuracy 0.9168
discarded batch 1527

wandb: WARNING Step must only increase in log calls.  Step 5 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34122276>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9166851>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-33
Epoch 5 Loss 0.3412 Accuracy 0.9167
Time taken for 1 epoch: 36.099586725234985 secs

epoch lasted: 36.103639125823975
Epoch 6 Batch 0 Loss 0.3457 Accuracy 0.9103
Epoch 6 Batch 50 Loss 0.3121 Accuracy 0.9226
Epoch 6 Batch 100 Loss 0.3112 Accuracy 0.9222
Epoch 6 Batch 150 Loss 0.3147 Accuracy 0.9212
Epoch 6 Batch 200 Loss 0.3141 Accuracy 0.9212
Epoch 6 Batch 250 Loss 0.3158 Accuracy 0.9209
Epoch 6 Batch 300 Loss 0.3169 Accuracy 0.9207
Epoch 6 Batch 350 Loss 0.3193 Accuracy 0.9202
Epoch 6 Batch 400 Loss 0.3201 Accuracy 0.9202
Epoch 6 Batch 450 Loss 0.3216 Accuracy 0.9201
Epoch 6 Batch 500 Loss 0.3236 Accuracy 0.9198
Epoch 6 Batch 550 Loss 0.3245 Accuracy 0.9197
Epoch 6 Batch 600 Loss 0.3255 Accuracy 0.9195
Epoch 6 Batch 650 Loss 0.3266 Accuracy 0.9193
Epoch 6 Batch 700 Loss 0.3276 Accuracy 0.9192
Epoch 6 Batch 750 Loss 0.3285 Accuracy 0.9190
Epoch 6 Batch 800 Loss 0.3295 Accuracy 0.9188
Epoch 6 Batch 850 Loss 0.3306 Accuracy 0.9186
Epoch 6 Batch 900 Loss 0.3314 Accuracy 0.9184
Epoch 6 Batch 950 Loss 0.3321 Accuracy 0.9182
Epoch 6 Batch 1000 Loss 0.3326 Accuracy 0.9181
Epoch 6 Batch 1050 Loss 0.3334 Accuracy 0.9180
Epoch 6 Batch 1100 Loss 0.3343 Accuracy 0.9178
Epoch 6 Batch 1150 Loss 0.3348 Accuracy 0.9178
Epoch 6 Batch 1200 Loss 0.3355 Accuracy 0.9176
Epoch 6 Batch 1250 Loss 0.3367 Accuracy 0.9175
Epoch 6 Batch 1300 Loss 0.3375 Accuracy 0.9173
Epoch 6 Batch 1350 Loss 0.3381 Accuracy 0.9172
Epoch 6 Batch 1400 Loss 0.3388 Accuracy 0.9171
discarded batch 1428
Epoch 6 Batch 1450 Loss 0.3395 Accuracy 0.9170
Epoch 6 Batch 1500 Loss 0.3406 Accuracy 0.9169

wandb: WARNING Step must only increase in log calls.  Step 6 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3415709>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.916714>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 29; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.89529604>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8634551>}.

Epoch 6 Loss 0.3416 Accuracy 0.9167
Time taken for 1 epoch: 35.96160650253296 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.8953 Accuracy 0.8635

epoch lasted: 36.120155811309814
Epoch 7 Batch 0 Loss 0.2994 Accuracy 0.9302
Epoch 7 Batch 50 Loss 0.3014 Accuracy 0.9247
Epoch 7 Batch 100 Loss 0.3062 Accuracy 0.9232
Epoch 7 Batch 150 Loss 0.3103 Accuracy 0.9222
Epoch 7 Batch 200 Loss 0.3091 Accuracy 0.9223
Epoch 7 Batch 250 Loss 0.3125 Accuracy 0.9216
Epoch 7 Batch 300 Loss 0.3134 Accuracy 0.9214
Epoch 7 Batch 350 Loss 0.3156 Accuracy 0.9212
Epoch 7 Batch 400 Loss 0.3179 Accuracy 0.9208
Epoch 7 Batch 450 Loss 0.3190 Accuracy 0.9206
Epoch 7 Batch 500 Loss 0.3209 Accuracy 0.9203
Epoch 7 Batch 550 Loss 0.3223 Accuracy 0.9199
Epoch 7 Batch 600 Loss 0.3239 Accuracy 0.9196
Epoch 7 Batch 650 Loss 0.3246 Accuracy 0.9195
Epoch 7 Batch 700 Loss 0.3258 Accuracy 0.9193
Epoch 7 Batch 750 Loss 0.3267 Accuracy 0.9190
Epoch 7 Batch 800 Loss 0.3276 Accuracy 0.9189
Epoch 7 Batch 850 Loss 0.3286 Accuracy 0.9187
Epoch 7 Batch 900 Loss 0.3298 Accuracy 0.9185
Epoch 7 Batch 950 Loss 0.3309 Accuracy 0.9183
discarded batch 974
Epoch 7 Batch 1000 Loss 0.3319 Accuracy 0.9181
Epoch 7 Batch 1050 Loss 0.3330 Accuracy 0.9179
Epoch 7 Batch 1100 Loss 0.3336 Accuracy 0.9177
Epoch 7 Batch 1150 Loss 0.3346 Accuracy 0.9175
Epoch 7 Batch 1200 Loss 0.3356 Accuracy 0.9174
Epoch 7 Batch 1250 Loss 0.3370 Accuracy 0.9172
Epoch 7 Batch 1300 Loss 0.3376 Accuracy 0.9171
Epoch 7 Batch 1350 Loss 0.3384 Accuracy 0.9169
Epoch 7 Batch 1400 Loss 0.3392 Accuracy 0.9168
Epoch 7 Batch 1450 Loss 0.3399 Accuracy 0.9167
Epoch 7 Batch 1500 Loss 0.3405 Accuracy 0.9166

wandb: WARNING Step must only increase in log calls.  Step 7 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.34095067>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9165371>}.

Epoch 7 Loss 0.3410 Accuracy 0.9165
Time taken for 1 epoch: 36.13396906852722 secs

epoch lasted: 36.13825297355652
Epoch 8 Batch 0 Loss 0.2995 Accuracy 0.9186
Epoch 8 Batch 50 Loss 0.3104 Accuracy 0.9226
Epoch 8 Batch 100 Loss 0.3104 Accuracy 0.9226
Epoch 8 Batch 150 Loss 0.3133 Accuracy 0.9218
Epoch 8 Batch 200 Loss 0.3147 Accuracy 0.9214
Epoch 8 Batch 250 Loss 0.3156 Accuracy 0.9212
Epoch 8 Batch 300 Loss 0.3170 Accuracy 0.9208
Epoch 8 Batch 350 Loss 0.3165 Accuracy 0.9209
Epoch 8 Batch 400 Loss 0.3178 Accuracy 0.9208
Epoch 8 Batch 450 Loss 0.3186 Accuracy 0.9205
Epoch 8 Batch 500 Loss 0.3199 Accuracy 0.9203
Epoch 8 Batch 550 Loss 0.3209 Accuracy 0.9202
Epoch 8 Batch 600 Loss 0.3216 Accuracy 0.9201
Epoch 8 Batch 650 Loss 0.3232 Accuracy 0.9198
Epoch 8 Batch 700 Loss 0.3241 Accuracy 0.9196
Epoch 8 Batch 750 Loss 0.3251 Accuracy 0.9194
Epoch 8 Batch 800 Loss 0.3262 Accuracy 0.9192
Epoch 8 Batch 850 Loss 0.3267 Accuracy 0.9192
Epoch 8 Batch 900 Loss 0.3273 Accuracy 0.9191
Epoch 8 Batch 950 Loss 0.3283 Accuracy 0.9189
Epoch 8 Batch 1000 Loss 0.3296 Accuracy 0.9187
Epoch 8 Batch 1050 Loss 0.3307 Accuracy 0.9185
Epoch 8 Batch 1100 Loss 0.3315 Accuracy 0.9184
Epoch 8 Batch 1150 Loss 0.3323 Accuracy 0.9182
Epoch 8 Batch 1200 Loss 0.3331 Accuracy 0.9182
Epoch 8 Batch 1250 Loss 0.3339 Accuracy 0.9179
Epoch 8 Batch 1300 Loss 0.3349 Accuracy 0.9178
Epoch 8 Batch 1350 Loss 0.3360 Accuracy 0.9176
Epoch 8 Batch 1400 Loss 0.3369 Accuracy 0.9174
Epoch 8 Batch 1450 Loss 0.3377 Accuracy 0.9173
discarded batch 1460
Epoch 8 Batch 1500 Loss 0.3383 Accuracy 0.9172

wandb: WARNING Step must only increase in log calls.  Step 8 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33929345>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9171108>}.

Epoch 8 Loss 0.3393 Accuracy 0.9171
Time taken for 1 epoch: 36.35484266281128 secs

epoch lasted: 36.36850619316101
Epoch 9 Batch 0 Loss 0.2716 Accuracy 0.9169
Epoch 9 Batch 50 Loss 0.3084 Accuracy 0.9228
Epoch 9 Batch 100 Loss 0.3079 Accuracy 0.9229
Epoch 9 Batch 150 Loss 0.3076 Accuracy 0.9232
Epoch 9 Batch 200 Loss 0.3107 Accuracy 0.9223
Epoch 9 Batch 250 Loss 0.3121 Accuracy 0.9218
Epoch 9 Batch 300 Loss 0.3134 Accuracy 0.9215
Epoch 9 Batch 350 Loss 0.3138 Accuracy 0.9215
Epoch 9 Batch 400 Loss 0.3158 Accuracy 0.9212
Epoch 9 Batch 450 Loss 0.3161 Accuracy 0.9210
Epoch 9 Batch 500 Loss 0.3174 Accuracy 0.9207
Epoch 9 Batch 550 Loss 0.3190 Accuracy 0.9205
Epoch 9 Batch 600 Loss 0.3197 Accuracy 0.9204
Epoch 9 Batch 650 Loss 0.3214 Accuracy 0.9201
Epoch 9 Batch 700 Loss 0.3228 Accuracy 0.9199
Epoch 9 Batch 750 Loss 0.3237 Accuracy 0.9197
Epoch 9 Batch 800 Loss 0.3247 Accuracy 0.9196
Epoch 9 Batch 850 Loss 0.3261 Accuracy 0.9194
Epoch 9 Batch 900 Loss 0.3268 Accuracy 0.9192
Epoch 9 Batch 950 Loss 0.3276 Accuracy 0.9191
Epoch 9 Batch 1000 Loss 0.3284 Accuracy 0.9189
Epoch 9 Batch 1050 Loss 0.3294 Accuracy 0.9187
Epoch 9 Batch 1100 Loss 0.3303 Accuracy 0.9186
Epoch 9 Batch 1150 Loss 0.3313 Accuracy 0.9184
Epoch 9 Batch 1200 Loss 0.3321 Accuracy 0.9183
Epoch 9 Batch 1250 Loss 0.3331 Accuracy 0.9181
Epoch 9 Batch 1300 Loss 0.3338 Accuracy 0.9179
discarded batch 1349
Epoch 9 Batch 1350 Loss 0.3346 Accuracy 0.9178
Epoch 9 Batch 1400 Loss 0.3353 Accuracy 0.9177
Epoch 9 Batch 1450 Loss 0.3359 Accuracy 0.9176
Epoch 9 Batch 1500 Loss 0.3366 Accuracy 0.9174

wandb: WARNING Step must only increase in log calls.  Step 9 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33720812>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91728455>}.

Epoch 9 Loss 0.3372 Accuracy 0.9173
Time taken for 1 epoch: 36.05982756614685 secs

epoch lasted: 36.0643527507782
Epoch 10 Batch 0 Loss 0.2952 Accuracy 0.9203
Epoch 10 Batch 50 Loss 0.3064 Accuracy 0.9247
Epoch 10 Batch 100 Loss 0.3078 Accuracy 0.9236
Epoch 10 Batch 150 Loss 0.3095 Accuracy 0.9227
Epoch 10 Batch 200 Loss 0.3098 Accuracy 0.9228
Epoch 10 Batch 250 Loss 0.3107 Accuracy 0.9224
Epoch 10 Batch 300 Loss 0.3137 Accuracy 0.9217
Epoch 10 Batch 350 Loss 0.3150 Accuracy 0.9212
Epoch 10 Batch 400 Loss 0.3167 Accuracy 0.9211
Epoch 10 Batch 450 Loss 0.3186 Accuracy 0.9208
Epoch 10 Batch 500 Loss 0.3203 Accuracy 0.9204
Epoch 10 Batch 550 Loss 0.3213 Accuracy 0.9202
Epoch 10 Batch 600 Loss 0.3230 Accuracy 0.9199
Epoch 10 Batch 650 Loss 0.3233 Accuracy 0.9197
Epoch 10 Batch 700 Loss 0.3242 Accuracy 0.9195
Epoch 10 Batch 750 Loss 0.3249 Accuracy 0.9193
Epoch 10 Batch 800 Loss 0.3263 Accuracy 0.9191
Epoch 10 Batch 850 Loss 0.3275 Accuracy 0.9188
Epoch 10 Batch 900 Loss 0.3284 Accuracy 0.9188
Epoch 10 Batch 950 Loss 0.3290 Accuracy 0.9186
Epoch 10 Batch 1000 Loss 0.3299 Accuracy 0.9185
Epoch 10 Batch 1050 Loss 0.3306 Accuracy 0.9184
Epoch 10 Batch 1100 Loss 0.3310 Accuracy 0.9183
discarded batch 1110
Epoch 10 Batch 1150 Loss 0.3318 Accuracy 0.9182
Epoch 10 Batch 1200 Loss 0.3326 Accuracy 0.9181
Epoch 10 Batch 1250 Loss 0.3336 Accuracy 0.9179
Epoch 10 Batch 1300 Loss 0.3346 Accuracy 0.9177
Epoch 10 Batch 1350 Loss 0.3354 Accuracy 0.9176
Epoch 10 Batch 1400 Loss 0.3366 Accuracy 0.9174
Epoch 10 Batch 1450 Loss 0.3371 Accuracy 0.9173
Epoch 10 Batch 1500 Loss 0.3379 Accuracy 0.9171

wandb: WARNING Step must only increase in log calls.  Step 10 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33872604>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91696924>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-34
Epoch 10 Loss 0.3387 Accuracy 0.9170
Time taken for 1 epoch: 36.125720500946045 secs

epoch lasted: 36.12964415550232
Epoch 11 Batch 0 Loss 0.2786 Accuracy 0.9252
Epoch 11 Batch 50 Loss 0.3077 Accuracy 0.9228
Epoch 11 Batch 100 Loss 0.3039 Accuracy 0.9232
Epoch 11 Batch 150 Loss 0.3066 Accuracy 0.9226
Epoch 11 Batch 200 Loss 0.3070 Accuracy 0.9222
Epoch 11 Batch 250 Loss 0.3089 Accuracy 0.9216
Epoch 11 Batch 300 Loss 0.3109 Accuracy 0.9216
Epoch 11 Batch 350 Loss 0.3127 Accuracy 0.9215
Epoch 11 Batch 400 Loss 0.3145 Accuracy 0.9214
Epoch 11 Batch 450 Loss 0.3167 Accuracy 0.9211
discarded batch 462
Epoch 11 Batch 500 Loss 0.3178 Accuracy 0.9209
Epoch 11 Batch 550 Loss 0.3194 Accuracy 0.9205
Epoch 11 Batch 600 Loss 0.3206 Accuracy 0.9203
Epoch 11 Batch 650 Loss 0.3213 Accuracy 0.9201
Epoch 11 Batch 700 Loss 0.3223 Accuracy 0.9199
Epoch 11 Batch 750 Loss 0.3232 Accuracy 0.9197
Epoch 11 Batch 800 Loss 0.3240 Accuracy 0.9195
Epoch 11 Batch 850 Loss 0.3249 Accuracy 0.9194
Epoch 11 Batch 900 Loss 0.3249 Accuracy 0.9194
Epoch 11 Batch 950 Loss 0.3258 Accuracy 0.9193
Epoch 11 Batch 1000 Loss 0.3274 Accuracy 0.9190
Epoch 11 Batch 1050 Loss 0.3284 Accuracy 0.9189
Epoch 11 Batch 1100 Loss 0.3293 Accuracy 0.9187
Epoch 11 Batch 1150 Loss 0.3301 Accuracy 0.9186
Epoch 11 Batch 1200 Loss 0.3310 Accuracy 0.9184
Epoch 11 Batch 1250 Loss 0.3314 Accuracy 0.9183
Epoch 11 Batch 1300 Loss 0.3325 Accuracy 0.9182
Epoch 11 Batch 1350 Loss 0.3335 Accuracy 0.9179
Epoch 11 Batch 1400 Loss 0.3342 Accuracy 0.9178
Epoch 11 Batch 1450 Loss 0.3351 Accuracy 0.9177
Epoch 11 Batch 1500 Loss 0.3361 Accuracy 0.9175

wandb: WARNING Step must only increase in log calls.  Step 11 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3370788>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91740036>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 29; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.8978869>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86489487>}.

Epoch 11 Loss 0.3371 Accuracy 0.9174
Time taken for 1 epoch: 35.874279499053955 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.8979 Accuracy 0.8649

epoch lasted: 36.036022901535034
Epoch 12 Batch 0 Loss 0.2814 Accuracy 0.9219
Epoch 12 Batch 50 Loss 0.3025 Accuracy 0.9231
Epoch 12 Batch 100 Loss 0.3049 Accuracy 0.9234
Epoch 12 Batch 150 Loss 0.3063 Accuracy 0.9230
Epoch 12 Batch 200 Loss 0.3074 Accuracy 0.9230
discarded batch 213
Epoch 12 Batch 250 Loss 0.3094 Accuracy 0.9225
Epoch 12 Batch 300 Loss 0.3116 Accuracy 0.9218
Epoch 12 Batch 350 Loss 0.3124 Accuracy 0.9218
Epoch 12 Batch 400 Loss 0.3127 Accuracy 0.9216
Epoch 12 Batch 450 Loss 0.3142 Accuracy 0.9212
Epoch 12 Batch 500 Loss 0.3152 Accuracy 0.9210
Epoch 12 Batch 550 Loss 0.3164 Accuracy 0.9208
Epoch 12 Batch 600 Loss 0.3178 Accuracy 0.9206
Epoch 12 Batch 650 Loss 0.3191 Accuracy 0.9205
Epoch 12 Batch 700 Loss 0.3204 Accuracy 0.9203
Epoch 12 Batch 750 Loss 0.3217 Accuracy 0.9202
Epoch 12 Batch 800 Loss 0.3227 Accuracy 0.9200
Epoch 12 Batch 850 Loss 0.3236 Accuracy 0.9199
Epoch 12 Batch 900 Loss 0.3247 Accuracy 0.9197
Epoch 12 Batch 950 Loss 0.3257 Accuracy 0.9196
Epoch 12 Batch 1000 Loss 0.3267 Accuracy 0.9193
Epoch 12 Batch 1050 Loss 0.3277 Accuracy 0.9192
Epoch 12 Batch 1100 Loss 0.3288 Accuracy 0.9191
Epoch 12 Batch 1150 Loss 0.3296 Accuracy 0.9189
Epoch 12 Batch 1200 Loss 0.3307 Accuracy 0.9187
Epoch 12 Batch 1250 Loss 0.3315 Accuracy 0.9185
Epoch 12 Batch 1300 Loss 0.3327 Accuracy 0.9183
Epoch 12 Batch 1350 Loss 0.3336 Accuracy 0.9182
Epoch 12 Batch 1400 Loss 0.3344 Accuracy 0.9180
Epoch 12 Batch 1450 Loss 0.3350 Accuracy 0.9179
Epoch 12 Batch 1500 Loss 0.3356 Accuracy 0.9178

wandb: WARNING Step must only increase in log calls.  Step 12 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3361119>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9176631>}.

Epoch 12 Loss 0.3361 Accuracy 0.9177
Time taken for 1 epoch: 35.98063564300537 secs

epoch lasted: 35.985594272613525
Epoch 13 Batch 0 Loss 0.3589 Accuracy 0.9136
Epoch 13 Batch 50 Loss 0.2979 Accuracy 0.9240
Epoch 13 Batch 100 Loss 0.3026 Accuracy 0.9222
Epoch 13 Batch 150 Loss 0.3066 Accuracy 0.9219
Epoch 13 Batch 200 Loss 0.3076 Accuracy 0.9217
Epoch 13 Batch 250 Loss 0.3101 Accuracy 0.9216
Epoch 13 Batch 300 Loss 0.3119 Accuracy 0.9212
Epoch 13 Batch 350 Loss 0.3127 Accuracy 0.9212
Epoch 13 Batch 400 Loss 0.3134 Accuracy 0.9210
Epoch 13 Batch 450 Loss 0.3153 Accuracy 0.9207
Epoch 13 Batch 500 Loss 0.3166 Accuracy 0.9205
Epoch 13 Batch 550 Loss 0.3185 Accuracy 0.9204
Epoch 13 Batch 600 Loss 0.3201 Accuracy 0.9201
Epoch 13 Batch 650 Loss 0.3217 Accuracy 0.9198
Epoch 13 Batch 700 Loss 0.3227 Accuracy 0.9196
Epoch 13 Batch 750 Loss 0.3231 Accuracy 0.9195
Epoch 13 Batch 800 Loss 0.3241 Accuracy 0.9193
Epoch 13 Batch 850 Loss 0.3249 Accuracy 0.9192
Epoch 13 Batch 900 Loss 0.3259 Accuracy 0.9190
Epoch 13 Batch 950 Loss 0.3269 Accuracy 0.9188
Epoch 13 Batch 1000 Loss 0.3280 Accuracy 0.9186
Epoch 13 Batch 1050 Loss 0.3287 Accuracy 0.9184
Epoch 13 Batch 1100 Loss 0.3296 Accuracy 0.9183
Epoch 13 Batch 1150 Loss 0.3302 Accuracy 0.9182
Epoch 13 Batch 1200 Loss 0.3312 Accuracy 0.9181
Epoch 13 Batch 1250 Loss 0.3318 Accuracy 0.9180
Epoch 13 Batch 1300 Loss 0.3329 Accuracy 0.9178
Epoch 13 Batch 1350 Loss 0.3337 Accuracy 0.9178
Epoch 13 Batch 1400 Loss 0.3347 Accuracy 0.9176
Epoch 13 Batch 1450 Loss 0.3355 Accuracy 0.9174
Epoch 13 Batch 1500 Loss 0.3364 Accuracy 0.9173
discarded batch 1505

wandb: WARNING Step must only increase in log calls.  Step 13 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33707535>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9171827>}.

Epoch 13 Loss 0.3371 Accuracy 0.9172
Time taken for 1 epoch: 36.04056739807129 secs

epoch lasted: 36.04502558708191
Epoch 14 Batch 0 Loss 0.2561 Accuracy 0.9302
Epoch 14 Batch 50 Loss 0.2995 Accuracy 0.9243
Epoch 14 Batch 100 Loss 0.3023 Accuracy 0.9240
Epoch 14 Batch 150 Loss 0.3072 Accuracy 0.9229
Epoch 14 Batch 200 Loss 0.3076 Accuracy 0.9226
Epoch 14 Batch 250 Loss 0.3092 Accuracy 0.9224
Epoch 14 Batch 300 Loss 0.3093 Accuracy 0.9223
Epoch 14 Batch 350 Loss 0.3120 Accuracy 0.9217
Epoch 14 Batch 400 Loss 0.3141 Accuracy 0.9215
Epoch 14 Batch 450 Loss 0.3157 Accuracy 0.9212
Epoch 14 Batch 500 Loss 0.3175 Accuracy 0.9208
Epoch 14 Batch 550 Loss 0.3186 Accuracy 0.9205
Epoch 14 Batch 600 Loss 0.3200 Accuracy 0.9202
Epoch 14 Batch 650 Loss 0.3208 Accuracy 0.9200
discarded batch 666
Epoch 14 Batch 700 Loss 0.3216 Accuracy 0.9201
Epoch 14 Batch 750 Loss 0.3223 Accuracy 0.9200
Epoch 14 Batch 800 Loss 0.3232 Accuracy 0.9198
Epoch 14 Batch 850 Loss 0.3242 Accuracy 0.9196
Epoch 14 Batch 900 Loss 0.3250 Accuracy 0.9195
Epoch 14 Batch 950 Loss 0.3256 Accuracy 0.9193
Epoch 14 Batch 1000 Loss 0.3262 Accuracy 0.9192
Epoch 14 Batch 1050 Loss 0.3268 Accuracy 0.9190
Epoch 14 Batch 1100 Loss 0.3276 Accuracy 0.9190
Epoch 14 Batch 1150 Loss 0.3280 Accuracy 0.9189
Epoch 14 Batch 1200 Loss 0.3293 Accuracy 0.9187
Epoch 14 Batch 1250 Loss 0.3303 Accuracy 0.9185
Epoch 14 Batch 1300 Loss 0.3311 Accuracy 0.9183
Epoch 14 Batch 1350 Loss 0.3318 Accuracy 0.9183
Epoch 14 Batch 1400 Loss 0.3331 Accuracy 0.9180
Epoch 14 Batch 1450 Loss 0.3339 Accuracy 0.9179
Epoch 14 Batch 1500 Loss 0.3346 Accuracy 0.9178

wandb: WARNING Step must only increase in log calls.  Step 14 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33527365>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91769636>}.

Epoch 14 Loss 0.3353 Accuracy 0.9177
Time taken for 1 epoch: 35.956974506378174 secs

epoch lasted: 35.96104621887207
Epoch 15 Batch 0 Loss 0.3548 Accuracy 0.9203
Epoch 15 Batch 50 Loss 0.3091 Accuracy 0.9217
Epoch 15 Batch 100 Loss 0.3112 Accuracy 0.9211
Epoch 15 Batch 150 Loss 0.3110 Accuracy 0.9215
Epoch 15 Batch 200 Loss 0.3108 Accuracy 0.9215
Epoch 15 Batch 250 Loss 0.3116 Accuracy 0.9215
Epoch 15 Batch 300 Loss 0.3130 Accuracy 0.9211
Epoch 15 Batch 350 Loss 0.3133 Accuracy 0.9211
Epoch 15 Batch 400 Loss 0.3148 Accuracy 0.9209
Epoch 15 Batch 450 Loss 0.3152 Accuracy 0.9207
Epoch 15 Batch 500 Loss 0.3162 Accuracy 0.9206
Epoch 15 Batch 550 Loss 0.3174 Accuracy 0.9204
Epoch 15 Batch 600 Loss 0.3180 Accuracy 0.9202
Epoch 15 Batch 650 Loss 0.3193 Accuracy 0.9199
Epoch 15 Batch 700 Loss 0.3205 Accuracy 0.9198
Epoch 15 Batch 750 Loss 0.3214 Accuracy 0.9197
Epoch 15 Batch 800 Loss 0.3219 Accuracy 0.9197
Epoch 15 Batch 850 Loss 0.3230 Accuracy 0.9195
Epoch 15 Batch 900 Loss 0.3236 Accuracy 0.9194
Epoch 15 Batch 950 Loss 0.3246 Accuracy 0.9192
Epoch 15 Batch 1000 Loss 0.3258 Accuracy 0.9191
Epoch 15 Batch 1050 Loss 0.3263 Accuracy 0.9191
Epoch 15 Batch 1100 Loss 0.3273 Accuracy 0.9189
Epoch 15 Batch 1150 Loss 0.3283 Accuracy 0.9188
Epoch 15 Batch 1200 Loss 0.3294 Accuracy 0.9186
Epoch 15 Batch 1250 Loss 0.3301 Accuracy 0.9185
discarded batch 1295
Epoch 15 Batch 1300 Loss 0.3312 Accuracy 0.9183
Epoch 15 Batch 1350 Loss 0.3320 Accuracy 0.9183
Epoch 15 Batch 1400 Loss 0.3326 Accuracy 0.9182
Epoch 15 Batch 1450 Loss 0.3335 Accuracy 0.9181
Epoch 15 Batch 1500 Loss 0.3343 Accuracy 0.9179

wandb: WARNING Step must only increase in log calls.  Step 15 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33482847>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9178036>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-35
Epoch 15 Loss 0.3348 Accuracy 0.9178
Time taken for 1 epoch: 36.01287078857422 secs

epoch lasted: 36.01685357093811
Epoch 16 Batch 0 Loss 0.2574 Accuracy 0.9336
Epoch 16 Batch 50 Loss 0.3086 Accuracy 0.9222
Epoch 16 Batch 100 Loss 0.3061 Accuracy 0.9227
Epoch 16 Batch 150 Loss 0.3082 Accuracy 0.9220
Epoch 16 Batch 200 Loss 0.3097 Accuracy 0.9217
Epoch 16 Batch 250 Loss 0.3111 Accuracy 0.9215
Epoch 16 Batch 300 Loss 0.3112 Accuracy 0.9216
Epoch 16 Batch 350 Loss 0.3124 Accuracy 0.9213
Epoch 16 Batch 400 Loss 0.3132 Accuracy 0.9211
Epoch 16 Batch 450 Loss 0.3144 Accuracy 0.9207
Epoch 16 Batch 500 Loss 0.3154 Accuracy 0.9205
Epoch 16 Batch 550 Loss 0.3165 Accuracy 0.9203
Epoch 16 Batch 600 Loss 0.3175 Accuracy 0.9202
Epoch 16 Batch 650 Loss 0.3179 Accuracy 0.9202
Epoch 16 Batch 700 Loss 0.3193 Accuracy 0.9200
Epoch 16 Batch 750 Loss 0.3200 Accuracy 0.9199
Epoch 16 Batch 800 Loss 0.3209 Accuracy 0.9198
Epoch 16 Batch 850 Loss 0.3221 Accuracy 0.9195
Epoch 16 Batch 900 Loss 0.3231 Accuracy 0.9194
Epoch 16 Batch 950 Loss 0.3242 Accuracy 0.9192
Epoch 16 Batch 1000 Loss 0.3254 Accuracy 0.9191
Epoch 16 Batch 1050 Loss 0.3262 Accuracy 0.9189
Epoch 16 Batch 1100 Loss 0.3269 Accuracy 0.9188
Epoch 16 Batch 1150 Loss 0.3275 Accuracy 0.9187
Epoch 16 Batch 1200 Loss 0.3285 Accuracy 0.9185
Epoch 16 Batch 1250 Loss 0.3294 Accuracy 0.9184
Epoch 16 Batch 1300 Loss 0.3303 Accuracy 0.9182
Epoch 16 Batch 1350 Loss 0.3310 Accuracy 0.9181
Epoch 16 Batch 1400 Loss 0.3315 Accuracy 0.9181
Epoch 16 Batch 1450 Loss 0.3323 Accuracy 0.9179
Epoch 16 Batch 1500 Loss 0.3332 Accuracy 0.9178
discarded batch 1503

wandb: WARNING Step must only increase in log calls.  Step 16 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3337739>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.917676>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 29; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.9127225>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86456263>}.

Epoch 16 Loss 0.3338 Accuracy 0.9177
Time taken for 1 epoch: 36.271522521972656 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.9127 Accuracy 0.8646

epoch lasted: 36.427809953689575
Epoch 17 Batch 0 Loss 0.3454 Accuracy 0.9186
Epoch 17 Batch 50 Loss 0.3054 Accuracy 0.9226
Epoch 17 Batch 100 Loss 0.2987 Accuracy 0.9236
Epoch 17 Batch 150 Loss 0.3026 Accuracy 0.9229
Epoch 17 Batch 200 Loss 0.3049 Accuracy 0.9228
Epoch 17 Batch 250 Loss 0.3058 Accuracy 0.9225
Epoch 17 Batch 300 Loss 0.3079 Accuracy 0.9221
Epoch 17 Batch 350 Loss 0.3090 Accuracy 0.9221
Epoch 17 Batch 400 Loss 0.3123 Accuracy 0.9215
Epoch 17 Batch 450 Loss 0.3137 Accuracy 0.9212
Epoch 17 Batch 500 Loss 0.3152 Accuracy 0.9211
Epoch 17 Batch 550 Loss 0.3171 Accuracy 0.9208
Epoch 17 Batch 600 Loss 0.3180 Accuracy 0.9206
Epoch 17 Batch 650 Loss 0.3187 Accuracy 0.9205
Epoch 17 Batch 700 Loss 0.3201 Accuracy 0.9202
Epoch 17 Batch 750 Loss 0.3213 Accuracy 0.9201
Epoch 17 Batch 800 Loss 0.3220 Accuracy 0.9200
Epoch 17 Batch 850 Loss 0.3231 Accuracy 0.9198
Epoch 17 Batch 900 Loss 0.3242 Accuracy 0.9196
Epoch 17 Batch 950 Loss 0.3255 Accuracy 0.9194
Epoch 17 Batch 1000 Loss 0.3263 Accuracy 0.9192
Epoch 17 Batch 1050 Loss 0.3270 Accuracy 0.9192
Epoch 17 Batch 1100 Loss 0.3279 Accuracy 0.9190
Epoch 17 Batch 1150 Loss 0.3286 Accuracy 0.9189
Epoch 17 Batch 1200 Loss 0.3291 Accuracy 0.9188
Epoch 17 Batch 1250 Loss 0.3301 Accuracy 0.9187
Epoch 17 Batch 1300 Loss 0.3311 Accuracy 0.9185
discarded batch 1327
Epoch 17 Batch 1350 Loss 0.3319 Accuracy 0.9183
Epoch 17 Batch 1400 Loss 0.3326 Accuracy 0.9182
Epoch 17 Batch 1450 Loss 0.3335 Accuracy 0.9181
Epoch 17 Batch 1500 Loss 0.3343 Accuracy 0.9179

wandb: WARNING Step must only increase in log calls.  Step 17 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3350144>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91778964>}.

Epoch 17 Loss 0.3350 Accuracy 0.9178
Time taken for 1 epoch: 36.26112985610962 secs

epoch lasted: 36.26545286178589
Epoch 18 Batch 0 Loss 0.2896 Accuracy 0.9252
Epoch 18 Batch 50 Loss 0.2993 Accuracy 0.9241
Epoch 18 Batch 100 Loss 0.2962 Accuracy 0.9253
Epoch 18 Batch 150 Loss 0.2995 Accuracy 0.9249
Epoch 18 Batch 200 Loss 0.2999 Accuracy 0.9245
Epoch 18 Batch 250 Loss 0.3011 Accuracy 0.9242
Epoch 18 Batch 300 Loss 0.3046 Accuracy 0.9233
Epoch 18 Batch 350 Loss 0.3063 Accuracy 0.9229
Epoch 18 Batch 400 Loss 0.3083 Accuracy 0.9227
Epoch 18 Batch 450 Loss 0.3094 Accuracy 0.9225
Epoch 18 Batch 500 Loss 0.3109 Accuracy 0.9222
Epoch 18 Batch 550 Loss 0.3119 Accuracy 0.9219
Epoch 18 Batch 600 Loss 0.3133 Accuracy 0.9215
Epoch 18 Batch 650 Loss 0.3154 Accuracy 0.9212
Epoch 18 Batch 700 Loss 0.3160 Accuracy 0.9211
Epoch 18 Batch 750 Loss 0.3171 Accuracy 0.9210
Epoch 18 Batch 800 Loss 0.3179 Accuracy 0.9208
Epoch 18 Batch 850 Loss 0.3192 Accuracy 0.9205
Epoch 18 Batch 900 Loss 0.3205 Accuracy 0.9203
Epoch 18 Batch 950 Loss 0.3215 Accuracy 0.9201
Epoch 18 Batch 1000 Loss 0.3227 Accuracy 0.9199
Epoch 18 Batch 1050 Loss 0.3238 Accuracy 0.9197
Epoch 18 Batch 1100 Loss 0.3245 Accuracy 0.9196
Epoch 18 Batch 1150 Loss 0.3254 Accuracy 0.9195
Epoch 18 Batch 1200 Loss 0.3261 Accuracy 0.9193
discarded batch 1243
Epoch 18 Batch 1250 Loss 0.3268 Accuracy 0.9191
Epoch 18 Batch 1300 Loss 0.3274 Accuracy 0.9190
Epoch 18 Batch 1350 Loss 0.3282 Accuracy 0.9188
Epoch 18 Batch 1400 Loss 0.3292 Accuracy 0.9186
Epoch 18 Batch 1450 Loss 0.3302 Accuracy 0.9184
Epoch 18 Batch 1500 Loss 0.3310 Accuracy 0.9183

wandb: WARNING Step must only increase in log calls.  Step 18 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33190873>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91818964>}.

Epoch 18 Loss 0.3319 Accuracy 0.9182
Time taken for 1 epoch: 35.888779401779175 secs

epoch lasted: 35.893378496170044
Epoch 19 Batch 0 Loss 0.3019 Accuracy 0.9252
Epoch 19 Batch 50 Loss 0.3006 Accuracy 0.9253
Epoch 19 Batch 100 Loss 0.2976 Accuracy 0.9245
Epoch 19 Batch 150 Loss 0.3009 Accuracy 0.9241
Epoch 19 Batch 200 Loss 0.3030 Accuracy 0.9237
Epoch 19 Batch 250 Loss 0.3057 Accuracy 0.9231
Epoch 19 Batch 300 Loss 0.3074 Accuracy 0.9228
Epoch 19 Batch 350 Loss 0.3073 Accuracy 0.9227
Epoch 19 Batch 400 Loss 0.3085 Accuracy 0.9225
Epoch 19 Batch 450 Loss 0.3095 Accuracy 0.9223
Epoch 19 Batch 500 Loss 0.3112 Accuracy 0.9220
Epoch 19 Batch 550 Loss 0.3125 Accuracy 0.9218
Epoch 19 Batch 600 Loss 0.3139 Accuracy 0.9215
Epoch 19 Batch 650 Loss 0.3153 Accuracy 0.9212
Epoch 19 Batch 700 Loss 0.3162 Accuracy 0.9210
Epoch 19 Batch 750 Loss 0.3168 Accuracy 0.9209
Epoch 19 Batch 800 Loss 0.3177 Accuracy 0.9208
Epoch 19 Batch 850 Loss 0.3188 Accuracy 0.9206
Epoch 19 Batch 900 Loss 0.3195 Accuracy 0.9204
Epoch 19 Batch 950 Loss 0.3208 Accuracy 0.9202
discarded batch 1000
Epoch 19 Batch 1050 Loss 0.3228 Accuracy 0.9198
Epoch 19 Batch 1100 Loss 0.3237 Accuracy 0.9196
Epoch 19 Batch 1150 Loss 0.3250 Accuracy 0.9193
Epoch 19 Batch 1200 Loss 0.3258 Accuracy 0.9191
Epoch 19 Batch 1250 Loss 0.3267 Accuracy 0.9190
Epoch 19 Batch 1300 Loss 0.3274 Accuracy 0.9189
Epoch 19 Batch 1350 Loss 0.3284 Accuracy 0.9187
Epoch 19 Batch 1400 Loss 0.3293 Accuracy 0.9185
Epoch 19 Batch 1450 Loss 0.3300 Accuracy 0.9184
Epoch 19 Batch 1500 Loss 0.3311 Accuracy 0.9182

wandb: WARNING Step must only increase in log calls.  Step 19 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33210987>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91804916>}.

Epoch 19 Loss 0.3321 Accuracy 0.9180
Time taken for 1 epoch: 35.92307090759277 secs

epoch lasted: 35.92731213569641
Epoch 20 Batch 0 Loss 0.3379 Accuracy 0.9136
Epoch 20 Batch 50 Loss 0.3050 Accuracy 0.9230
Epoch 20 Batch 100 Loss 0.3054 Accuracy 0.9228
Epoch 20 Batch 150 Loss 0.3061 Accuracy 0.9224
Epoch 20 Batch 200 Loss 0.3060 Accuracy 0.9224
Epoch 20 Batch 250 Loss 0.3065 Accuracy 0.9227
Epoch 20 Batch 300 Loss 0.3071 Accuracy 0.9229
Epoch 20 Batch 350 Loss 0.3086 Accuracy 0.9225
Epoch 20 Batch 400 Loss 0.3094 Accuracy 0.9223
Epoch 20 Batch 450 Loss 0.3112 Accuracy 0.9220
Epoch 20 Batch 500 Loss 0.3127 Accuracy 0.9218
Epoch 20 Batch 550 Loss 0.3143 Accuracy 0.9216
Epoch 20 Batch 600 Loss 0.3164 Accuracy 0.9212
Epoch 20 Batch 650 Loss 0.3170 Accuracy 0.9209
Epoch 20 Batch 700 Loss 0.3182 Accuracy 0.9208
discarded batch 728
Epoch 20 Batch 750 Loss 0.3191 Accuracy 0.9207
Epoch 20 Batch 800 Loss 0.3201 Accuracy 0.9205
Epoch 20 Batch 850 Loss 0.3206 Accuracy 0.9205
Epoch 20 Batch 900 Loss 0.3220 Accuracy 0.9202
Epoch 20 Batch 950 Loss 0.3227 Accuracy 0.9201
Epoch 20 Batch 1000 Loss 0.3236 Accuracy 0.9199
Epoch 20 Batch 1050 Loss 0.3245 Accuracy 0.9197
Epoch 20 Batch 1100 Loss 0.3252 Accuracy 0.9196
Epoch 20 Batch 1150 Loss 0.3260 Accuracy 0.9194
Epoch 20 Batch 1200 Loss 0.3267 Accuracy 0.9193
Epoch 20 Batch 1250 Loss 0.3273 Accuracy 0.9192
Epoch 20 Batch 1300 Loss 0.3280 Accuracy 0.9190
Epoch 20 Batch 1350 Loss 0.3285 Accuracy 0.9189
Epoch 20 Batch 1400 Loss 0.3293 Accuracy 0.9188
Epoch 20 Batch 1450 Loss 0.3301 Accuracy 0.9186
Epoch 20 Batch 1500 Loss 0.3309 Accuracy 0.9185

wandb: WARNING Step must only increase in log calls.  Step 20 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33154285>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9183602>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-36
Epoch 20 Loss 0.3315 Accuracy 0.9184
Time taken for 1 epoch: 36.08319401741028 secs

epoch lasted: 36.08724665641785
Epoch 21 Batch 0 Loss 0.2461 Accuracy 0.9419
Epoch 21 Batch 50 Loss 0.2904 Accuracy 0.9264
Epoch 21 Batch 100 Loss 0.2960 Accuracy 0.9259
Epoch 21 Batch 150 Loss 0.2989 Accuracy 0.9246
Epoch 21 Batch 200 Loss 0.3027 Accuracy 0.9238
Epoch 21 Batch 250 Loss 0.3040 Accuracy 0.9235
Epoch 21 Batch 300 Loss 0.3063 Accuracy 0.9230
Epoch 21 Batch 350 Loss 0.3078 Accuracy 0.9226
Epoch 21 Batch 400 Loss 0.3097 Accuracy 0.9222
Epoch 21 Batch 450 Loss 0.3113 Accuracy 0.9218
Epoch 21 Batch 500 Loss 0.3119 Accuracy 0.9216
Epoch 21 Batch 550 Loss 0.3137 Accuracy 0.9213
Epoch 21 Batch 600 Loss 0.3143 Accuracy 0.9212
Epoch 21 Batch 650 Loss 0.3151 Accuracy 0.9210
Epoch 21 Batch 700 Loss 0.3164 Accuracy 0.9208
Epoch 21 Batch 750 Loss 0.3178 Accuracy 0.9204
discarded batch 757
Epoch 21 Batch 800 Loss 0.3188 Accuracy 0.9203
Epoch 21 Batch 850 Loss 0.3197 Accuracy 0.9200
Epoch 21 Batch 900 Loss 0.3207 Accuracy 0.9198
Epoch 21 Batch 950 Loss 0.3217 Accuracy 0.9196
Epoch 21 Batch 1000 Loss 0.3228 Accuracy 0.9195
Epoch 21 Batch 1050 Loss 0.3240 Accuracy 0.9192
Epoch 21 Batch 1100 Loss 0.3246 Accuracy 0.9191
Epoch 21 Batch 1150 Loss 0.3252 Accuracy 0.9190
Epoch 21 Batch 1200 Loss 0.3259 Accuracy 0.9189
Epoch 21 Batch 1250 Loss 0.3262 Accuracy 0.9188
Epoch 21 Batch 1300 Loss 0.3271 Accuracy 0.9186
Epoch 21 Batch 1350 Loss 0.3281 Accuracy 0.9184
Epoch 21 Batch 1400 Loss 0.3288 Accuracy 0.9183
Epoch 21 Batch 1450 Loss 0.3295 Accuracy 0.9182
Epoch 21 Batch 1500 Loss 0.3302 Accuracy 0.9181

wandb: WARNING Step must only increase in log calls.  Step 21 < 29; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33105943>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9179183>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 29; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.91485125>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8624585>}.

Epoch 21 Loss 0.3311 Accuracy 0.9179
Time taken for 1 epoch: 35.83887243270874 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.9149 Accuracy 0.8625

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
  e |dal |pro|mes|so |per |lo |cui |tan|ti|co|
lo |du|ca |mio |ma|e|stro |mio |in|te|so|
che |ben |ti |veg|gio |ben |di|scen|der |ti|co|
                                                                                                                                                                   
 e |già |e|stro |mio |an|cor |sa|li|gen|so|
in|fi|no al |par|la|vam |con |in|ten|ti|co|
e |an|cor |lo |sol |di |co|stui |in|ten|to|
 che |fu |puo|se |fa|re |con |l’ a|mor |ch’ a |be|ne|
que|sta |chie|sa in |que|sta |cor|po |ru|i|na|
or |qua |giù |do|ve ’l |sol |cor|po |sì |bel|la|
                                                                                                                                                                   
 a |de|stro |di|cen|dio |fa |me|de|li|na|
que|cen|ti e |cin|se |tu |vuo’ |ch’ i’ |fu’ |io |que|
quin|ci |le|ti|ma |mia |vi|ci|ma |vi|na|
 e |quin|ci |se|gna|te |più |lie|to |di|ste|so|
per |que|sta |gen|te |che |son |se|con|fi|ste|
e |io |fe|ce a |lui |la|gri|man|dò |chi|se|
                                                                                                                                                                   
 ne |la |sua |ca|gion |che |son |lan|do |giu|ste|
non |è |vea |cin|ge |con |es|sa |rot|to|
 mo|ve|sti|te |quan|to |lo|co o|ve |ve|der |bel|
e |per |lo |co|sto|re e |e |con |la |gui|da|
del |cui |cia|scun |sen|tì |da |sua |di|ste|sa|
                                                                                                                                                                   
 quan|d’ io |ma|e|stro |mio |di|sï|an|da|to|
fu |rot|to |sti|mo|è |con |la |mia |men|sa|
ma |per |lo |mio |fi|gliuol |de |la |cui |ma|to|
 di |cui |tan|to |ca|gion |mi |chie|se |bat|ten|to|
non |te|ma |per |chi |è |chi |è |lin|to|sto|
par|tì |da |cui |a |noi |e |per |le |gen|to|
                                                                                                                                                                   
 per |lo |du|ca |mio |du|ca |d’ u|na |spe|sto|
non |son |bea|tri|ce |mia |ca|gion |per |ar|to|
e |quei |che |ne |va |per |vo|stro |pec|ca|to|
 e |vi|vo |su|stan|ca |con |le |pec|ca|to|sto|
quin|ci |det|to a |con|vien |ch’ io |mi |con|ce|so|
ma |sì |che |tu |vuo’ |ch’ i’ |fu’ |io |u|l’ ac|que|sto|
                                                                                                                                                                  
 non |è |co|min|cia|scun |che |ti |gui|ste|so|
con |le |sue |bel|lin|gua |sì |fac|cia|scun |rot|to|
son |por|te|si |mo|ria |si |di|man|che|
 che |pria |par|se|gna|ta |sot|to |per |lo |net|to|
ma |pri|mo |ch’ è |con |la |sua |mia |lin|gua |sciol|to|
mi |pa|ce |tut|to |che |hai |con|ten|to|
                                                                                                                                                                   
 qua |giù |per |lo |mio |du|ca |sen|tì |lie|to|
co|me |ca|gion |la |mia |ca|gion |la |fron|te|
e |que|sta |mia |don|na |mia |di |que|sta |cer|to|
e |che |sot|to |son |ten|za |mia |fa|cea |ché |que|sto|
e |co|me a |cui |son |con|ten|za |di|let|to|
e |io |mi |s’ io |son |bea|tri|ce |du|sto|sto|
                                                                                                                                                                   
 vi|vo |si|ni|ma |non |è |da |si|gna|to|
e |quin|ci |mo|strò |giu|sti|zia |lor |ca|sto|
e |quin|ci |vien |per |qual |io |ri|ma|gna|to|
 e |se |quei |fu |e |non |per|ché |non |si |mo|ve|
già |e|ra|vam |par|la|gri|dan|do al |col|to|
io |sap|pi |che |chi|na|ti |par|la|vo|fe|
                                                                                                                                                                   
 a |co|me ’l |sol |ca|gion |che |son |o|gne |ro|
dis|se ’l |ma|e|stro |mio |dir |mi |strin|se|co|
io |cre|do |che |più |di |mil|lin|gua |sciol|ro|
in|tor|na|scen|de|re|si|cu|na |con |la |fa|ce|
ma |la|scia|van|no |già |e|ran |con|tem|pio|
                                                                                                                                                                               
 non |so |chi |sie|te |già |per |fe|ce |fon|da|
ed |el|li a |me |con |la |boc|ca |si |mos|se|
e |quin|ci e |quin|di |tor|ni a |ve|der |fon|da|
 cre|do |che |nul|la |con|ce|dir |ti |con|fes|sa|
con |la |fa|ce|le|re e |con |la |sua |fa|ma|
non |vo’ |che |più |co|me a |lui |la|scia|gno|sco|
                                                                                                                                                                   
 che |so|mi|nòs |a |far |se|gnor |fa |rat|to|
po|co |fa |me|co e |mal |più |fu |più |pres|so|
e |co|me ’l |mio |du|ca |mio |cor |ac|cor|to|
 che |quei |fu |chia|ro|pa |ne |le |spal|con |e |que|
ne |li oc|chi |miei |con|do|vo |tor|ti|re|
ne |le |spal|zo|gna|to |fu |a |sé |e |que|sto|
                                                                                                                                                                   
 par|lar |ca|po |suo |ar|ro|te |fa|ce|re|
a |me |fa |me|ro |cui |non |ne |l’ al|tro |sto|
ne |la |sua |o|ra |sem|pre |fa |ma|go|mo|
 e |dis|se a |ro|pa |con|vien |che |tu |ar|ci|co|
e |que|sta |par|te |sì |ch’ i’ |non |ve|sto|re|
ma |o|ve |per |far |ma|e|stro |pro|ce|ste|
                                                                                                                                                                   
 ché |ve|ren|du|to |re|va |con |ar|ren|sto|
e |chi|rón |il |qual |tu |sai |an|co |chi|
su |per |cui |ma|e|stro |vi|vo |con|ten|sto|sto|
 che |già |per |lo |mon|tar |a |ve|der |l’ al|tre |don|
or |s’ io |be|a|to |che |per |lo |con|giun|to|
que|sta |mia |di|scen|den|tro a |me |re|mo|stra|
                                                                                                                                                                   
 per |lo |mon|tar |di |quel|li |ch’ è |con|for|to|
e |io |fa|rai |co|stui |che ’l |lo|ro|ma|stra|
e |quei |che |di |te |ché |di |que|sta |por|to|
e |io |ca|gion |per |ma|ra|vi|ta |mia |na|scon|co|
per |che |par|la|men|ti |che |tu |i|pro|fon|do|
ne |la |mia |don|na |mia |vi|sta |gen|co|
                                                                                                                                                                   
 sì |è |o|dio |e |quei |che |ne |la |sua |fron|de|
per |ch’ el|li a |me |l’ uom |cui |tu |chie|des|se|
sot|to |li |mo|ria |sot|to |lei |si |fon|da|
 vi|vo |se|con|do |per |ch’ io |mi |con|do |spen|to?|
e |un |glo|rï|o|so |noi |pas|so |mar|cia|
in|fi|no a |noi |par|lar |con |la |mia |u|ra|
                                                                                                                                                                   
 e |un |al|tro |se|gna|ta |la |mia |par|la|
e |un |lu|me |che |le |pian|gen|to |so|la|
non |ti |co|stui |fa |la |sua |per|cos|sen|na|

epoch lasted: 519.0470323562622
(1900, 128)
Epoch 1 Batch 0 Loss 0.2372 Accuracy 0.9252
Epoch 1 Batch 50 Loss 0.2972 Accuracy 0.9219
Epoch 1 Batch 100 Loss 0.3005 Accuracy 0.9224
Epoch 1 Batch 150 Loss 0.3023 Accuracy 0.9220
Epoch 1 Batch 200 Loss 0.3047 Accuracy 0.9215
Epoch 1 Batch 250 Loss 0.3054 Accuracy 0.9219
Epoch 1 Batch 300 Loss 0.3076 Accuracy 0.9217
Epoch 1 Batch 350 Loss 0.3084 Accuracy 0.9217
Epoch 1 Batch 400 Loss 0.3101 Accuracy 0.9214
Epoch 1 Batch 450 Loss 0.3117 Accuracy 0.9212
Epoch 1 Batch 500 Loss 0.3129 Accuracy 0.9210
Epoch 1 Batch 550 Loss 0.3139 Accuracy 0.9209
Epoch 1 Batch 600 Loss 0.3144 Accuracy 0.9209
Epoch 1 Batch 650 Loss 0.3161 Accuracy 0.9206
Epoch 1 Batch 700 Loss 0.3174 Accuracy 0.9204
Epoch 1 Batch 750 Loss 0.3187 Accuracy 0.9202
Epoch 1 Batch 800 Loss 0.3194 Accuracy 0.9201
Epoch 1 Batch 850 Loss 0.3205 Accuracy 0.9199
discarded batch 874
Epoch 1 Batch 900 Loss 0.3212 Accuracy 0.9198
Epoch 1 Batch 950 Loss 0.3221 Accuracy 0.9196
Epoch 1 Batch 1000 Loss 0.3229 Accuracy 0.9195
Epoch 1 Batch 1050 Loss 0.3236 Accuracy 0.9194
Epoch 1 Batch 1100 Loss 0.3247 Accuracy 0.9192
Epoch 1 Batch 1150 Loss 0.3256 Accuracy 0.9191
Epoch 1 Batch 1200 Loss 0.3262 Accuracy 0.9190
Epoch 1 Batch 1250 Loss 0.3272 Accuracy 0.9188
Epoch 1 Batch 1300 Loss 0.3281 Accuracy 0.9186
Epoch 1 Batch 1350 Loss 0.3287 Accuracy 0.9185
Epoch 1 Batch 1400 Loss 0.3294 Accuracy 0.9184
Epoch 1 Batch 1450 Loss 0.3300 Accuracy 0.9184
Epoch 1 Batch 1500 Loss 0.3308 Accuracy 0.9183

wandb: WARNING Step must only increase in log calls.  Step 1 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3313404>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9181886>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 30; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.91931695>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8625692>}.

Epoch 1 Loss 0.3313 Accuracy 0.9182
Time taken for 1 epoch: 35.758777141571045 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.9193 Accuracy 0.8626

epoch lasted: 35.91341686248779
Epoch 2 Batch 0 Loss 0.2922 Accuracy 0.9169
Epoch 2 Batch 50 Loss 0.2928 Accuracy 0.9244
Epoch 2 Batch 100 Loss 0.2963 Accuracy 0.9245
Epoch 2 Batch 150 Loss 0.3014 Accuracy 0.9234
Epoch 2 Batch 200 Loss 0.3060 Accuracy 0.9229
Epoch 2 Batch 250 Loss 0.3074 Accuracy 0.9227
Epoch 2 Batch 300 Loss 0.3087 Accuracy 0.9224
Epoch 2 Batch 350 Loss 0.3101 Accuracy 0.9219
Epoch 2 Batch 400 Loss 0.3106 Accuracy 0.9218
Epoch 2 Batch 450 Loss 0.3119 Accuracy 0.9215
Epoch 2 Batch 500 Loss 0.3131 Accuracy 0.9213
Epoch 2 Batch 550 Loss 0.3139 Accuracy 0.9209
Epoch 2 Batch 600 Loss 0.3141 Accuracy 0.9208
Epoch 2 Batch 650 Loss 0.3151 Accuracy 0.9207
Epoch 2 Batch 700 Loss 0.3160 Accuracy 0.9205
Epoch 2 Batch 750 Loss 0.3165 Accuracy 0.9204
Epoch 2 Batch 800 Loss 0.3170 Accuracy 0.9202
discarded batch 841
Epoch 2 Batch 850 Loss 0.3180 Accuracy 0.9202
Epoch 2 Batch 900 Loss 0.3191 Accuracy 0.9200
Epoch 2 Batch 950 Loss 0.3201 Accuracy 0.9198
Epoch 2 Batch 1000 Loss 0.3211 Accuracy 0.9196
Epoch 2 Batch 1050 Loss 0.3222 Accuracy 0.9194
Epoch 2 Batch 1100 Loss 0.3228 Accuracy 0.9193
Epoch 2 Batch 1150 Loss 0.3236 Accuracy 0.9191
Epoch 2 Batch 1200 Loss 0.3246 Accuracy 0.9190
Epoch 2 Batch 1250 Loss 0.3258 Accuracy 0.9188
Epoch 2 Batch 1300 Loss 0.3267 Accuracy 0.9186
Epoch 2 Batch 1350 Loss 0.3272 Accuracy 0.9186
Epoch 2 Batch 1400 Loss 0.3283 Accuracy 0.9185
Epoch 2 Batch 1450 Loss 0.3289 Accuracy 0.9184
Epoch 2 Batch 1500 Loss 0.3295 Accuracy 0.9184

wandb: WARNING Step must only increase in log calls.  Step 2 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.33007494>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9182636>}.

Epoch 2 Loss 0.3301 Accuracy 0.9183
Time taken for 1 epoch: 35.77291703224182 secs

epoch lasted: 35.77764821052551
Epoch 3 Batch 0 Loss 0.2377 Accuracy 0.9369
Epoch 3 Batch 50 Loss 0.3058 Accuracy 0.9235
Epoch 3 Batch 100 Loss 0.3017 Accuracy 0.9237
Epoch 3 Batch 150 Loss 0.3029 Accuracy 0.9240
Epoch 3 Batch 200 Loss 0.3049 Accuracy 0.9236
discarded batch 205
Epoch 3 Batch 250 Loss 0.3063 Accuracy 0.9232
Epoch 3 Batch 300 Loss 0.3086 Accuracy 0.9227
Epoch 3 Batch 350 Loss 0.3100 Accuracy 0.9223
Epoch 3 Batch 400 Loss 0.3104 Accuracy 0.9224
Epoch 3 Batch 450 Loss 0.3105 Accuracy 0.9224
Epoch 3 Batch 500 Loss 0.3107 Accuracy 0.9223
Epoch 3 Batch 550 Loss 0.3112 Accuracy 0.9222
Epoch 3 Batch 600 Loss 0.3119 Accuracy 0.9221
Epoch 3 Batch 650 Loss 0.3128 Accuracy 0.9218
Epoch 3 Batch 700 Loss 0.3141 Accuracy 0.9214
Epoch 3 Batch 750 Loss 0.3148 Accuracy 0.9213
Epoch 3 Batch 800 Loss 0.3162 Accuracy 0.9210
Epoch 3 Batch 850 Loss 0.3173 Accuracy 0.9208
Epoch 3 Batch 900 Loss 0.3180 Accuracy 0.9205
Epoch 3 Batch 950 Loss 0.3187 Accuracy 0.9204
Epoch 3 Batch 1000 Loss 0.3198 Accuracy 0.9201
Epoch 3 Batch 1050 Loss 0.3204 Accuracy 0.9201
Epoch 3 Batch 1100 Loss 0.3210 Accuracy 0.9200
Epoch 3 Batch 1150 Loss 0.3223 Accuracy 0.9197
Epoch 3 Batch 1200 Loss 0.3236 Accuracy 0.9195
Epoch 3 Batch 1250 Loss 0.3245 Accuracy 0.9193
Epoch 3 Batch 1300 Loss 0.3252 Accuracy 0.9192
Epoch 3 Batch 1350 Loss 0.3261 Accuracy 0.9191
Epoch 3 Batch 1400 Loss 0.3266 Accuracy 0.9191
Epoch 3 Batch 1450 Loss 0.3273 Accuracy 0.9190
Epoch 3 Batch 1500 Loss 0.3283 Accuracy 0.9188

wandb: WARNING Step must only increase in log calls.  Step 3 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3287956>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9187762>}.

Epoch 3 Loss 0.3288 Accuracy 0.9188
Time taken for 1 epoch: 35.74501848220825 secs

epoch lasted: 35.761284828186035
Epoch 4 Batch 0 Loss 0.3413 Accuracy 0.9169
Epoch 4 Batch 50 Loss 0.2920 Accuracy 0.9252
Epoch 4 Batch 100 Loss 0.2989 Accuracy 0.9238
discarded batch 129
Epoch 4 Batch 150 Loss 0.2996 Accuracy 0.9237
Epoch 4 Batch 200 Loss 0.3023 Accuracy 0.9229
Epoch 4 Batch 250 Loss 0.3033 Accuracy 0.9225
Epoch 4 Batch 300 Loss 0.3040 Accuracy 0.9224
Epoch 4 Batch 350 Loss 0.3062 Accuracy 0.9221
Epoch 4 Batch 400 Loss 0.3071 Accuracy 0.9219
Epoch 4 Batch 450 Loss 0.3082 Accuracy 0.9218
Epoch 4 Batch 500 Loss 0.3090 Accuracy 0.9218
Epoch 4 Batch 550 Loss 0.3109 Accuracy 0.9216
Epoch 4 Batch 600 Loss 0.3122 Accuracy 0.9214
Epoch 4 Batch 650 Loss 0.3132 Accuracy 0.9212
Epoch 4 Batch 700 Loss 0.3141 Accuracy 0.9210
Epoch 4 Batch 750 Loss 0.3145 Accuracy 0.9209
Epoch 4 Batch 800 Loss 0.3158 Accuracy 0.9207
Epoch 4 Batch 850 Loss 0.3168 Accuracy 0.9205
Epoch 4 Batch 900 Loss 0.3178 Accuracy 0.9203
Epoch 4 Batch 950 Loss 0.3185 Accuracy 0.9202
Epoch 4 Batch 1000 Loss 0.3197 Accuracy 0.9200
Epoch 4 Batch 1050 Loss 0.3204 Accuracy 0.9199
Epoch 4 Batch 1100 Loss 0.3216 Accuracy 0.9196
Epoch 4 Batch 1150 Loss 0.3223 Accuracy 0.9195
Epoch 4 Batch 1200 Loss 0.3232 Accuracy 0.9194
Epoch 4 Batch 1250 Loss 0.3241 Accuracy 0.9193
Epoch 4 Batch 1300 Loss 0.3251 Accuracy 0.9192
Epoch 4 Batch 1350 Loss 0.3256 Accuracy 0.9191
Epoch 4 Batch 1400 Loss 0.3265 Accuracy 0.9189
Epoch 4 Batch 1450 Loss 0.3272 Accuracy 0.9188
Epoch 4 Batch 1500 Loss 0.3279 Accuracy 0.9187

wandb: WARNING Step must only increase in log calls.  Step 4 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3285276>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91858>}.

Epoch 4 Loss 0.3285 Accuracy 0.9186
Time taken for 1 epoch: 35.83773970603943 secs

epoch lasted: 35.8421049118042
Epoch 5 Batch 0 Loss 0.2295 Accuracy 0.9402
Epoch 5 Batch 50 Loss 0.2849 Accuracy 0.9262
Epoch 5 Batch 100 Loss 0.2895 Accuracy 0.9250
Epoch 5 Batch 150 Loss 0.2917 Accuracy 0.9246
Epoch 5 Batch 200 Loss 0.2950 Accuracy 0.9244
Epoch 5 Batch 250 Loss 0.2985 Accuracy 0.9235
Epoch 5 Batch 300 Loss 0.2997 Accuracy 0.9231
Epoch 5 Batch 350 Loss 0.3027 Accuracy 0.9227
Epoch 5 Batch 400 Loss 0.3050 Accuracy 0.9224
Epoch 5 Batch 450 Loss 0.3066 Accuracy 0.9221
Epoch 5 Batch 500 Loss 0.3078 Accuracy 0.9220
Epoch 5 Batch 550 Loss 0.3093 Accuracy 0.9218
Epoch 5 Batch 600 Loss 0.3114 Accuracy 0.9215
Epoch 5 Batch 650 Loss 0.3125 Accuracy 0.9213
discarded batch 693
Epoch 5 Batch 700 Loss 0.3133 Accuracy 0.9211
Epoch 5 Batch 750 Loss 0.3142 Accuracy 0.9210
Epoch 5 Batch 800 Loss 0.3151 Accuracy 0.9207
Epoch 5 Batch 850 Loss 0.3162 Accuracy 0.9205
Epoch 5 Batch 900 Loss 0.3177 Accuracy 0.9203
Epoch 5 Batch 950 Loss 0.3183 Accuracy 0.9202
Epoch 5 Batch 1000 Loss 0.3189 Accuracy 0.9201
Epoch 5 Batch 1050 Loss 0.3201 Accuracy 0.9198
Epoch 5 Batch 1100 Loss 0.3210 Accuracy 0.9197
Epoch 5 Batch 1150 Loss 0.3219 Accuracy 0.9196
Epoch 5 Batch 1200 Loss 0.3222 Accuracy 0.9196
Epoch 5 Batch 1250 Loss 0.3232 Accuracy 0.9195
Epoch 5 Batch 1300 Loss 0.3240 Accuracy 0.9194
Epoch 5 Batch 1350 Loss 0.3248 Accuracy 0.9193
Epoch 5 Batch 1400 Loss 0.3258 Accuracy 0.9192
Epoch 5 Batch 1450 Loss 0.3268 Accuracy 0.9190
Epoch 5 Batch 1500 Loss 0.3277 Accuracy 0.9189

wandb: WARNING Step must only increase in log calls.  Step 5 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32820326>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91883737>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-37
Epoch 5 Loss 0.3282 Accuracy 0.9188
Time taken for 1 epoch: 36.00784778594971 secs

epoch lasted: 36.01207876205444
Epoch 6 Batch 0 Loss 0.2871 Accuracy 0.9269
Epoch 6 Batch 50 Loss 0.2866 Accuracy 0.9279
Epoch 6 Batch 100 Loss 0.2915 Accuracy 0.9260
Epoch 6 Batch 150 Loss 0.2944 Accuracy 0.9249
Epoch 6 Batch 200 Loss 0.2969 Accuracy 0.9250
Epoch 6 Batch 250 Loss 0.2988 Accuracy 0.9242
Epoch 6 Batch 300 Loss 0.3020 Accuracy 0.9236
Epoch 6 Batch 350 Loss 0.3031 Accuracy 0.9235
Epoch 6 Batch 400 Loss 0.3052 Accuracy 0.9233
Epoch 6 Batch 450 Loss 0.3062 Accuracy 0.9231
Epoch 6 Batch 500 Loss 0.3072 Accuracy 0.9229
Epoch 6 Batch 550 Loss 0.3086 Accuracy 0.9224
Epoch 6 Batch 600 Loss 0.3096 Accuracy 0.9222
Epoch 6 Batch 650 Loss 0.3106 Accuracy 0.9219
Epoch 6 Batch 700 Loss 0.3113 Accuracy 0.9217
Epoch 6 Batch 750 Loss 0.3129 Accuracy 0.9214
Epoch 6 Batch 800 Loss 0.3146 Accuracy 0.9211
Epoch 6 Batch 850 Loss 0.3158 Accuracy 0.9209
Epoch 6 Batch 900 Loss 0.3169 Accuracy 0.9207
Epoch 6 Batch 950 Loss 0.3177 Accuracy 0.9206
Epoch 6 Batch 1000 Loss 0.3187 Accuracy 0.9205
Epoch 6 Batch 1050 Loss 0.3193 Accuracy 0.9204
discarded batch 1094
Epoch 6 Batch 1100 Loss 0.3202 Accuracy 0.9202
Epoch 6 Batch 1150 Loss 0.3212 Accuracy 0.9200
Epoch 6 Batch 1200 Loss 0.3223 Accuracy 0.9198
Epoch 6 Batch 1250 Loss 0.3230 Accuracy 0.9198
Epoch 6 Batch 1300 Loss 0.3241 Accuracy 0.9195
Epoch 6 Batch 1350 Loss 0.3249 Accuracy 0.9195
Epoch 6 Batch 1400 Loss 0.3253 Accuracy 0.9194
Epoch 6 Batch 1450 Loss 0.3262 Accuracy 0.9193
Epoch 6 Batch 1500 Loss 0.3269 Accuracy 0.9191

wandb: WARNING Step must only increase in log calls.  Step 6 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32748577>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91901004>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 30; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.91986305>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8636766>}.

Epoch 6 Loss 0.3275 Accuracy 0.9190
Time taken for 1 epoch: 35.89839434623718 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.9199 Accuracy 0.8637

epoch lasted: 36.0683970451355
Epoch 7 Batch 0 Loss 0.2896 Accuracy 0.9252
Epoch 7 Batch 50 Loss 0.3026 Accuracy 0.9232
Epoch 7 Batch 100 Loss 0.2970 Accuracy 0.9246
Epoch 7 Batch 150 Loss 0.2999 Accuracy 0.9238
Epoch 7 Batch 200 Loss 0.3034 Accuracy 0.9230
Epoch 7 Batch 250 Loss 0.3074 Accuracy 0.9224
Epoch 7 Batch 300 Loss 0.3070 Accuracy 0.9225
Epoch 7 Batch 350 Loss 0.3087 Accuracy 0.9221
Epoch 7 Batch 400 Loss 0.3084 Accuracy 0.9221
Epoch 7 Batch 450 Loss 0.3094 Accuracy 0.9219
Epoch 7 Batch 500 Loss 0.3100 Accuracy 0.9217
Epoch 7 Batch 550 Loss 0.3112 Accuracy 0.9215
Epoch 7 Batch 600 Loss 0.3122 Accuracy 0.9212
Epoch 7 Batch 650 Loss 0.3129 Accuracy 0.9212
Epoch 7 Batch 700 Loss 0.3132 Accuracy 0.9211
Epoch 7 Batch 750 Loss 0.3145 Accuracy 0.9208
Epoch 7 Batch 800 Loss 0.3153 Accuracy 0.9207
Epoch 7 Batch 850 Loss 0.3166 Accuracy 0.9205
Epoch 7 Batch 900 Loss 0.3174 Accuracy 0.9204
Epoch 7 Batch 950 Loss 0.3185 Accuracy 0.9203
Epoch 7 Batch 1000 Loss 0.3193 Accuracy 0.9202
Epoch 7 Batch 1050 Loss 0.3202 Accuracy 0.9201
Epoch 7 Batch 1100 Loss 0.3209 Accuracy 0.9199
Epoch 7 Batch 1150 Loss 0.3215 Accuracy 0.9197
Epoch 7 Batch 1200 Loss 0.3225 Accuracy 0.9196
Epoch 7 Batch 1250 Loss 0.3235 Accuracy 0.9195
discarded batch 1293
Epoch 7 Batch 1300 Loss 0.3245 Accuracy 0.9193
Epoch 7 Batch 1350 Loss 0.3252 Accuracy 0.9192
Epoch 7 Batch 1400 Loss 0.3259 Accuracy 0.9191
Epoch 7 Batch 1450 Loss 0.3268 Accuracy 0.9190
Epoch 7 Batch 1500 Loss 0.3275 Accuracy 0.9188

wandb: WARNING Step must only increase in log calls.  Step 7 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32823244>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9186797>}.

Epoch 7 Loss 0.3282 Accuracy 0.9187
Time taken for 1 epoch: 35.92403292655945 secs

epoch lasted: 35.928428649902344
Epoch 8 Batch 0 Loss 0.3223 Accuracy 0.9236
Epoch 8 Batch 50 Loss 0.2903 Accuracy 0.9263
Epoch 8 Batch 100 Loss 0.2926 Accuracy 0.9256
Epoch 8 Batch 150 Loss 0.2961 Accuracy 0.9247
Epoch 8 Batch 200 Loss 0.2984 Accuracy 0.9242
discarded batch 206
Epoch 8 Batch 250 Loss 0.2992 Accuracy 0.9240
Epoch 8 Batch 300 Loss 0.3001 Accuracy 0.9240
Epoch 8 Batch 350 Loss 0.3007 Accuracy 0.9241
Epoch 8 Batch 400 Loss 0.3014 Accuracy 0.9241
Epoch 8 Batch 450 Loss 0.3027 Accuracy 0.9238
Epoch 8 Batch 500 Loss 0.3041 Accuracy 0.9235
Epoch 8 Batch 550 Loss 0.3058 Accuracy 0.9232
Epoch 8 Batch 600 Loss 0.3070 Accuracy 0.9230
Epoch 8 Batch 650 Loss 0.3088 Accuracy 0.9227
Epoch 8 Batch 700 Loss 0.3103 Accuracy 0.9223
Epoch 8 Batch 750 Loss 0.3113 Accuracy 0.9220
Epoch 8 Batch 800 Loss 0.3122 Accuracy 0.9218
Epoch 8 Batch 850 Loss 0.3134 Accuracy 0.9215
Epoch 8 Batch 900 Loss 0.3142 Accuracy 0.9215
Epoch 8 Batch 950 Loss 0.3155 Accuracy 0.9212
Epoch 8 Batch 1000 Loss 0.3168 Accuracy 0.9210
Epoch 8 Batch 1050 Loss 0.3177 Accuracy 0.9208
Epoch 8 Batch 1100 Loss 0.3185 Accuracy 0.9207
Epoch 8 Batch 1150 Loss 0.3195 Accuracy 0.9205
Epoch 8 Batch 1200 Loss 0.3204 Accuracy 0.9203
Epoch 8 Batch 1250 Loss 0.3217 Accuracy 0.9201
Epoch 8 Batch 1300 Loss 0.3226 Accuracy 0.9199
Epoch 8 Batch 1350 Loss 0.3234 Accuracy 0.9197
Epoch 8 Batch 1400 Loss 0.3240 Accuracy 0.9196
Epoch 8 Batch 1450 Loss 0.3249 Accuracy 0.9194
Epoch 8 Batch 1500 Loss 0.3255 Accuracy 0.9193

wandb: WARNING Step must only increase in log calls.  Step 8 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32637757>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9191494>}.

Epoch 8 Loss 0.3264 Accuracy 0.9191
Time taken for 1 epoch: 35.885886907577515 secs

epoch lasted: 35.89018154144287
Epoch 9 Batch 0 Loss 0.3413 Accuracy 0.9120
discarded batch 13
Epoch 9 Batch 50 Loss 0.3001 Accuracy 0.9235
Epoch 9 Batch 100 Loss 0.2999 Accuracy 0.9238
Epoch 9 Batch 150 Loss 0.3003 Accuracy 0.9234
Epoch 9 Batch 200 Loss 0.2999 Accuracy 0.9237
Epoch 9 Batch 250 Loss 0.3002 Accuracy 0.9238
Epoch 9 Batch 300 Loss 0.3032 Accuracy 0.9233
Epoch 9 Batch 350 Loss 0.3042 Accuracy 0.9232
Epoch 9 Batch 400 Loss 0.3053 Accuracy 0.9230
Epoch 9 Batch 450 Loss 0.3067 Accuracy 0.9225
Epoch 9 Batch 500 Loss 0.3072 Accuracy 0.9224
Epoch 9 Batch 550 Loss 0.3085 Accuracy 0.9223
Epoch 9 Batch 600 Loss 0.3094 Accuracy 0.9220
Epoch 9 Batch 650 Loss 0.3102 Accuracy 0.9218
Epoch 9 Batch 700 Loss 0.3104 Accuracy 0.9218
Epoch 9 Batch 750 Loss 0.3117 Accuracy 0.9216
Epoch 9 Batch 800 Loss 0.3125 Accuracy 0.9215
Epoch 9 Batch 850 Loss 0.3139 Accuracy 0.9212
Epoch 9 Batch 900 Loss 0.3148 Accuracy 0.9210
Epoch 9 Batch 950 Loss 0.3158 Accuracy 0.9208
Epoch 9 Batch 1000 Loss 0.3169 Accuracy 0.9206
Epoch 9 Batch 1050 Loss 0.3176 Accuracy 0.9205
Epoch 9 Batch 1100 Loss 0.3182 Accuracy 0.9203
Epoch 9 Batch 1150 Loss 0.3189 Accuracy 0.9202
Epoch 9 Batch 1200 Loss 0.3197 Accuracy 0.9200
Epoch 9 Batch 1250 Loss 0.3204 Accuracy 0.9199
Epoch 9 Batch 1300 Loss 0.3213 Accuracy 0.9197
Epoch 9 Batch 1350 Loss 0.3219 Accuracy 0.9196
Epoch 9 Batch 1400 Loss 0.3226 Accuracy 0.9195
Epoch 9 Batch 1450 Loss 0.3235 Accuracy 0.9193
Epoch 9 Batch 1500 Loss 0.3243 Accuracy 0.9192

wandb: WARNING Step must only increase in log calls.  Step 9 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3250159>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9191323>}.

Epoch 9 Loss 0.3250 Accuracy 0.9191
Time taken for 1 epoch: 36.54922366142273 secs

epoch lasted: 36.55352807044983
Epoch 10 Batch 0 Loss 0.2512 Accuracy 0.9302
Epoch 10 Batch 50 Loss 0.2998 Accuracy 0.9226
Epoch 10 Batch 100 Loss 0.3001 Accuracy 0.9229
Epoch 10 Batch 150 Loss 0.2986 Accuracy 0.9231
Epoch 10 Batch 200 Loss 0.2999 Accuracy 0.9231
Epoch 10 Batch 250 Loss 0.3004 Accuracy 0.9230
Epoch 10 Batch 300 Loss 0.3021 Accuracy 0.9226
Epoch 10 Batch 350 Loss 0.3032 Accuracy 0.9224
Epoch 10 Batch 400 Loss 0.3051 Accuracy 0.9221
Epoch 10 Batch 450 Loss 0.3060 Accuracy 0.9220
Epoch 10 Batch 500 Loss 0.3072 Accuracy 0.9218
Epoch 10 Batch 550 Loss 0.3085 Accuracy 0.9215
Epoch 10 Batch 600 Loss 0.3096 Accuracy 0.9214
Epoch 10 Batch 650 Loss 0.3103 Accuracy 0.9212
Epoch 10 Batch 700 Loss 0.3111 Accuracy 0.9212
Epoch 10 Batch 750 Loss 0.3122 Accuracy 0.9211
Epoch 10 Batch 800 Loss 0.3131 Accuracy 0.9209
Epoch 10 Batch 850 Loss 0.3141 Accuracy 0.9208
Epoch 10 Batch 900 Loss 0.3152 Accuracy 0.9206
Epoch 10 Batch 950 Loss 0.3165 Accuracy 0.9203
discarded batch 954
Epoch 10 Batch 1000 Loss 0.3174 Accuracy 0.9202
Epoch 10 Batch 1050 Loss 0.3183 Accuracy 0.9200
Epoch 10 Batch 1100 Loss 0.3190 Accuracy 0.9200
Epoch 10 Batch 1150 Loss 0.3199 Accuracy 0.9198
Epoch 10 Batch 1200 Loss 0.3207 Accuracy 0.9197
Epoch 10 Batch 1250 Loss 0.3216 Accuracy 0.9196
Epoch 10 Batch 1300 Loss 0.3221 Accuracy 0.9195
Epoch 10 Batch 1350 Loss 0.3227 Accuracy 0.9194
Epoch 10 Batch 1400 Loss 0.3235 Accuracy 0.9192
Epoch 10 Batch 1450 Loss 0.3240 Accuracy 0.9191
Epoch 10 Batch 1500 Loss 0.3247 Accuracy 0.9190

wandb: WARNING Step must only increase in log calls.  Step 10 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32528716>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9189081>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-38
Epoch 10 Loss 0.3253 Accuracy 0.9189
Time taken for 1 epoch: 36.52794790267944 secs

epoch lasted: 36.541521310806274
Epoch 11 Batch 0 Loss 0.3185 Accuracy 0.9302
Epoch 11 Batch 50 Loss 0.2980 Accuracy 0.9259
Epoch 11 Batch 100 Loss 0.2953 Accuracy 0.9254
Epoch 11 Batch 150 Loss 0.2944 Accuracy 0.9254
Epoch 11 Batch 200 Loss 0.2968 Accuracy 0.9248
Epoch 11 Batch 250 Loss 0.2982 Accuracy 0.9243
Epoch 11 Batch 300 Loss 0.2994 Accuracy 0.9239
Epoch 11 Batch 350 Loss 0.3000 Accuracy 0.9237
Epoch 11 Batch 400 Loss 0.3020 Accuracy 0.9231
Epoch 11 Batch 450 Loss 0.3036 Accuracy 0.9228
Epoch 11 Batch 500 Loss 0.3049 Accuracy 0.9226
Epoch 11 Batch 550 Loss 0.3055 Accuracy 0.9225
Epoch 11 Batch 600 Loss 0.3063 Accuracy 0.9222
Epoch 11 Batch 650 Loss 0.3077 Accuracy 0.9221
Epoch 11 Batch 700 Loss 0.3084 Accuracy 0.9219
Epoch 11 Batch 750 Loss 0.3101 Accuracy 0.9217
Epoch 11 Batch 800 Loss 0.3110 Accuracy 0.9215
Epoch 11 Batch 850 Loss 0.3125 Accuracy 0.9212
Epoch 11 Batch 900 Loss 0.3136 Accuracy 0.9210
Epoch 11 Batch 950 Loss 0.3149 Accuracy 0.9209
Epoch 11 Batch 1000 Loss 0.3159 Accuracy 0.9207
Epoch 11 Batch 1050 Loss 0.3169 Accuracy 0.9205
Epoch 11 Batch 1100 Loss 0.3179 Accuracy 0.9203
Epoch 11 Batch 1150 Loss 0.3186 Accuracy 0.9202
Epoch 11 Batch 1200 Loss 0.3192 Accuracy 0.9201
Epoch 11 Batch 1250 Loss 0.3199 Accuracy 0.9200
Epoch 11 Batch 1300 Loss 0.3209 Accuracy 0.9198
Epoch 11 Batch 1350 Loss 0.3218 Accuracy 0.9197
Epoch 11 Batch 1400 Loss 0.3225 Accuracy 0.9196
Epoch 11 Batch 1450 Loss 0.3234 Accuracy 0.9194
discarded batch 1497
Epoch 11 Batch 1500 Loss 0.3240 Accuracy 0.9192

wandb: WARNING Step must only increase in log calls.  Step 11 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3247396>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9191655>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 30; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.9275373>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8631228>}.

Epoch 11 Loss 0.3247 Accuracy 0.9192
Time taken for 1 epoch: 36.386162519454956 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.9275 Accuracy 0.8631

epoch lasted: 36.54406380653381
Epoch 12 Batch 0 Loss 0.2783 Accuracy 0.9269
Epoch 12 Batch 50 Loss 0.2862 Accuracy 0.9276
Epoch 12 Batch 100 Loss 0.2894 Accuracy 0.9270
Epoch 12 Batch 150 Loss 0.2921 Accuracy 0.9262
Epoch 12 Batch 200 Loss 0.2953 Accuracy 0.9250
Epoch 12 Batch 250 Loss 0.2999 Accuracy 0.9239
Epoch 12 Batch 300 Loss 0.3006 Accuracy 0.9239
Epoch 12 Batch 350 Loss 0.3016 Accuracy 0.9237
Epoch 12 Batch 400 Loss 0.3028 Accuracy 0.9236
Epoch 12 Batch 450 Loss 0.3048 Accuracy 0.9234
Epoch 12 Batch 500 Loss 0.3062 Accuracy 0.9230
Epoch 12 Batch 550 Loss 0.3072 Accuracy 0.9227
Epoch 12 Batch 600 Loss 0.3087 Accuracy 0.9223
Epoch 12 Batch 650 Loss 0.3097 Accuracy 0.9222
Epoch 12 Batch 700 Loss 0.3108 Accuracy 0.9219
Epoch 12 Batch 750 Loss 0.3118 Accuracy 0.9218
Epoch 12 Batch 800 Loss 0.3129 Accuracy 0.9215
Epoch 12 Batch 850 Loss 0.3140 Accuracy 0.9213
Epoch 12 Batch 900 Loss 0.3150 Accuracy 0.9211
Epoch 12 Batch 950 Loss 0.3159 Accuracy 0.9209
Epoch 12 Batch 1000 Loss 0.3165 Accuracy 0.9208
Epoch 12 Batch 1050 Loss 0.3175 Accuracy 0.9207
discarded batch 1054
Epoch 12 Batch 1100 Loss 0.3185 Accuracy 0.9205
Epoch 12 Batch 1150 Loss 0.3196 Accuracy 0.9203
Epoch 12 Batch 1200 Loss 0.3203 Accuracy 0.9202
Epoch 12 Batch 1250 Loss 0.3210 Accuracy 0.9201
Epoch 12 Batch 1300 Loss 0.3218 Accuracy 0.9199
Epoch 12 Batch 1350 Loss 0.3224 Accuracy 0.9198
Epoch 12 Batch 1400 Loss 0.3234 Accuracy 0.9196
Epoch 12 Batch 1450 Loss 0.3240 Accuracy 0.9195
Epoch 12 Batch 1500 Loss 0.3248 Accuracy 0.9193

wandb: WARNING Step must only increase in log calls.  Step 12 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32541186>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9192406>}.

Epoch 12 Loss 0.3254 Accuracy 0.9192
Time taken for 1 epoch: 36.08002591133118 secs

epoch lasted: 36.084139585494995
Epoch 13 Batch 0 Loss 0.3501 Accuracy 0.9037
Epoch 13 Batch 50 Loss 0.2889 Accuracy 0.9251
Epoch 13 Batch 100 Loss 0.2927 Accuracy 0.9255
Epoch 13 Batch 150 Loss 0.2949 Accuracy 0.9254
Epoch 13 Batch 200 Loss 0.2955 Accuracy 0.9249
Epoch 13 Batch 250 Loss 0.2973 Accuracy 0.9242
Epoch 13 Batch 300 Loss 0.2986 Accuracy 0.9241
Epoch 13 Batch 350 Loss 0.3002 Accuracy 0.9238
Epoch 13 Batch 400 Loss 0.3019 Accuracy 0.9236
Epoch 13 Batch 450 Loss 0.3039 Accuracy 0.9231
Epoch 13 Batch 500 Loss 0.3051 Accuracy 0.9230
Epoch 13 Batch 550 Loss 0.3063 Accuracy 0.9228
Epoch 13 Batch 600 Loss 0.3070 Accuracy 0.9227
Epoch 13 Batch 650 Loss 0.3083 Accuracy 0.9225
Epoch 13 Batch 700 Loss 0.3089 Accuracy 0.9224
Epoch 13 Batch 750 Loss 0.3097 Accuracy 0.9223
Epoch 13 Batch 800 Loss 0.3109 Accuracy 0.9221
Epoch 13 Batch 850 Loss 0.3125 Accuracy 0.9218
Epoch 13 Batch 900 Loss 0.3134 Accuracy 0.9216
Epoch 13 Batch 950 Loss 0.3143 Accuracy 0.9214
Epoch 13 Batch 1000 Loss 0.3151 Accuracy 0.9212
Epoch 13 Batch 1050 Loss 0.3159 Accuracy 0.9212
Epoch 13 Batch 1100 Loss 0.3168 Accuracy 0.9210
Epoch 13 Batch 1150 Loss 0.3181 Accuracy 0.9207
Epoch 13 Batch 1200 Loss 0.3192 Accuracy 0.9205
Epoch 13 Batch 1250 Loss 0.3199 Accuracy 0.9204
Epoch 13 Batch 1300 Loss 0.3205 Accuracy 0.9203
discarded batch 1308
Epoch 13 Batch 1350 Loss 0.3214 Accuracy 0.9201
Epoch 13 Batch 1400 Loss 0.3218 Accuracy 0.9200
Epoch 13 Batch 1450 Loss 0.3227 Accuracy 0.9199
Epoch 13 Batch 1500 Loss 0.3238 Accuracy 0.9197

wandb: WARNING Step must only increase in log calls.  Step 13 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32421216>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9195859>}.

Epoch 13 Loss 0.3242 Accuracy 0.9196
Time taken for 1 epoch: 36.06767964363098 secs

epoch lasted: 36.071999073028564
Epoch 14 Batch 0 Loss 0.2520 Accuracy 0.9385
Epoch 14 Batch 50 Loss 0.2911 Accuracy 0.9242
Epoch 14 Batch 100 Loss 0.2950 Accuracy 0.9242
Epoch 14 Batch 150 Loss 0.2962 Accuracy 0.9244
discarded batch 167
Epoch 14 Batch 200 Loss 0.2972 Accuracy 0.9241
Epoch 14 Batch 250 Loss 0.2977 Accuracy 0.9240
Epoch 14 Batch 300 Loss 0.2986 Accuracy 0.9239
Epoch 14 Batch 350 Loss 0.3005 Accuracy 0.9233
Epoch 14 Batch 400 Loss 0.3025 Accuracy 0.9229
Epoch 14 Batch 450 Loss 0.3039 Accuracy 0.9228
Epoch 14 Batch 500 Loss 0.3047 Accuracy 0.9226
Epoch 14 Batch 550 Loss 0.3055 Accuracy 0.9224
Epoch 14 Batch 600 Loss 0.3071 Accuracy 0.9224
Epoch 14 Batch 650 Loss 0.3079 Accuracy 0.9222
Epoch 14 Batch 700 Loss 0.3090 Accuracy 0.9220
Epoch 14 Batch 750 Loss 0.3096 Accuracy 0.9218
Epoch 14 Batch 800 Loss 0.3111 Accuracy 0.9215
Epoch 14 Batch 850 Loss 0.3120 Accuracy 0.9213
Epoch 14 Batch 900 Loss 0.3131 Accuracy 0.9211
Epoch 14 Batch 950 Loss 0.3139 Accuracy 0.9210
Epoch 14 Batch 1000 Loss 0.3147 Accuracy 0.9209
Epoch 14 Batch 1050 Loss 0.3153 Accuracy 0.9208
Epoch 14 Batch 1100 Loss 0.3162 Accuracy 0.9207
Epoch 14 Batch 1150 Loss 0.3170 Accuracy 0.9205
Epoch 14 Batch 1200 Loss 0.3178 Accuracy 0.9204
Epoch 14 Batch 1250 Loss 0.3186 Accuracy 0.9203
Epoch 14 Batch 1300 Loss 0.3193 Accuracy 0.9202
Epoch 14 Batch 1350 Loss 0.3203 Accuracy 0.9200
Epoch 14 Batch 1400 Loss 0.3210 Accuracy 0.9198
Epoch 14 Batch 1450 Loss 0.3218 Accuracy 0.9196
Epoch 14 Batch 1500 Loss 0.3230 Accuracy 0.9195

wandb: WARNING Step must only increase in log calls.  Step 14 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32355455>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91936606>}.

Epoch 14 Loss 0.3236 Accuracy 0.9194
Time taken for 1 epoch: 36.07993769645691 secs

epoch lasted: 36.095418214797974
Epoch 15 Batch 0 Loss 0.3247 Accuracy 0.9186
Epoch 15 Batch 50 Loss 0.2901 Accuracy 0.9263
discarded batch 100
Epoch 15 Batch 150 Loss 0.2916 Accuracy 0.9258
Epoch 15 Batch 200 Loss 0.2924 Accuracy 0.9254
Epoch 15 Batch 250 Loss 0.2953 Accuracy 0.9251
Epoch 15 Batch 300 Loss 0.2974 Accuracy 0.9246
Epoch 15 Batch 350 Loss 0.2989 Accuracy 0.9242
Epoch 15 Batch 400 Loss 0.3001 Accuracy 0.9240
Epoch 15 Batch 450 Loss 0.3029 Accuracy 0.9234
Epoch 15 Batch 500 Loss 0.3037 Accuracy 0.9234
Epoch 15 Batch 550 Loss 0.3047 Accuracy 0.9232
Epoch 15 Batch 600 Loss 0.3058 Accuracy 0.9229
Epoch 15 Batch 650 Loss 0.3076 Accuracy 0.9227
Epoch 15 Batch 700 Loss 0.3088 Accuracy 0.9224
Epoch 15 Batch 750 Loss 0.3103 Accuracy 0.9220
Epoch 15 Batch 800 Loss 0.3113 Accuracy 0.9219
Epoch 15 Batch 850 Loss 0.3122 Accuracy 0.9217
Epoch 15 Batch 900 Loss 0.3135 Accuracy 0.9214
Epoch 15 Batch 950 Loss 0.3140 Accuracy 0.9214
Epoch 15 Batch 1000 Loss 0.3149 Accuracy 0.9212
Epoch 15 Batch 1050 Loss 0.3159 Accuracy 0.9210
Epoch 15 Batch 1100 Loss 0.3169 Accuracy 0.9208
Epoch 15 Batch 1150 Loss 0.3178 Accuracy 0.9206
Epoch 15 Batch 1200 Loss 0.3185 Accuracy 0.9205
Epoch 15 Batch 1250 Loss 0.3188 Accuracy 0.9205
Epoch 15 Batch 1300 Loss 0.3193 Accuracy 0.9204
Epoch 15 Batch 1350 Loss 0.3200 Accuracy 0.9203
Epoch 15 Batch 1400 Loss 0.3208 Accuracy 0.9202
Epoch 15 Batch 1450 Loss 0.3215 Accuracy 0.9200
Epoch 15 Batch 1500 Loss 0.3223 Accuracy 0.9199

wandb: WARNING Step must only increase in log calls.  Step 15 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32305783>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9198175>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-39
Epoch 15 Loss 0.3231 Accuracy 0.9198
Time taken for 1 epoch: 36.55317759513855 secs

epoch lasted: 36.55752348899841
Epoch 16 Batch 0 Loss 0.2844 Accuracy 0.9252
Epoch 16 Batch 50 Loss 0.2843 Accuracy 0.9258
Epoch 16 Batch 100 Loss 0.2880 Accuracy 0.9257
Epoch 16 Batch 150 Loss 0.2908 Accuracy 0.9250
Epoch 16 Batch 200 Loss 0.2935 Accuracy 0.9248
Epoch 16 Batch 250 Loss 0.2961 Accuracy 0.9243
Epoch 16 Batch 300 Loss 0.2972 Accuracy 0.9242
Epoch 16 Batch 350 Loss 0.2987 Accuracy 0.9240
discarded batch 390
Epoch 16 Batch 400 Loss 0.2999 Accuracy 0.9239
Epoch 16 Batch 450 Loss 0.3012 Accuracy 0.9239
Epoch 16 Batch 500 Loss 0.3023 Accuracy 0.9237
Epoch 16 Batch 550 Loss 0.3030 Accuracy 0.9234
Epoch 16 Batch 600 Loss 0.3038 Accuracy 0.9234
Epoch 16 Batch 650 Loss 0.3054 Accuracy 0.9229
Epoch 16 Batch 700 Loss 0.3062 Accuracy 0.9228
Epoch 16 Batch 750 Loss 0.3072 Accuracy 0.9227
Epoch 16 Batch 800 Loss 0.3082 Accuracy 0.9225
Epoch 16 Batch 850 Loss 0.3093 Accuracy 0.9222
Epoch 16 Batch 900 Loss 0.3106 Accuracy 0.9220
Epoch 16 Batch 950 Loss 0.3118 Accuracy 0.9218
Epoch 16 Batch 1000 Loss 0.3127 Accuracy 0.9215
Epoch 16 Batch 1050 Loss 0.3137 Accuracy 0.9213
Epoch 16 Batch 1100 Loss 0.3144 Accuracy 0.9212
Epoch 16 Batch 1150 Loss 0.3154 Accuracy 0.9210
Epoch 16 Batch 1200 Loss 0.3163 Accuracy 0.9209
Epoch 16 Batch 1250 Loss 0.3172 Accuracy 0.9207
Epoch 16 Batch 1300 Loss 0.3178 Accuracy 0.9206
Epoch 16 Batch 1350 Loss 0.3184 Accuracy 0.9205
Epoch 16 Batch 1400 Loss 0.3195 Accuracy 0.9203
Epoch 16 Batch 1450 Loss 0.3203 Accuracy 0.9201
Epoch 16 Batch 1500 Loss 0.3210 Accuracy 0.9200

wandb: WARNING Step must only increase in log calls.  Step 16 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32172373>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.91992474>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 30; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.9229787>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8626801>}.

Epoch 16 Loss 0.3217 Accuracy 0.9199
Time taken for 1 epoch: 36.33443593978882 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.9230 Accuracy 0.8627

epoch lasted: 36.50042963027954
Epoch 17 Batch 0 Loss 0.2198 Accuracy 0.9402
Epoch 17 Batch 50 Loss 0.2892 Accuracy 0.9251
Epoch 17 Batch 100 Loss 0.2937 Accuracy 0.9251
Epoch 17 Batch 150 Loss 0.2943 Accuracy 0.9249
Epoch 17 Batch 200 Loss 0.2953 Accuracy 0.9249
Epoch 17 Batch 250 Loss 0.2971 Accuracy 0.9243
Epoch 17 Batch 300 Loss 0.2976 Accuracy 0.9243
Epoch 17 Batch 350 Loss 0.2992 Accuracy 0.9238
Epoch 17 Batch 400 Loss 0.3011 Accuracy 0.9235
Epoch 17 Batch 450 Loss 0.3025 Accuracy 0.9231
Epoch 17 Batch 500 Loss 0.3031 Accuracy 0.9230
Epoch 17 Batch 550 Loss 0.3044 Accuracy 0.9228
discarded batch 561
Epoch 17 Batch 600 Loss 0.3049 Accuracy 0.9228
Epoch 17 Batch 650 Loss 0.3061 Accuracy 0.9226
Epoch 17 Batch 700 Loss 0.3072 Accuracy 0.9225
Epoch 17 Batch 750 Loss 0.3079 Accuracy 0.9225
Epoch 17 Batch 800 Loss 0.3093 Accuracy 0.9222
Epoch 17 Batch 850 Loss 0.3101 Accuracy 0.9221
Epoch 17 Batch 900 Loss 0.3113 Accuracy 0.9219
Epoch 17 Batch 950 Loss 0.3123 Accuracy 0.9217
Epoch 17 Batch 1000 Loss 0.3132 Accuracy 0.9215
Epoch 17 Batch 1050 Loss 0.3141 Accuracy 0.9214
Epoch 17 Batch 1100 Loss 0.3149 Accuracy 0.9213
Epoch 17 Batch 1150 Loss 0.3160 Accuracy 0.9211
Epoch 17 Batch 1200 Loss 0.3169 Accuracy 0.9209
Epoch 17 Batch 1250 Loss 0.3176 Accuracy 0.9208
Epoch 17 Batch 1300 Loss 0.3184 Accuracy 0.9206
Epoch 17 Batch 1350 Loss 0.3192 Accuracy 0.9204
Epoch 17 Batch 1400 Loss 0.3200 Accuracy 0.9203
Epoch 17 Batch 1450 Loss 0.3209 Accuracy 0.9201
Epoch 17 Batch 1500 Loss 0.3215 Accuracy 0.9200

wandb: WARNING Step must only increase in log calls.  Step 17 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32198682>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9198615>}.

Epoch 17 Loss 0.3220 Accuracy 0.9199
Time taken for 1 epoch: 35.908724546432495 secs

epoch lasted: 35.91287422180176
Epoch 18 Batch 0 Loss 0.2430 Accuracy 0.9286
Epoch 18 Batch 50 Loss 0.2871 Accuracy 0.9263
Epoch 18 Batch 100 Loss 0.2864 Accuracy 0.9269
discarded batch 137
Epoch 18 Batch 150 Loss 0.2892 Accuracy 0.9263
Epoch 18 Batch 200 Loss 0.2906 Accuracy 0.9261
Epoch 18 Batch 250 Loss 0.2933 Accuracy 0.9254
Epoch 18 Batch 300 Loss 0.2950 Accuracy 0.9248
Epoch 18 Batch 350 Loss 0.2981 Accuracy 0.9242
Epoch 18 Batch 400 Loss 0.2986 Accuracy 0.9241
Epoch 18 Batch 450 Loss 0.3002 Accuracy 0.9237
Epoch 18 Batch 500 Loss 0.3017 Accuracy 0.9234
Epoch 18 Batch 550 Loss 0.3029 Accuracy 0.9232
Epoch 18 Batch 600 Loss 0.3035 Accuracy 0.9231
Epoch 18 Batch 650 Loss 0.3046 Accuracy 0.9229
Epoch 18 Batch 700 Loss 0.3054 Accuracy 0.9227
Epoch 18 Batch 750 Loss 0.3061 Accuracy 0.9226
Epoch 18 Batch 800 Loss 0.3074 Accuracy 0.9224
Epoch 18 Batch 850 Loss 0.3080 Accuracy 0.9223
Epoch 18 Batch 900 Loss 0.3087 Accuracy 0.9221
Epoch 18 Batch 950 Loss 0.3097 Accuracy 0.9219
Epoch 18 Batch 1000 Loss 0.3107 Accuracy 0.9217
Epoch 18 Batch 1050 Loss 0.3117 Accuracy 0.9215
Epoch 18 Batch 1100 Loss 0.3124 Accuracy 0.9214
Epoch 18 Batch 1150 Loss 0.3130 Accuracy 0.9212
Epoch 18 Batch 1200 Loss 0.3138 Accuracy 0.9211
Epoch 18 Batch 1250 Loss 0.3148 Accuracy 0.9209
Epoch 18 Batch 1300 Loss 0.3155 Accuracy 0.9208
Epoch 18 Batch 1350 Loss 0.3162 Accuracy 0.9207
Epoch 18 Batch 1400 Loss 0.3172 Accuracy 0.9205
Epoch 18 Batch 1450 Loss 0.3180 Accuracy 0.9204
Epoch 18 Batch 1500 Loss 0.3187 Accuracy 0.9203

wandb: WARNING Step must only increase in log calls.  Step 18 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31974468>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92011994>}.

Epoch 18 Loss 0.3197 Accuracy 0.9201
Time taken for 1 epoch: 35.94125962257385 secs

epoch lasted: 35.945544719696045
Epoch 19 Batch 0 Loss 0.2335 Accuracy 0.9369
Epoch 19 Batch 50 Loss 0.2867 Accuracy 0.9258
Epoch 19 Batch 100 Loss 0.2884 Accuracy 0.9257
discarded batch 115
Epoch 19 Batch 150 Loss 0.2877 Accuracy 0.9258
Epoch 19 Batch 200 Loss 0.2927 Accuracy 0.9247
Epoch 19 Batch 250 Loss 0.2932 Accuracy 0.9244
Epoch 19 Batch 300 Loss 0.2935 Accuracy 0.9244
Epoch 19 Batch 350 Loss 0.2940 Accuracy 0.9243
Epoch 19 Batch 400 Loss 0.2951 Accuracy 0.9240
Epoch 19 Batch 450 Loss 0.2968 Accuracy 0.9239
Epoch 19 Batch 500 Loss 0.2990 Accuracy 0.9235
Epoch 19 Batch 550 Loss 0.3004 Accuracy 0.9233
Epoch 19 Batch 600 Loss 0.3021 Accuracy 0.9230
Epoch 19 Batch 650 Loss 0.3030 Accuracy 0.9229
Epoch 19 Batch 700 Loss 0.3041 Accuracy 0.9228
Epoch 19 Batch 750 Loss 0.3049 Accuracy 0.9227
Epoch 19 Batch 800 Loss 0.3063 Accuracy 0.9225
Epoch 19 Batch 850 Loss 0.3079 Accuracy 0.9223
Epoch 19 Batch 900 Loss 0.3086 Accuracy 0.9221
Epoch 19 Batch 950 Loss 0.3104 Accuracy 0.9218
Epoch 19 Batch 1000 Loss 0.3117 Accuracy 0.9216
Epoch 19 Batch 1050 Loss 0.3128 Accuracy 0.9214
Epoch 19 Batch 1100 Loss 0.3138 Accuracy 0.9212
Epoch 19 Batch 1150 Loss 0.3148 Accuracy 0.9211
Epoch 19 Batch 1200 Loss 0.3160 Accuracy 0.9209
Epoch 19 Batch 1250 Loss 0.3168 Accuracy 0.9208
Epoch 19 Batch 1300 Loss 0.3177 Accuracy 0.9207
Epoch 19 Batch 1350 Loss 0.3184 Accuracy 0.9205
Epoch 19 Batch 1400 Loss 0.3194 Accuracy 0.9204
Epoch 19 Batch 1450 Loss 0.3201 Accuracy 0.9203
Epoch 19 Batch 1500 Loss 0.3208 Accuracy 0.9202

wandb: WARNING Step must only increase in log calls.  Step 19 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32162398>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9200652>}.

Epoch 19 Loss 0.3216 Accuracy 0.9201
Time taken for 1 epoch: 35.96513032913208 secs

epoch lasted: 35.968804359436035
Epoch 20 Batch 0 Loss 0.3177 Accuracy 0.9186
Epoch 20 Batch 50 Loss 0.2782 Accuracy 0.9278
Epoch 20 Batch 100 Loss 0.2843 Accuracy 0.9262
Epoch 20 Batch 150 Loss 0.2889 Accuracy 0.9257
Epoch 20 Batch 200 Loss 0.2930 Accuracy 0.9251
Epoch 20 Batch 250 Loss 0.2933 Accuracy 0.9252
Epoch 20 Batch 300 Loss 0.2958 Accuracy 0.9244
Epoch 20 Batch 350 Loss 0.2967 Accuracy 0.9241
Epoch 20 Batch 400 Loss 0.2984 Accuracy 0.9237
Epoch 20 Batch 450 Loss 0.2999 Accuracy 0.9235
Epoch 20 Batch 500 Loss 0.3010 Accuracy 0.9233
Epoch 20 Batch 550 Loss 0.3022 Accuracy 0.9232
Epoch 20 Batch 600 Loss 0.3037 Accuracy 0.9229
Epoch 20 Batch 650 Loss 0.3047 Accuracy 0.9227
Epoch 20 Batch 700 Loss 0.3057 Accuracy 0.9224
Epoch 20 Batch 750 Loss 0.3067 Accuracy 0.9223
discarded batch 758
Epoch 20 Batch 800 Loss 0.3080 Accuracy 0.9221
Epoch 20 Batch 850 Loss 0.3089 Accuracy 0.9220
Epoch 20 Batch 900 Loss 0.3096 Accuracy 0.9220
Epoch 20 Batch 950 Loss 0.3107 Accuracy 0.9218
Epoch 20 Batch 1000 Loss 0.3111 Accuracy 0.9218
Epoch 20 Batch 1050 Loss 0.3121 Accuracy 0.9216
Epoch 20 Batch 1100 Loss 0.3132 Accuracy 0.9215
Epoch 20 Batch 1150 Loss 0.3144 Accuracy 0.9214
Epoch 20 Batch 1200 Loss 0.3154 Accuracy 0.9212
Epoch 20 Batch 1250 Loss 0.3166 Accuracy 0.9210
Epoch 20 Batch 1300 Loss 0.3175 Accuracy 0.9209
Epoch 20 Batch 1350 Loss 0.3182 Accuracy 0.9207
Epoch 20 Batch 1400 Loss 0.3191 Accuracy 0.9206
Epoch 20 Batch 1450 Loss 0.3200 Accuracy 0.9204
Epoch 20 Batch 1500 Loss 0.3207 Accuracy 0.9203

wandb: WARNING Step must only increase in log calls.  Step 20 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.32161954>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92011887>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-40
Epoch 20 Loss 0.3216 Accuracy 0.9201
Time taken for 1 epoch: 36.33091926574707 secs

epoch lasted: 36.33478331565857
Epoch 21 Batch 0 Loss 0.2563 Accuracy 0.9319
Epoch 21 Batch 50 Loss 0.2930 Accuracy 0.9246
Epoch 21 Batch 100 Loss 0.2941 Accuracy 0.9248
Epoch 21 Batch 150 Loss 0.2920 Accuracy 0.9252
Epoch 21 Batch 200 Loss 0.2920 Accuracy 0.9249
Epoch 21 Batch 250 Loss 0.2928 Accuracy 0.9251
Epoch 21 Batch 300 Loss 0.2938 Accuracy 0.9250
Epoch 21 Batch 350 Loss 0.2942 Accuracy 0.9249
Epoch 21 Batch 400 Loss 0.2954 Accuracy 0.9246
Epoch 21 Batch 450 Loss 0.2967 Accuracy 0.9243
Epoch 21 Batch 500 Loss 0.2979 Accuracy 0.9241
Epoch 21 Batch 550 Loss 0.2994 Accuracy 0.9237
Epoch 21 Batch 600 Loss 0.3000 Accuracy 0.9235
Epoch 21 Batch 650 Loss 0.3013 Accuracy 0.9233
Epoch 21 Batch 700 Loss 0.3026 Accuracy 0.9230
Epoch 21 Batch 750 Loss 0.3035 Accuracy 0.9228
Epoch 21 Batch 800 Loss 0.3053 Accuracy 0.9225
discarded batch 809
Epoch 21 Batch 850 Loss 0.3066 Accuracy 0.9222
Epoch 21 Batch 900 Loss 0.3076 Accuracy 0.9221
Epoch 21 Batch 950 Loss 0.3087 Accuracy 0.9219
Epoch 21 Batch 1000 Loss 0.3095 Accuracy 0.9217
Epoch 21 Batch 1050 Loss 0.3106 Accuracy 0.9215
Epoch 21 Batch 1100 Loss 0.3116 Accuracy 0.9214
Epoch 21 Batch 1150 Loss 0.3129 Accuracy 0.9212
Epoch 21 Batch 1200 Loss 0.3138 Accuracy 0.9210
Epoch 21 Batch 1250 Loss 0.3148 Accuracy 0.9208
Epoch 21 Batch 1300 Loss 0.3155 Accuracy 0.9207
Epoch 21 Batch 1350 Loss 0.3165 Accuracy 0.9205
Epoch 21 Batch 1400 Loss 0.3173 Accuracy 0.9204
Epoch 21 Batch 1450 Loss 0.3181 Accuracy 0.9202
Epoch 21 Batch 1500 Loss 0.3187 Accuracy 0.9202

wandb: WARNING Step must only increase in log calls.  Step 21 < 30; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31949738>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9200738>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 30; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.92576635>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86411965>}.

Epoch 21 Loss 0.3195 Accuracy 0.9201
Time taken for 1 epoch: 35.95691132545471 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.9258 Accuracy 0.8641

params: k=4, t=0.9
la |tua |be|ni|gni|tà |non |pur |soc|cor|re|
a |chi |do|man|da |ma |mol|te |fï|a|te|
li|be|ra|men|te al |di|man|dar |pre|cor|re|
                                                                                                                                                                   
 quan|do |l’ e|mi|spe|rio |sia |sem|pro |fos|se |li|
quan|do |que|sto |cie|lo e |per|ché |di|ver|go|
che |tu |ve|ra|ti |sia |que|sto |ch’ i’ |vi|li|
                                                                                                                                                                   
 on|d’ io |do|vria |pur |cor|pi |la |sua |pos|sa|
on|d’ io |par|te |pres|so e |quei |che |sì |fat|ti|
ri|tor|no |sì |com’ |uom |fa |far |suo|sa|le|
e |vi|di |co|min|ciò |che |non |vi |con|ce|des|si|
par|le|var|ro |che |di |tut|ti |con|for|se|
e |ve|lo|re e |con |que|sta |dol|ce |pun|to|
                                                                                                                                                                   
 vol|gi|ra|va |con |tut|ta |sua |ra|gio|ce|
e |al |tri|sta |mia |don|na |che |son |cin|to|
vol|te |del |ma|no |spi|ri|to |di|ste|
e |co|sì |con |an|zi |po|scia |che |tu |cre|a|ti|
e |io |m’ ac|cor|si |mos|si |ve|der |suo|le|
an|dar |ve|drai |a |lui |a |que|sto |mo|di|
                                                                                                                                                                   
 per |lo |buon |ma|e|stro e |io |co|min|ciò |chi|
per|ché |sap|pi |che |tut|to |son |mo|ni|chi|
e |o|mai |a |lor |ve|der |non |ve|di|chi|
 con |que|sta |ce|ves|se |per |ch’ io |sia |cor|s’ io |
que|sti |per |se|con|do |che |per |que|sto |spon|da|
que|sta |re|gi|na |ce|tà |del |mon|do|me|
                                                                                                                                                                   
 an|cor |mi |par|la|gri|man|dar |per |ar|da|
li |mo|strar |di|sio |d’ i |cor|pi |do|no|me|
e |al|lor |mi |pa|rea |là |do|ve |cu|ra|
e |che |pria |far |co|min|ciò |ch’ io |sia |e |o|gne |va|
con |que|sti |se|gnor |ca|gion |mi |ce|des|se|
e |per|ché |tut|to ’l |gri|dò |ten|to |va|
                                                                                                                                                                    
 sì |co|me |ri|ma|ra|vi|tà |che |por|se|
per |ch’ io |sap|pi |che |per |que|sto |cie|li|va|
per |ch’ io |par|la|gri|man|do |re|gno |mor|se|
e |an|da|ti |la|ti |con |an|da|ti |mo|stra|le|
se |pria |che |per |far |non |fa|cea |con |i|ma|
ma |per|ché |non |fos|se |già |mai |non |bi|le|
                                                                                                                                                                   
 là |do|ve |la |dol|ce |lu|ce |suo|na|ma|
e |io |vi|di |lor |sì |com’ |io |di|let|to|
ed |el|li a |me |quei |che |tu |ti |si |scer|no|
in|ver’ |lo |mio |ma|lo |ve|des|se |che |s’ a|ves|si|
in|ten|ti |di|let|to |con |que|sto |cen|no|
ma |o|ve |ve|nim|mo in|tan|to |vol|si|sto|
                                                                                                                                                                   
 per |lo |mez|zo |cer|to |fa |che |si |fon|do|
non |è |quei |fu |sì |que|sti |nan|zi |giun|sto|
quan|to |que|sti |che |si |tor|ce|de|cen|do|
e |non |son |at|ten|za |mia |di|man|da |l’ in|ten|ti|
ma |per|so|vra |la |sua |di|man|da |se|gno|
ma |per|ché |tu |i|vi |par|lar |si |man|ti|
                                                                                                                                                                   
 e |io |ap|pres|so |quel |che |for|se in |do|
e |al|lor |con|vien |con |lei |fa|cea |fi|gliuo|lo|
ne |la |fac|cia |del |cie|lo e |in|ten|cio|do|
 e |io |e |la |vir|tù |che |fu |ma |na|sce|ma|
non |è |se|gnor |con |fa|ti|ma |se|gno|
co|sì |com’ |io |ma|e|stro |son |cor|po |se|
                                                                                                                                                                    
 e |que|sti |ma|e|stro |dì |an|co |suo|no|
e ’l |sol |che |giun|to |tut|to |lor |ve|de|gno|
che |pian|to |dal |cie|lo |per |que|sto |cie|lo|
e |ve|des|se |che |pe|rò |là |do|ve |si |spen|se|
e |la |ca|gion |di |lei |a |dir |si |puo|se|
non |m’ ac|cor|si |là |do|ve |per |più |bel|la|
                                                                                                                                                                   
 ma |el|la |mia |don|na |mia |che |si |puo|se|
co|min|ciò |el|l’ è |di|ven|to |ti |bel|la|
per|ché |mi |vol|si |veg|gi |sua |cor|se|gno|
e |al|lor |ve|di |lo|ro |son |per |lo |re|vel|la|
e |se |vol|si al |suon |del |ca|lor |ve|des|se|
e |non |al|lor |non |sia |e |di |so|gna|
                                                                                                                                                                    
 ché |la |mia |ca|gion |che |per |suo |de|gno|se|
e |di |re|gi|ra|gio|nan|zi |da |se|gna|
e ’l |som|mo |ben |ch’ a |ve|di |que|sto |mon|do|
e |un |pen|sier |car|dir |per|ché |non |son |qui|vi|so|
non |cre|det|to |lei |per|ché |noi |di|sde|gno|
non |ti |sia |giun|ti |fuor |cor|se|gnor |che |que|
                                                                                                                                                                   
 non |pos|si|cu|ra|men|tr’ io |li |si |de|gno|
a |co|min|ciò |el|la |spe|ra e |an|ca|ro|
son |sì |che |da |la |mia |vi|ta |più |le|gno|
e |co|sì |ch’ a |que|sta |cor|po |non |sia |cor|pria |ci|
co|me |quei |che |ve|nir |per|ché |na|sco|se|
ma |per|ché |la |mia |ca|gion |che |tu |ar|ci|
                                                                                                                                                                   
 e |co|me |noi |e |con |al|tro |di|spo|se|
per|ché |non |pian|ger |del |cor|po |di|ven|ti|
ro|ma|e|stro |mio |dir |per|ché |non |re|se|
e |se |pria |che |pria |che |sia |e |se |ben |m’ ac|cor|se|
ri|cen|za |ri|ma|ne e |poi |sem|pre |cin|ti|
per |ch’ io |par|la|men|te |del |suo |ver|go|se|
                                                                                                                                                                   
 e |io |a |lui |a |lui |che ’n |que|sto |cin|ti|
fi|gliuol |di |là |on|d’ el|li |tuoi |ri|ma|se|
e |io |cre|di |là |dal |qual |tu |vuo’ |di|gno|
 che |si |con|do |che |son |la|det|ti |di|pin|que|
co|min|ciai |co|lui |che |pos|se|gui|da|
e |com’ |e|ran |se|gnor |mio |ma|e|stro |cor|no|
                                                                                                                                                                   
 e |co|min|ciò |lo |mio |cor|po |di|scer|no|
in |po|scia |vi|so in |ter|na |vol|to |por|no|
e |io |pur |per |lo |cor |non |tor|men|zo|
che |si |sta |mia |me|de|re in |que|sta |mia |me|mo|ve|
in|co|me |quei |che |sia |per |que|sta |fon|da|
ma |per|ché |non |può |ca|po |che |sia |to|ve|
                                                                                                                                                                   
 co|sì |an|cor |ch’ al|cu|na |na|ta |fon|da|
vol|gen|do |si |vol|se |man |de|stra |sciol|ta|
son |tor|na|men|te |qui |si |far |for|se|gna|

epoch lasted: 524.4999680519104
(1900, 128)
Epoch 1 Batch 0 Loss 0.2943 Accuracy 0.9203
Epoch 1 Batch 50 Loss 0.2871 Accuracy 0.9266
discarded batch 82
Epoch 1 Batch 100 Loss 0.2848 Accuracy 0.9269
Epoch 1 Batch 150 Loss 0.2897 Accuracy 0.9256
Epoch 1 Batch 200 Loss 0.2926 Accuracy 0.9251
Epoch 1 Batch 250 Loss 0.2936 Accuracy 0.9249
Epoch 1 Batch 300 Loss 0.2947 Accuracy 0.9247
Epoch 1 Batch 350 Loss 0.2961 Accuracy 0.9243
Epoch 1 Batch 400 Loss 0.2968 Accuracy 0.9242
Epoch 1 Batch 450 Loss 0.2981 Accuracy 0.9239
Epoch 1 Batch 500 Loss 0.2991 Accuracy 0.9236
Epoch 1 Batch 550 Loss 0.3011 Accuracy 0.9232
Epoch 1 Batch 600 Loss 0.3019 Accuracy 0.9231
Epoch 1 Batch 650 Loss 0.3031 Accuracy 0.9230
Epoch 1 Batch 700 Loss 0.3037 Accuracy 0.9230
Epoch 1 Batch 750 Loss 0.3049 Accuracy 0.9227
Epoch 1 Batch 800 Loss 0.3062 Accuracy 0.9225
Epoch 1 Batch 850 Loss 0.3072 Accuracy 0.9223
Epoch 1 Batch 900 Loss 0.3083 Accuracy 0.9222
Epoch 1 Batch 950 Loss 0.3095 Accuracy 0.9218
Epoch 1 Batch 1000 Loss 0.3104 Accuracy 0.9217
Epoch 1 Batch 1050 Loss 0.3115 Accuracy 0.9216
Epoch 1 Batch 1100 Loss 0.3123 Accuracy 0.9215
Epoch 1 Batch 1150 Loss 0.3133 Accuracy 0.9213
Epoch 1 Batch 1200 Loss 0.3142 Accuracy 0.9211
Epoch 1 Batch 1250 Loss 0.3149 Accuracy 0.9210
Epoch 1 Batch 1300 Loss 0.3159 Accuracy 0.9208
Epoch 1 Batch 1350 Loss 0.3169 Accuracy 0.9207
Epoch 1 Batch 1400 Loss 0.3177 Accuracy 0.9205
Epoch 1 Batch 1450 Loss 0.3187 Accuracy 0.9203
Epoch 1 Batch 1500 Loss 0.3195 Accuracy 0.9202

wandb: WARNING Step must only increase in log calls.  Step 1 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3199699>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9201146>}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 31; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.9273998>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86301225>}.

Epoch 1 Loss 0.3200 Accuracy 0.9201
Time taken for 1 epoch: 35.546959400177 secs

discarded batch 15
Epoch 1 VALIDATION: Loss 0.9274 Accuracy 0.8630

epoch lasted: 35.70316004753113
Epoch 2 Batch 0 Loss 0.2760 Accuracy 0.9302
Epoch 2 Batch 50 Loss 0.2880 Accuracy 0.9265
Epoch 2 Batch 100 Loss 0.2890 Accuracy 0.9261
Epoch 2 Batch 150 Loss 0.2895 Accuracy 0.9260
Epoch 2 Batch 200 Loss 0.2907 Accuracy 0.9255
Epoch 2 Batch 250 Loss 0.2912 Accuracy 0.9250
Epoch 2 Batch 300 Loss 0.2932 Accuracy 0.9247
Epoch 2 Batch 350 Loss 0.2948 Accuracy 0.9244
Epoch 2 Batch 400 Loss 0.2961 Accuracy 0.9240
Epoch 2 Batch 450 Loss 0.2977 Accuracy 0.9236
Epoch 2 Batch 500 Loss 0.2990 Accuracy 0.9234
Epoch 2 Batch 550 Loss 0.2999 Accuracy 0.9232
Epoch 2 Batch 600 Loss 0.3012 Accuracy 0.9230
Epoch 2 Batch 650 Loss 0.3033 Accuracy 0.9227
Epoch 2 Batch 700 Loss 0.3049 Accuracy 0.9225
Epoch 2 Batch 750 Loss 0.3062 Accuracy 0.9223
Epoch 2 Batch 800 Loss 0.3070 Accuracy 0.9222
Epoch 2 Batch 850 Loss 0.3080 Accuracy 0.9221
Epoch 2 Batch 900 Loss 0.3088 Accuracy 0.9219
Epoch 2 Batch 950 Loss 0.3100 Accuracy 0.9217
Epoch 2 Batch 1000 Loss 0.3112 Accuracy 0.9216
Epoch 2 Batch 1050 Loss 0.3120 Accuracy 0.9215
Epoch 2 Batch 1100 Loss 0.3129 Accuracy 0.9213
Epoch 2 Batch 1150 Loss 0.3138 Accuracy 0.9212
discarded batch 1161
Epoch 2 Batch 1200 Loss 0.3142 Accuracy 0.9212
Epoch 2 Batch 1250 Loss 0.3150 Accuracy 0.9211
Epoch 2 Batch 1300 Loss 0.3159 Accuracy 0.9209
Epoch 2 Batch 1350 Loss 0.3165 Accuracy 0.9209
Epoch 2 Batch 1400 Loss 0.3171 Accuracy 0.9207
Epoch 2 Batch 1450 Loss 0.3181 Accuracy 0.9205
Epoch 2 Batch 1500 Loss 0.3189 Accuracy 0.9204

wandb: WARNING Step must only increase in log calls.  Step 2 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31936923>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9202583>}.

Epoch 2 Loss 0.3194 Accuracy 0.9203
Time taken for 1 epoch: 35.40041518211365 secs

epoch lasted: 35.40604209899902
Epoch 3 Batch 0 Loss 0.2552 Accuracy 0.9169
Epoch 3 Batch 50 Loss 0.2866 Accuracy 0.9269
Epoch 3 Batch 100 Loss 0.2858 Accuracy 0.9264
Epoch 3 Batch 150 Loss 0.2867 Accuracy 0.9260
Epoch 3 Batch 200 Loss 0.2903 Accuracy 0.9256
Epoch 3 Batch 250 Loss 0.2925 Accuracy 0.9251
Epoch 3 Batch 300 Loss 0.2935 Accuracy 0.9247
Epoch 3 Batch 350 Loss 0.2949 Accuracy 0.9243
Epoch 3 Batch 400 Loss 0.2953 Accuracy 0.9243
Epoch 3 Batch 450 Loss 0.2967 Accuracy 0.9242
Epoch 3 Batch 500 Loss 0.2966 Accuracy 0.9242
Epoch 3 Batch 550 Loss 0.2973 Accuracy 0.9241
Epoch 3 Batch 600 Loss 0.2988 Accuracy 0.9239
Epoch 3 Batch 650 Loss 0.2999 Accuracy 0.9237
Epoch 3 Batch 700 Loss 0.3013 Accuracy 0.9235
Epoch 3 Batch 750 Loss 0.3029 Accuracy 0.9230
Epoch 3 Batch 800 Loss 0.3040 Accuracy 0.9229
Epoch 3 Batch 850 Loss 0.3055 Accuracy 0.9226
Epoch 3 Batch 900 Loss 0.3067 Accuracy 0.9224
discarded batch 920
Epoch 3 Batch 950 Loss 0.3076 Accuracy 0.9224
Epoch 3 Batch 1000 Loss 0.3086 Accuracy 0.9222
Epoch 3 Batch 1050 Loss 0.3095 Accuracy 0.9221
Epoch 3 Batch 1100 Loss 0.3104 Accuracy 0.9219
Epoch 3 Batch 1150 Loss 0.3113 Accuracy 0.9217
Epoch 3 Batch 1200 Loss 0.3121 Accuracy 0.9216
Epoch 3 Batch 1250 Loss 0.3129 Accuracy 0.9214
Epoch 3 Batch 1300 Loss 0.3137 Accuracy 0.9213
Epoch 3 Batch 1350 Loss 0.3144 Accuracy 0.9211
Epoch 3 Batch 1400 Loss 0.3154 Accuracy 0.9210
Epoch 3 Batch 1450 Loss 0.3161 Accuracy 0.9209
Epoch 3 Batch 1500 Loss 0.3171 Accuracy 0.9207

wandb: WARNING Step must only increase in log calls.  Step 3 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31787652>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9205264>}.

Epoch 3 Loss 0.3179 Accuracy 0.9205
Time taken for 1 epoch: 35.59089207649231 secs

epoch lasted: 35.60845756530762
Epoch 4 Batch 0 Loss 0.2195 Accuracy 0.9419
Epoch 4 Batch 50 Loss 0.2890 Accuracy 0.9241
Epoch 4 Batch 100 Loss 0.2854 Accuracy 0.9255
Epoch 4 Batch 150 Loss 0.2882 Accuracy 0.9253
Epoch 4 Batch 200 Loss 0.2889 Accuracy 0.9255
Epoch 4 Batch 250 Loss 0.2894 Accuracy 0.9254
Epoch 4 Batch 300 Loss 0.2912 Accuracy 0.9250
Epoch 4 Batch 350 Loss 0.2928 Accuracy 0.9246
Epoch 4 Batch 400 Loss 0.2951 Accuracy 0.9242
Epoch 4 Batch 450 Loss 0.2963 Accuracy 0.9240
Epoch 4 Batch 500 Loss 0.2980 Accuracy 0.9237
Epoch 4 Batch 550 Loss 0.2992 Accuracy 0.9234
Epoch 4 Batch 600 Loss 0.3005 Accuracy 0.9231
Epoch 4 Batch 650 Loss 0.3015 Accuracy 0.9229
Epoch 4 Batch 700 Loss 0.3031 Accuracy 0.9227
Epoch 4 Batch 750 Loss 0.3041 Accuracy 0.9225
Epoch 4 Batch 800 Loss 0.3048 Accuracy 0.9225
Epoch 4 Batch 850 Loss 0.3060 Accuracy 0.9223
Epoch 4 Batch 900 Loss 0.3071 Accuracy 0.9221
Epoch 4 Batch 950 Loss 0.3080 Accuracy 0.9220
Epoch 4 Batch 1000 Loss 0.3090 Accuracy 0.9218
Epoch 4 Batch 1050 Loss 0.3097 Accuracy 0.9218
Epoch 4 Batch 1100 Loss 0.3103 Accuracy 0.9217
Epoch 4 Batch 1150 Loss 0.3112 Accuracy 0.9215
Epoch 4 Batch 1200 Loss 0.3122 Accuracy 0.9213
Epoch 4 Batch 1250 Loss 0.3130 Accuracy 0.9213
Epoch 4 Batch 1300 Loss 0.3139 Accuracy 0.9211
Epoch 4 Batch 1350 Loss 0.3148 Accuracy 0.9209
Epoch 4 Batch 1400 Loss 0.3154 Accuracy 0.9208
discarded batch 1432
Epoch 4 Batch 1450 Loss 0.3164 Accuracy 0.9206
Epoch 4 Batch 1500 Loss 0.3171 Accuracy 0.9204

wandb: WARNING Step must only increase in log calls.  Step 4 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31764278>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9203269>}.

Epoch 4 Loss 0.3176 Accuracy 0.9203
Time taken for 1 epoch: 35.65608763694763 secs

epoch lasted: 35.660292863845825
Epoch 5 Batch 0 Loss 0.2593 Accuracy 0.9352
Epoch 5 Batch 50 Loss 0.2727 Accuracy 0.9292
Epoch 5 Batch 100 Loss 0.2801 Accuracy 0.9279
Epoch 5 Batch 150 Loss 0.2848 Accuracy 0.9265
discarded batch 178
Epoch 5 Batch 200 Loss 0.2853 Accuracy 0.9263
Epoch 5 Batch 250 Loss 0.2899 Accuracy 0.9254
Epoch 5 Batch 300 Loss 0.2910 Accuracy 0.9253
Epoch 5 Batch 350 Loss 0.2921 Accuracy 0.9252
Epoch 5 Batch 400 Loss 0.2937 Accuracy 0.9251
Epoch 5 Batch 450 Loss 0.2951 Accuracy 0.9247
Epoch 5 Batch 500 Loss 0.2958 Accuracy 0.9244
Epoch 5 Batch 550 Loss 0.2973 Accuracy 0.9242
Epoch 5 Batch 600 Loss 0.2991 Accuracy 0.9239
Epoch 5 Batch 650 Loss 0.2997 Accuracy 0.9237
Epoch 5 Batch 700 Loss 0.3004 Accuracy 0.9235
Epoch 5 Batch 750 Loss 0.3014 Accuracy 0.9234
Epoch 5 Batch 800 Loss 0.3024 Accuracy 0.9233
Epoch 5 Batch 850 Loss 0.3034 Accuracy 0.9231
Epoch 5 Batch 900 Loss 0.3051 Accuracy 0.9228
Epoch 5 Batch 950 Loss 0.3058 Accuracy 0.9227
Epoch 5 Batch 1000 Loss 0.3072 Accuracy 0.9223
Epoch 5 Batch 1050 Loss 0.3083 Accuracy 0.9222
Epoch 5 Batch 1100 Loss 0.3090 Accuracy 0.9221
Epoch 5 Batch 1150 Loss 0.3101 Accuracy 0.9220
Epoch 5 Batch 1200 Loss 0.3107 Accuracy 0.9219
Epoch 5 Batch 1250 Loss 0.3119 Accuracy 0.9217
Epoch 5 Batch 1300 Loss 0.3130 Accuracy 0.9215
Epoch 5 Batch 1350 Loss 0.3138 Accuracy 0.9213
Epoch 5 Batch 1400 Loss 0.3144 Accuracy 0.9212
Epoch 5 Batch 1450 Loss 0.3150 Accuracy 0.9211
Epoch 5 Batch 1500 Loss 0.3157 Accuracy 0.9210

wandb: WARNING Step must only increase in log calls.  Step 5 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31657508>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9208663>}.

Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-41
Epoch 5 Loss 0.3166 Accuracy 0.9209
Time taken for 1 epoch: 35.91714358329773 secs

epoch lasted: 35.92120718955994
Epoch 6 Batch 0 Loss 0.2770 Accuracy 0.9302
Epoch 6 Batch 50 Loss 0.2746 Accuracy 0.9290
Epoch 6 Batch 100 Loss 0.2808 Accuracy 0.9273
Epoch 6 Batch 150 Loss 0.2861 Accuracy 0.9264
Epoch 6 Batch 200 Loss 0.2885 Accuracy 0.9257
Epoch 6 Batch 250 Loss 0.2904 Accuracy 0.9253
Epoch 6 Batch 300 Loss 0.2916 Accuracy 0.9251
Epoch 6 Batch 350 Loss 0.2938 Accuracy 0.9248
Epoch 6 Batch 400 Loss 0.2947 Accuracy 0.9247
Epoch 6 Batch 450 Loss 0.2956 Accuracy 0.9244
Epoch 6 Batch 500 Loss 0.2968 Accuracy 0.9241
Epoch 6 Batch 550 Loss 0.2984 Accuracy 0.9238
Epoch 6 Batch 600 Loss 0.2998 Accuracy 0.9237
Epoch 6 Batch 650 Loss 0.3008 Accuracy 0.9235
Epoch 6 Batch 700 Loss 0.3023 Accuracy 0.9233
Epoch 6 Batch 750 Loss 0.3033 Accuracy 0.9231
Epoch 6 Batch 800 Loss 0.3042 Accuracy 0.9230
Epoch 6 Batch 850 Loss 0.3053 Accuracy 0.9229
Epoch 6 Batch 900 Loss 0.3066 Accuracy 0.9226
Epoch 6 Batch 950 Loss 0.3078 Accuracy 0.9224
discarded batch 984
Epoch 6 Batch 1000 Loss 0.3086 Accuracy 0.9223
Epoch 6 Batch 1050 Loss 0.3093 Accuracy 0.9221
Epoch 6 Batch 1100 Loss 0.3100 Accuracy 0.9221
Epoch 6 Batch 1150 Loss 0.3104 Accuracy 0.9220
Epoch 6 Batch 1200 Loss 0.3112 Accuracy 0.9218
Epoch 6 Batch 1250 Loss 0.3120 Accuracy 0.9217
Epoch 6 Batch 1300 Loss 0.3127 Accuracy 0.9215
Epoch 6 Batch 1350 Loss 0.3133 Accuracy 0.9214
Epoch 6 Batch 1400 Loss 0.3141 Accuracy 0.9212
Epoch 6 Batch 1450 Loss 0.3148 Accuracy 0.9211
Epoch 6 Batch 1500 Loss 0.3155 Accuracy 0.9209

wandb: WARNING Step must only increase in log calls.  Step 6 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3162419>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9208395>}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 31; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.93738323>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86312294>}.

Epoch 6 Loss 0.3162 Accuracy 0.9208
Time taken for 1 epoch: 35.94206976890564 secs

discarded batch 15
Epoch 6 VALIDATION: Loss 0.9374 Accuracy 0.8631

epoch lasted: 36.1006178855896
Epoch 7 Batch 0 Loss 0.3497 Accuracy 0.9136
Epoch 7 Batch 50 Loss 0.2900 Accuracy 0.9241
Epoch 7 Batch 100 Loss 0.2888 Accuracy 0.9247
Epoch 7 Batch 150 Loss 0.2927 Accuracy 0.9241
Epoch 7 Batch 200 Loss 0.2933 Accuracy 0.9240
Epoch 7 Batch 250 Loss 0.2940 Accuracy 0.9243
Epoch 7 Batch 300 Loss 0.2956 Accuracy 0.9242
Epoch 7 Batch 350 Loss 0.2964 Accuracy 0.9239
Epoch 7 Batch 400 Loss 0.2977 Accuracy 0.9237
Epoch 7 Batch 450 Loss 0.2989 Accuracy 0.9234
Epoch 7 Batch 500 Loss 0.3000 Accuracy 0.9233
Epoch 7 Batch 550 Loss 0.3002 Accuracy 0.9233
Epoch 7 Batch 600 Loss 0.3013 Accuracy 0.9231
Epoch 7 Batch 650 Loss 0.3019 Accuracy 0.9230
Epoch 7 Batch 700 Loss 0.3026 Accuracy 0.9229
Epoch 7 Batch 750 Loss 0.3033 Accuracy 0.9228
discarded batch 795
Epoch 7 Batch 800 Loss 0.3048 Accuracy 0.9225
Epoch 7 Batch 850 Loss 0.3061 Accuracy 0.9224
Epoch 7 Batch 900 Loss 0.3069 Accuracy 0.9223
Epoch 7 Batch 950 Loss 0.3081 Accuracy 0.9221
Epoch 7 Batch 1000 Loss 0.3090 Accuracy 0.9220
Epoch 7 Batch 1050 Loss 0.3101 Accuracy 0.9218
Epoch 7 Batch 1100 Loss 0.3107 Accuracy 0.9216
Epoch 7 Batch 1150 Loss 0.3116 Accuracy 0.9214
Epoch 7 Batch 1200 Loss 0.3122 Accuracy 0.9212
Epoch 7 Batch 1250 Loss 0.3129 Accuracy 0.9211
Epoch 7 Batch 1300 Loss 0.3135 Accuracy 0.9210
Epoch 7 Batch 1350 Loss 0.3141 Accuracy 0.9209
Epoch 7 Batch 1400 Loss 0.3146 Accuracy 0.9209
Epoch 7 Batch 1450 Loss 0.3154 Accuracy 0.9209
Epoch 7 Batch 1500 Loss 0.3163 Accuracy 0.9207

wandb: WARNING Step must only increase in log calls.  Step 7 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3169346>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92062074>}.

Epoch 7 Loss 0.3169 Accuracy 0.9206
Time taken for 1 epoch: 36.405807971954346 secs

epoch lasted: 36.410354137420654
Epoch 8 Batch 0 Loss 0.2795 Accuracy 0.9286
Epoch 8 Batch 50 Loss 0.2777 Accuracy 0.9279
Epoch 8 Batch 100 Loss 0.2831 Accuracy 0.9259
Epoch 8 Batch 150 Loss 0.2835 Accuracy 0.9266
Epoch 8 Batch 200 Loss 0.2839 Accuracy 0.9261
Epoch 8 Batch 250 Loss 0.2858 Accuracy 0.9259
discarded batch 278
Epoch 8 Batch 300 Loss 0.2865 Accuracy 0.9255
Epoch 8 Batch 350 Loss 0.2871 Accuracy 0.9255
Epoch 8 Batch 400 Loss 0.2908 Accuracy 0.9248
Epoch 8 Batch 450 Loss 0.2922 Accuracy 0.9245
Epoch 8 Batch 500 Loss 0.2935 Accuracy 0.9244
Epoch 8 Batch 550 Loss 0.2945 Accuracy 0.9242
Epoch 8 Batch 600 Loss 0.2963 Accuracy 0.9239
Epoch 8 Batch 650 Loss 0.2979 Accuracy 0.9236
Epoch 8 Batch 700 Loss 0.3000 Accuracy 0.9233
Epoch 8 Batch 750 Loss 0.3011 Accuracy 0.9230
Epoch 8 Batch 800 Loss 0.3025 Accuracy 0.9228
Epoch 8 Batch 850 Loss 0.3033 Accuracy 0.9227
Epoch 8 Batch 900 Loss 0.3045 Accuracy 0.9225
Epoch 8 Batch 950 Loss 0.3056 Accuracy 0.9223
Epoch 8 Batch 1000 Loss 0.3064 Accuracy 0.9222
Epoch 8 Batch 1050 Loss 0.3070 Accuracy 0.9221
Epoch 8 Batch 1100 Loss 0.3080 Accuracy 0.9219
Epoch 8 Batch 1150 Loss 0.3090 Accuracy 0.9217
Epoch 8 Batch 1200 Loss 0.3097 Accuracy 0.9216
Epoch 8 Batch 1250 Loss 0.3108 Accuracy 0.9214
Epoch 8 Batch 1300 Loss 0.3117 Accuracy 0.9213
Epoch 8 Batch 1350 Loss 0.3122 Accuracy 0.9212
Epoch 8 Batch 1400 Loss 0.3131 Accuracy 0.9210
Epoch 8 Batch 1450 Loss 0.3140 Accuracy 0.9209
Epoch 8 Batch 1500 Loss 0.3147 Accuracy 0.9208

wandb: WARNING Step must only increase in log calls.  Step 8 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3153638>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.920743>}.

Epoch 8 Loss 0.3154 Accuracy 0.9207
Time taken for 1 epoch: 37.135390281677246 secs

epoch lasted: 37.15113162994385
Epoch 9 Batch 0 Loss 0.2847 Accuracy 0.9169
Epoch 9 Batch 50 Loss 0.2853 Accuracy 0.9260
Epoch 9 Batch 100 Loss 0.2877 Accuracy 0.9263
Epoch 9 Batch 150 Loss 0.2867 Accuracy 0.9265
Epoch 9 Batch 200 Loss 0.2884 Accuracy 0.9262
Epoch 9 Batch 250 Loss 0.2911 Accuracy 0.9255
Epoch 9 Batch 300 Loss 0.2926 Accuracy 0.9253
Epoch 9 Batch 350 Loss 0.2925 Accuracy 0.9253
Epoch 9 Batch 400 Loss 0.2940 Accuracy 0.9249
Epoch 9 Batch 450 Loss 0.2937 Accuracy 0.9250
Epoch 9 Batch 500 Loss 0.2947 Accuracy 0.9248
discarded batch 529
Epoch 9 Batch 550 Loss 0.2962 Accuracy 0.9244
Epoch 9 Batch 600 Loss 0.2981 Accuracy 0.9241
Epoch 9 Batch 650 Loss 0.2989 Accuracy 0.9240
Epoch 9 Batch 700 Loss 0.3001 Accuracy 0.9237
Epoch 9 Batch 750 Loss 0.3008 Accuracy 0.9235
Epoch 9 Batch 800 Loss 0.3014 Accuracy 0.9233
Epoch 9 Batch 850 Loss 0.3023 Accuracy 0.9231
Epoch 9 Batch 900 Loss 0.3034 Accuracy 0.9231
Epoch 9 Batch 950 Loss 0.3045 Accuracy 0.9229
Epoch 9 Batch 1000 Loss 0.3054 Accuracy 0.9227
Epoch 9 Batch 1050 Loss 0.3065 Accuracy 0.9225
Epoch 9 Batch 1100 Loss 0.3069 Accuracy 0.9224
Epoch 9 Batch 1150 Loss 0.3079 Accuracy 0.9223
Epoch 9 Batch 1200 Loss 0.3087 Accuracy 0.9221
Epoch 9 Batch 1250 Loss 0.3097 Accuracy 0.9219
Epoch 9 Batch 1300 Loss 0.3105 Accuracy 0.9218
Epoch 9 Batch 1350 Loss 0.3113 Accuracy 0.9217
Epoch 9 Batch 1400 Loss 0.3122 Accuracy 0.9215
Epoch 9 Batch 1450 Loss 0.3131 Accuracy 0.9214
Epoch 9 Batch 1500 Loss 0.3139 Accuracy 0.9213

wandb: WARNING Step must only increase in log calls.  Step 9 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31449902>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9212631>}.

Epoch 9 Loss 0.3145 Accuracy 0.9213
Time taken for 1 epoch: 36.57028388977051 secs

epoch lasted: 36.575971841812134
Epoch 10 Batch 0 Loss 0.2855 Accuracy 0.9302
Epoch 10 Batch 50 Loss 0.2751 Accuracy 0.9285
Epoch 10 Batch 100 Loss 0.2777 Accuracy 0.9277
Epoch 10 Batch 150 Loss 0.2809 Accuracy 0.9272
Epoch 10 Batch 200 Loss 0.2826 Accuracy 0.9267
Epoch 10 Batch 250 Loss 0.2846 Accuracy 0.9264
Epoch 10 Batch 300 Loss 0.2874 Accuracy 0.9258
Epoch 10 Batch 350 Loss 0.2897 Accuracy 0.9256
Epoch 10 Batch 400 Loss 0.2913 Accuracy 0.9253
Epoch 10 Batch 450 Loss 0.2923 Accuracy 0.9252
Epoch 10 Batch 500 Loss 0.2933 Accuracy 0.9250
Epoch 10 Batch 550 Loss 0.2944 Accuracy 0.9248
Epoch 10 Batch 600 Loss 0.2959 Accuracy 0.9245
Epoch 10 Batch 650 Loss 0.2970 Accuracy 0.9243
Epoch 10 Batch 700 Loss 0.2981 Accuracy 0.9241
Epoch 10 Batch 750 Loss 0.2996 Accuracy 0.9239
Epoch 10 Batch 800 Loss 0.3005 Accuracy 0.9237
Epoch 10 Batch 850 Loss 0.3018 Accuracy 0.9234
Epoch 10 Batch 900 Loss 0.3026 Accuracy 0.9232
Epoch 10 Batch 950 Loss 0.3034 Accuracy 0.9231
discarded batch 997
Epoch 10 Batch 1000 Loss 0.3042 Accuracy 0.9230
Epoch 10 Batch 1050 Loss 0.3051 Accuracy 0.9229
Epoch 10 Batch 1100 Loss 0.3064 Accuracy 0.9226
Epoch 10 Batch 1150 Loss 0.3075 Accuracy 0.9224
Epoch 10 Batch 1200 Loss 0.3083 Accuracy 0.9222
Epoch 10 Batch 1250 Loss 0.3091 Accuracy 0.9220
Epoch 10 Batch 1300 Loss 0.3101 Accuracy 0.9217
Epoch 10 Batch 1350 Loss 0.3111 Accuracy 0.9216
Epoch 10 Batch 1400 Loss 0.3120 Accuracy 0.9214
Epoch 10 Batch 1450 Loss 0.3129 Accuracy 0.9212
Epoch 10 Batch 1500 Loss 0.3137 Accuracy 0.9211

wandb: WARNING Step must only increase in log calls.  Step 10 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3144978>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92099607>}.

Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-42
Epoch 10 Loss 0.3145 Accuracy 0.9210
Time taken for 1 epoch: 37.24304819107056 secs

epoch lasted: 37.24710988998413
Epoch 11 Batch 0 Loss 0.2788 Accuracy 0.9319
Epoch 11 Batch 50 Loss 0.2826 Accuracy 0.9261
Epoch 11 Batch 100 Loss 0.2863 Accuracy 0.9261
Epoch 11 Batch 150 Loss 0.2881 Accuracy 0.9260
Epoch 11 Batch 200 Loss 0.2887 Accuracy 0.9256
Epoch 11 Batch 250 Loss 0.2898 Accuracy 0.9251
Epoch 11 Batch 300 Loss 0.2922 Accuracy 0.9248
discarded batch 329
Epoch 11 Batch 350 Loss 0.2930 Accuracy 0.9248
Epoch 11 Batch 400 Loss 0.2935 Accuracy 0.9247
Epoch 11 Batch 450 Loss 0.2946 Accuracy 0.9245
Epoch 11 Batch 500 Loss 0.2954 Accuracy 0.9244
Epoch 11 Batch 550 Loss 0.2961 Accuracy 0.9241
Epoch 11 Batch 600 Loss 0.2979 Accuracy 0.9238
Epoch 11 Batch 650 Loss 0.2988 Accuracy 0.9237
Epoch 11 Batch 700 Loss 0.2997 Accuracy 0.9236
Epoch 11 Batch 750 Loss 0.3003 Accuracy 0.9235
Epoch 11 Batch 800 Loss 0.3017 Accuracy 0.9233
Epoch 11 Batch 850 Loss 0.3032 Accuracy 0.9231
Epoch 11 Batch 900 Loss 0.3039 Accuracy 0.9230
Epoch 11 Batch 950 Loss 0.3049 Accuracy 0.9227
Epoch 11 Batch 1000 Loss 0.3060 Accuracy 0.9224
Epoch 11 Batch 1050 Loss 0.3065 Accuracy 0.9223
Epoch 11 Batch 1100 Loss 0.3076 Accuracy 0.9222
Epoch 11 Batch 1150 Loss 0.3085 Accuracy 0.9221
Epoch 11 Batch 1200 Loss 0.3091 Accuracy 0.9219
Epoch 11 Batch 1250 Loss 0.3099 Accuracy 0.9218
Epoch 11 Batch 1300 Loss 0.3106 Accuracy 0.9217
Epoch 11 Batch 1350 Loss 0.3113 Accuracy 0.9216
Epoch 11 Batch 1400 Loss 0.3119 Accuracy 0.9215
Epoch 11 Batch 1450 Loss 0.3124 Accuracy 0.9214
Epoch 11 Batch 1500 Loss 0.3129 Accuracy 0.9213

wandb: WARNING Step must only increase in log calls.  Step 11 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31359592>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92121375>}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 31; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.93866223>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86268>}.

Epoch 11 Loss 0.3136 Accuracy 0.9212
Time taken for 1 epoch: 37.04943037033081 secs

discarded batch 15
Epoch 11 VALIDATION: Loss 0.9387 Accuracy 0.8627

epoch lasted: 37.21001315116882
Epoch 12 Batch 0 Loss 0.2891 Accuracy 0.9169
Epoch 12 Batch 50 Loss 0.2818 Accuracy 0.9264
Epoch 12 Batch 100 Loss 0.2840 Accuracy 0.9260
Epoch 12 Batch 150 Loss 0.2865 Accuracy 0.9256
Epoch 12 Batch 200 Loss 0.2870 Accuracy 0.9260
Epoch 12 Batch 250 Loss 0.2887 Accuracy 0.9259
Epoch 12 Batch 300 Loss 0.2915 Accuracy 0.9253
Epoch 12 Batch 350 Loss 0.2934 Accuracy 0.9251
Epoch 12 Batch 400 Loss 0.2941 Accuracy 0.9251
Epoch 12 Batch 450 Loss 0.2953 Accuracy 0.9249
Epoch 12 Batch 500 Loss 0.2961 Accuracy 0.9247
Epoch 12 Batch 550 Loss 0.2972 Accuracy 0.9242
Epoch 12 Batch 600 Loss 0.2982 Accuracy 0.9240
Epoch 12 Batch 650 Loss 0.2993 Accuracy 0.9239
Epoch 12 Batch 700 Loss 0.3007 Accuracy 0.9237
Epoch 12 Batch 750 Loss 0.3016 Accuracy 0.9236
Epoch 12 Batch 800 Loss 0.3023 Accuracy 0.9234
Epoch 12 Batch 850 Loss 0.3034 Accuracy 0.9232
Epoch 12 Batch 900 Loss 0.3041 Accuracy 0.9230
Epoch 12 Batch 950 Loss 0.3050 Accuracy 0.9228
Epoch 12 Batch 1000 Loss 0.3055 Accuracy 0.9228
Epoch 12 Batch 1050 Loss 0.3068 Accuracy 0.9227
Epoch 12 Batch 1100 Loss 0.3077 Accuracy 0.9225
Epoch 12 Batch 1150 Loss 0.3086 Accuracy 0.9223
Epoch 12 Batch 1200 Loss 0.3093 Accuracy 0.9221
Epoch 12 Batch 1250 Loss 0.3100 Accuracy 0.9220
discarded batch 1268
Epoch 12 Batch 1300 Loss 0.3106 Accuracy 0.9219
Epoch 12 Batch 1350 Loss 0.3115 Accuracy 0.9218
Epoch 12 Batch 1400 Loss 0.3122 Accuracy 0.9217
Epoch 12 Batch 1450 Loss 0.3130 Accuracy 0.9216
Epoch 12 Batch 1500 Loss 0.3138 Accuracy 0.9214

wandb: WARNING Step must only increase in log calls.  Step 12 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31454396>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92123735>}.

Epoch 12 Loss 0.3145 Accuracy 0.9212
Time taken for 1 epoch: 36.78285264968872 secs

epoch lasted: 36.78847694396973
Epoch 13 Batch 0 Loss 0.2559 Accuracy 0.9302
Epoch 13 Batch 50 Loss 0.2767 Accuracy 0.9299
Epoch 13 Batch 100 Loss 0.2837 Accuracy 0.9281
Epoch 13 Batch 150 Loss 0.2858 Accuracy 0.9272
Epoch 13 Batch 200 Loss 0.2876 Accuracy 0.9268
Epoch 13 Batch 250 Loss 0.2906 Accuracy 0.9263
Epoch 13 Batch 300 Loss 0.2921 Accuracy 0.9261
Epoch 13 Batch 350 Loss 0.2924 Accuracy 0.9259
Epoch 13 Batch 400 Loss 0.2940 Accuracy 0.9256
Epoch 13 Batch 450 Loss 0.2949 Accuracy 0.9251
Epoch 13 Batch 500 Loss 0.2956 Accuracy 0.9248
Epoch 13 Batch 550 Loss 0.2968 Accuracy 0.9245
Epoch 13 Batch 600 Loss 0.2984 Accuracy 0.9242
Epoch 13 Batch 650 Loss 0.2994 Accuracy 0.9239
Epoch 13 Batch 700 Loss 0.3007 Accuracy 0.9238
Epoch 13 Batch 750 Loss 0.3020 Accuracy 0.9236
Epoch 13 Batch 800 Loss 0.3027 Accuracy 0.9234
Epoch 13 Batch 850 Loss 0.3039 Accuracy 0.9232
discarded batch 869
Epoch 13 Batch 900 Loss 0.3045 Accuracy 0.9231
Epoch 13 Batch 950 Loss 0.3054 Accuracy 0.9229
Epoch 13 Batch 1000 Loss 0.3061 Accuracy 0.9228
Epoch 13 Batch 1050 Loss 0.3067 Accuracy 0.9227
Epoch 13 Batch 1100 Loss 0.3074 Accuracy 0.9225
Epoch 13 Batch 1150 Loss 0.3080 Accuracy 0.9224
Epoch 13 Batch 1200 Loss 0.3088 Accuracy 0.9223
Epoch 13 Batch 1250 Loss 0.3096 Accuracy 0.9221
Epoch 13 Batch 1300 Loss 0.3105 Accuracy 0.9220
Epoch 13 Batch 1350 Loss 0.3112 Accuracy 0.9218
Epoch 13 Batch 1400 Loss 0.3120 Accuracy 0.9217
Epoch 13 Batch 1450 Loss 0.3130 Accuracy 0.9215
Epoch 13 Batch 1500 Loss 0.3138 Accuracy 0.9213

wandb: WARNING Step must only increase in log calls.  Step 13 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31448522>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9211741>}.

Epoch 13 Loss 0.3145 Accuracy 0.9212
Time taken for 1 epoch: 36.23259663581848 secs

epoch lasted: 36.236817836761475
Epoch 14 Batch 0 Loss 0.2839 Accuracy 0.9336
Epoch 14 Batch 50 Loss 0.2819 Accuracy 0.9276
Epoch 14 Batch 100 Loss 0.2807 Accuracy 0.9276
Epoch 14 Batch 150 Loss 0.2821 Accuracy 0.9270
discarded batch 161
Epoch 14 Batch 200 Loss 0.2817 Accuracy 0.9269
Epoch 14 Batch 250 Loss 0.2838 Accuracy 0.9264
Epoch 14 Batch 300 Loss 0.2848 Accuracy 0.9262
Epoch 14 Batch 350 Loss 0.2867 Accuracy 0.9258
Epoch 14 Batch 400 Loss 0.2879 Accuracy 0.9256
Epoch 14 Batch 450 Loss 0.2903 Accuracy 0.9253
Epoch 14 Batch 500 Loss 0.2915 Accuracy 0.9250
Epoch 14 Batch 550 Loss 0.2936 Accuracy 0.9247
Epoch 14 Batch 600 Loss 0.2949 Accuracy 0.9246
Epoch 14 Batch 650 Loss 0.2955 Accuracy 0.9244
Epoch 14 Batch 700 Loss 0.2968 Accuracy 0.9240
Epoch 14 Batch 750 Loss 0.2982 Accuracy 0.9237
Epoch 14 Batch 800 Loss 0.2994 Accuracy 0.9235
Epoch 14 Batch 850 Loss 0.3003 Accuracy 0.9234
Epoch 14 Batch 900 Loss 0.3013 Accuracy 0.9232
Epoch 14 Batch 950 Loss 0.3023 Accuracy 0.9232
Epoch 14 Batch 1000 Loss 0.3030 Accuracy 0.9230
Epoch 14 Batch 1050 Loss 0.3038 Accuracy 0.9230
Epoch 14 Batch 1100 Loss 0.3050 Accuracy 0.9228
Epoch 14 Batch 1150 Loss 0.3061 Accuracy 0.9227
Epoch 14 Batch 1200 Loss 0.3068 Accuracy 0.9226
Epoch 14 Batch 1250 Loss 0.3080 Accuracy 0.9224
Epoch 14 Batch 1300 Loss 0.3087 Accuracy 0.9222
Epoch 14 Batch 1350 Loss 0.3097 Accuracy 0.9220
Epoch 14 Batch 1400 Loss 0.3104 Accuracy 0.9218
Epoch 14 Batch 1450 Loss 0.3111 Accuracy 0.9216
Epoch 14 Batch 1500 Loss 0.3119 Accuracy 0.9215

wandb: WARNING Step must only increase in log calls.  Step 14 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3124812>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9214186>}.

Epoch 14 Loss 0.3125 Accuracy 0.9214
Time taken for 1 epoch: 36.19467496871948 secs

epoch lasted: 36.19838523864746
Epoch 15 Batch 0 Loss 0.2725 Accuracy 0.9219
Epoch 15 Batch 50 Loss 0.2803 Accuracy 0.9267
Epoch 15 Batch 100 Loss 0.2791 Accuracy 0.9270
Epoch 15 Batch 150 Loss 0.2833 Accuracy 0.9266
Epoch 15 Batch 200 Loss 0.2860 Accuracy 0.9267
Epoch 15 Batch 250 Loss 0.2852 Accuracy 0.9270
Epoch 15 Batch 300 Loss 0.2869 Accuracy 0.9263
discarded batch 333
Epoch 15 Batch 350 Loss 0.2880 Accuracy 0.9261
Epoch 15 Batch 400 Loss 0.2895 Accuracy 0.9258
Epoch 15 Batch 450 Loss 0.2905 Accuracy 0.9258
Epoch 15 Batch 500 Loss 0.2925 Accuracy 0.9253
Epoch 15 Batch 550 Loss 0.2933 Accuracy 0.9252
Epoch 15 Batch 600 Loss 0.2950 Accuracy 0.9248
Epoch 15 Batch 650 Loss 0.2968 Accuracy 0.9245
Epoch 15 Batch 700 Loss 0.2982 Accuracy 0.9242
Epoch 15 Batch 750 Loss 0.2990 Accuracy 0.9240
Epoch 15 Batch 800 Loss 0.2997 Accuracy 0.9238
Epoch 15 Batch 850 Loss 0.3005 Accuracy 0.9236
Epoch 15 Batch 900 Loss 0.3013 Accuracy 0.9234
Epoch 15 Batch 950 Loss 0.3024 Accuracy 0.9232
Epoch 15 Batch 1000 Loss 0.3035 Accuracy 0.9230
Epoch 15 Batch 1050 Loss 0.3043 Accuracy 0.9229
Epoch 15 Batch 1100 Loss 0.3048 Accuracy 0.9228
Epoch 15 Batch 1150 Loss 0.3054 Accuracy 0.9226
Epoch 15 Batch 1200 Loss 0.3065 Accuracy 0.9224
Epoch 15 Batch 1250 Loss 0.3074 Accuracy 0.9223
Epoch 15 Batch 1300 Loss 0.3082 Accuracy 0.9222
Epoch 15 Batch 1350 Loss 0.3090 Accuracy 0.9221
Epoch 15 Batch 1400 Loss 0.3097 Accuracy 0.9219
Epoch 15 Batch 1450 Loss 0.3104 Accuracy 0.9218
Epoch 15 Batch 1500 Loss 0.3114 Accuracy 0.9216

wandb: WARNING Step must only increase in log calls.  Step 15 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31222123>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92144114>}.

Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-43
Epoch 15 Loss 0.3122 Accuracy 0.9214
Time taken for 1 epoch: 36.58800983428955 secs

epoch lasted: 36.592894077301025
Epoch 16 Batch 0 Loss 0.2798 Accuracy 0.9219
Epoch 16 Batch 50 Loss 0.2761 Accuracy 0.9276
Epoch 16 Batch 100 Loss 0.2798 Accuracy 0.9271
Epoch 16 Batch 150 Loss 0.2806 Accuracy 0.9268
Epoch 16 Batch 200 Loss 0.2811 Accuracy 0.9267
Epoch 16 Batch 250 Loss 0.2829 Accuracy 0.9265
Epoch 16 Batch 300 Loss 0.2848 Accuracy 0.9261
Epoch 16 Batch 350 Loss 0.2860 Accuracy 0.9260
Epoch 16 Batch 400 Loss 0.2880 Accuracy 0.9257
Epoch 16 Batch 450 Loss 0.2896 Accuracy 0.9254
Epoch 16 Batch 500 Loss 0.2908 Accuracy 0.9252
Epoch 16 Batch 550 Loss 0.2921 Accuracy 0.9250
Epoch 16 Batch 600 Loss 0.2931 Accuracy 0.9248
Epoch 16 Batch 650 Loss 0.2946 Accuracy 0.9245
Epoch 16 Batch 700 Loss 0.2955 Accuracy 0.9242
Epoch 16 Batch 750 Loss 0.2964 Accuracy 0.9240
Epoch 16 Batch 800 Loss 0.2977 Accuracy 0.9238
Epoch 16 Batch 850 Loss 0.2991 Accuracy 0.9237
Epoch 16 Batch 900 Loss 0.3002 Accuracy 0.9235
Epoch 16 Batch 950 Loss 0.3011 Accuracy 0.9233
Epoch 16 Batch 1000 Loss 0.3019 Accuracy 0.9232
Epoch 16 Batch 1050 Loss 0.3033 Accuracy 0.9230
Epoch 16 Batch 1100 Loss 0.3044 Accuracy 0.9228
Epoch 16 Batch 1150 Loss 0.3054 Accuracy 0.9226
Epoch 16 Batch 1200 Loss 0.3062 Accuracy 0.9224
Epoch 16 Batch 1250 Loss 0.3071 Accuracy 0.9222
discarded batch 1271
Epoch 16 Batch 1300 Loss 0.3077 Accuracy 0.9221
Epoch 16 Batch 1350 Loss 0.3083 Accuracy 0.9220
Epoch 16 Batch 1400 Loss 0.3093 Accuracy 0.9219
Epoch 16 Batch 1450 Loss 0.3100 Accuracy 0.9218
Epoch 16 Batch 1500 Loss 0.3106 Accuracy 0.9217

wandb: WARNING Step must only increase in log calls.  Step 16 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31141418>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9215355>}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 31; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.94381136>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.86445177>}.

Epoch 16 Loss 0.3114 Accuracy 0.9215
Time taken for 1 epoch: 36.26819968223572 secs

discarded batch 15
Epoch 16 VALIDATION: Loss 0.9438 Accuracy 0.8645

epoch lasted: 36.425113677978516
Epoch 17 Batch 0 Loss 0.2682 Accuracy 0.9302
Epoch 17 Batch 50 Loss 0.2816 Accuracy 0.9268
Epoch 17 Batch 100 Loss 0.2828 Accuracy 0.9267
Epoch 17 Batch 150 Loss 0.2844 Accuracy 0.9264
discarded batch 182
Epoch 17 Batch 200 Loss 0.2871 Accuracy 0.9260
Epoch 17 Batch 250 Loss 0.2874 Accuracy 0.9258
Epoch 17 Batch 300 Loss 0.2898 Accuracy 0.9254
Epoch 17 Batch 350 Loss 0.2901 Accuracy 0.9254
Epoch 17 Batch 400 Loss 0.2911 Accuracy 0.9252
Epoch 17 Batch 450 Loss 0.2926 Accuracy 0.9250
Epoch 17 Batch 500 Loss 0.2930 Accuracy 0.9250
Epoch 17 Batch 550 Loss 0.2945 Accuracy 0.9250
Epoch 17 Batch 600 Loss 0.2957 Accuracy 0.9247
Epoch 17 Batch 650 Loss 0.2963 Accuracy 0.9245
Epoch 17 Batch 700 Loss 0.2976 Accuracy 0.9242
Epoch 17 Batch 750 Loss 0.2985 Accuracy 0.9241
Epoch 17 Batch 800 Loss 0.2997 Accuracy 0.9238
Epoch 17 Batch 850 Loss 0.3006 Accuracy 0.9237
Epoch 17 Batch 900 Loss 0.3014 Accuracy 0.9235
Epoch 17 Batch 950 Loss 0.3024 Accuracy 0.9234
Epoch 17 Batch 1000 Loss 0.3035 Accuracy 0.9232
Epoch 17 Batch 1050 Loss 0.3044 Accuracy 0.9230
Epoch 17 Batch 1100 Loss 0.3051 Accuracy 0.9229
Epoch 17 Batch 1150 Loss 0.3058 Accuracy 0.9227
Epoch 17 Batch 1200 Loss 0.3066 Accuracy 0.9226
Epoch 17 Batch 1250 Loss 0.3073 Accuracy 0.9225
Epoch 17 Batch 1300 Loss 0.3080 Accuracy 0.9223
Epoch 17 Batch 1350 Loss 0.3088 Accuracy 0.9222
Epoch 17 Batch 1400 Loss 0.3096 Accuracy 0.9221
Epoch 17 Batch 1450 Loss 0.3099 Accuracy 0.9220
Epoch 17 Batch 1500 Loss 0.3106 Accuracy 0.9218

wandb: WARNING Step must only increase in log calls.  Step 17 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31121874>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92175853>}.

Epoch 17 Loss 0.3112 Accuracy 0.9218
Time taken for 1 epoch: 36.178606033325195 secs

epoch lasted: 36.1828989982605
Epoch 18 Batch 0 Loss 0.2897 Accuracy 0.9369
Epoch 18 Batch 50 Loss 0.2841 Accuracy 0.9267
Epoch 18 Batch 100 Loss 0.2792 Accuracy 0.9274
Epoch 18 Batch 150 Loss 0.2813 Accuracy 0.9268
Epoch 18 Batch 200 Loss 0.2843 Accuracy 0.9262
Epoch 18 Batch 250 Loss 0.2864 Accuracy 0.9257
Epoch 18 Batch 300 Loss 0.2889 Accuracy 0.9255
Epoch 18 Batch 350 Loss 0.2900 Accuracy 0.9253
Epoch 18 Batch 400 Loss 0.2914 Accuracy 0.9251
Epoch 18 Batch 450 Loss 0.2925 Accuracy 0.9249
Epoch 18 Batch 500 Loss 0.2947 Accuracy 0.9246
Epoch 18 Batch 550 Loss 0.2952 Accuracy 0.9244
Epoch 18 Batch 600 Loss 0.2960 Accuracy 0.9245
Epoch 18 Batch 650 Loss 0.2973 Accuracy 0.9241
Epoch 18 Batch 700 Loss 0.2982 Accuracy 0.9239
Epoch 18 Batch 750 Loss 0.2990 Accuracy 0.9238
Epoch 18 Batch 800 Loss 0.2999 Accuracy 0.9238
Epoch 18 Batch 850 Loss 0.3013 Accuracy 0.9236
Epoch 18 Batch 900 Loss 0.3019 Accuracy 0.9235
Epoch 18 Batch 950 Loss 0.3026 Accuracy 0.9234
Epoch 18 Batch 1000 Loss 0.3034 Accuracy 0.9232
Epoch 18 Batch 1050 Loss 0.3041 Accuracy 0.9232
Epoch 18 Batch 1100 Loss 0.3048 Accuracy 0.9230
Epoch 18 Batch 1150 Loss 0.3055 Accuracy 0.9229
Epoch 18 Batch 1200 Loss 0.3062 Accuracy 0.9228
Epoch 18 Batch 1250 Loss 0.3071 Accuracy 0.9226
Epoch 18 Batch 1300 Loss 0.3075 Accuracy 0.9225
Epoch 18 Batch 1350 Loss 0.3080 Accuracy 0.9224
Epoch 18 Batch 1400 Loss 0.3084 Accuracy 0.9223
discarded batch 1420
Epoch 18 Batch 1450 Loss 0.3093 Accuracy 0.9221
Epoch 18 Batch 1500 Loss 0.3101 Accuracy 0.9219

wandb: WARNING Step must only increase in log calls.  Step 18 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3109506>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92178965>}.

Epoch 18 Loss 0.3110 Accuracy 0.9218
Time taken for 1 epoch: 36.217137813568115 secs

epoch lasted: 36.22153854370117
Epoch 19 Batch 0 Loss 0.2849 Accuracy 0.9236
Epoch 19 Batch 50 Loss 0.2800 Accuracy 0.9273
Epoch 19 Batch 100 Loss 0.2762 Accuracy 0.9282
Epoch 19 Batch 150 Loss 0.2763 Accuracy 0.9285
Epoch 19 Batch 200 Loss 0.2798 Accuracy 0.9275
Epoch 19 Batch 250 Loss 0.2841 Accuracy 0.9266
Epoch 19 Batch 300 Loss 0.2861 Accuracy 0.9264
Epoch 19 Batch 350 Loss 0.2883 Accuracy 0.9260
Epoch 19 Batch 400 Loss 0.2898 Accuracy 0.9255
Epoch 19 Batch 450 Loss 0.2903 Accuracy 0.9254
Epoch 19 Batch 500 Loss 0.2912 Accuracy 0.9252
Epoch 19 Batch 550 Loss 0.2925 Accuracy 0.9250
Epoch 19 Batch 600 Loss 0.2934 Accuracy 0.9249
Epoch 19 Batch 650 Loss 0.2942 Accuracy 0.9247
Epoch 19 Batch 700 Loss 0.2954 Accuracy 0.9245
Epoch 19 Batch 750 Loss 0.2963 Accuracy 0.9242
Epoch 19 Batch 800 Loss 0.2976 Accuracy 0.9239
discarded batch 801
Epoch 19 Batch 850 Loss 0.2988 Accuracy 0.9236
Epoch 19 Batch 900 Loss 0.2999 Accuracy 0.9234
Epoch 19 Batch 950 Loss 0.3009 Accuracy 0.9233
Epoch 19 Batch 1000 Loss 0.3018 Accuracy 0.9231
Epoch 19 Batch 1050 Loss 0.3028 Accuracy 0.9229
Epoch 19 Batch 1100 Loss 0.3034 Accuracy 0.9228
Epoch 19 Batch 1150 Loss 0.3041 Accuracy 0.9227
Epoch 19 Batch 1200 Loss 0.3054 Accuracy 0.9224
Epoch 19 Batch 1250 Loss 0.3063 Accuracy 0.9223
Epoch 19 Batch 1300 Loss 0.3073 Accuracy 0.9221
Epoch 19 Batch 1350 Loss 0.3081 Accuracy 0.9220
Epoch 19 Batch 1400 Loss 0.3088 Accuracy 0.9218
Epoch 19 Batch 1450 Loss 0.3095 Accuracy 0.9218
Epoch 19 Batch 1500 Loss 0.3104 Accuracy 0.9216

wandb: WARNING Step must only increase in log calls.  Step 19 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31073174>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9216352>}.

Epoch 19 Loss 0.3107 Accuracy 0.9216
Time taken for 1 epoch: 36.11687517166138 secs

epoch lasted: 36.1212158203125
Epoch 20 Batch 0 Loss 0.2569 Accuracy 0.9219
Epoch 20 Batch 50 Loss 0.2792 Accuracy 0.9280
Epoch 20 Batch 100 Loss 0.2803 Accuracy 0.9277
Epoch 20 Batch 150 Loss 0.2827 Accuracy 0.9272
Epoch 20 Batch 200 Loss 0.2825 Accuracy 0.9274
Epoch 20 Batch 250 Loss 0.2846 Accuracy 0.9270
Epoch 20 Batch 300 Loss 0.2865 Accuracy 0.9267
Epoch 20 Batch 350 Loss 0.2878 Accuracy 0.9264
Epoch 20 Batch 400 Loss 0.2880 Accuracy 0.9263
Epoch 20 Batch 450 Loss 0.2897 Accuracy 0.9259
Epoch 20 Batch 500 Loss 0.2913 Accuracy 0.9257
discarded batch 545
Epoch 20 Batch 550 Loss 0.2928 Accuracy 0.9253
Epoch 20 Batch 600 Loss 0.2940 Accuracy 0.9252
Epoch 20 Batch 650 Loss 0.2952 Accuracy 0.9249
Epoch 20 Batch 700 Loss 0.2965 Accuracy 0.9247
Epoch 20 Batch 750 Loss 0.2975 Accuracy 0.9244
Epoch 20 Batch 800 Loss 0.2990 Accuracy 0.9241
Epoch 20 Batch 850 Loss 0.3004 Accuracy 0.9239
Epoch 20 Batch 900 Loss 0.3011 Accuracy 0.9237
Epoch 20 Batch 950 Loss 0.3022 Accuracy 0.9233
Epoch 20 Batch 1000 Loss 0.3027 Accuracy 0.9232
Epoch 20 Batch 1050 Loss 0.3035 Accuracy 0.9231
Epoch 20 Batch 1100 Loss 0.3047 Accuracy 0.9228
Epoch 20 Batch 1150 Loss 0.3055 Accuracy 0.9227
Epoch 20 Batch 1200 Loss 0.3063 Accuracy 0.9225
Epoch 20 Batch 1250 Loss 0.3072 Accuracy 0.9223
Epoch 20 Batch 1300 Loss 0.3078 Accuracy 0.9222
Epoch 20 Batch 1350 Loss 0.3086 Accuracy 0.9221
Epoch 20 Batch 1400 Loss 0.3093 Accuracy 0.9220
Epoch 20 Batch 1450 Loss 0.3100 Accuracy 0.9218
Epoch 20 Batch 1500 Loss 0.3108 Accuracy 0.9217

wandb: WARNING Step must only increase in log calls.  Step 20 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31146565>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.92156124>}.

Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-44
Epoch 20 Loss 0.3115 Accuracy 0.9216
Time taken for 1 epoch: 36.50665497779846 secs

epoch lasted: 36.51204705238342
Epoch 21 Batch 0 Loss 0.3251 Accuracy 0.9252
Epoch 21 Batch 50 Loss 0.2793 Accuracy 0.9267
Epoch 21 Batch 100 Loss 0.2794 Accuracy 0.9264
discarded batch 143
Epoch 21 Batch 150 Loss 0.2784 Accuracy 0.9274
Epoch 21 Batch 200 Loss 0.2824 Accuracy 0.9263
Epoch 21 Batch 250 Loss 0.2833 Accuracy 0.9265
Epoch 21 Batch 300 Loss 0.2862 Accuracy 0.9259
Epoch 21 Batch 350 Loss 0.2880 Accuracy 0.9256
Epoch 21 Batch 400 Loss 0.2887 Accuracy 0.9255
Epoch 21 Batch 450 Loss 0.2898 Accuracy 0.9252
Epoch 21 Batch 500 Loss 0.2908 Accuracy 0.9251
Epoch 21 Batch 550 Loss 0.2919 Accuracy 0.9250
Epoch 21 Batch 600 Loss 0.2931 Accuracy 0.9247
Epoch 21 Batch 650 Loss 0.2935 Accuracy 0.9247
Epoch 21 Batch 700 Loss 0.2942 Accuracy 0.9245
Epoch 21 Batch 750 Loss 0.2954 Accuracy 0.9244
Epoch 21 Batch 800 Loss 0.2963 Accuracy 0.9241
Epoch 21 Batch 850 Loss 0.2973 Accuracy 0.9240
Epoch 21 Batch 900 Loss 0.2982 Accuracy 0.9239
Epoch 21 Batch 950 Loss 0.2995 Accuracy 0.9236
Epoch 21 Batch 1000 Loss 0.3004 Accuracy 0.9234
Epoch 21 Batch 1050 Loss 0.3013 Accuracy 0.9233
Epoch 21 Batch 1100 Loss 0.3022 Accuracy 0.9232
Epoch 21 Batch 1150 Loss 0.3031 Accuracy 0.9229
Epoch 21 Batch 1200 Loss 0.3042 Accuracy 0.9228
Epoch 21 Batch 1250 Loss 0.3056 Accuracy 0.9226
Epoch 21 Batch 1300 Loss 0.3064 Accuracy 0.9224
Epoch 21 Batch 1350 Loss 0.3069 Accuracy 0.9223
Epoch 21 Batch 1400 Loss 0.3077 Accuracy 0.9222
Epoch 21 Batch 1450 Loss 0.3085 Accuracy 0.9221
Epoch 21 Batch 1500 Loss 0.3092 Accuracy 0.9220

wandb: WARNING Step must only increase in log calls.  Step 21 < 31; dropping {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31015202>, 'train_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9218229>}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 31; dropping {'val_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.94446176>, 'val_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.8632336>}.

Epoch 21 Loss 0.3102 Accuracy 0.9218
Time taken for 1 epoch: 36.14315629005432 secs

discarded batch 15
Epoch 21 VALIDATION: Loss 0.9445 Accuracy 0.8632

params: k=4, t=0.9

